{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction to Data Science with Python and AI","text":"<p>Welcome to our website for the course that uses AI to help students learn data science.  This course is designed to help advanced high-school and freshman college students quickly learn the core concepts of data science with extensive use of Micro-Simulations and AI.</p> <p>Please contact me on LinkedIn if you have any questions.</p> <ul> <li>Dan McCreary</li> </ul>"},{"location":"about/","title":"About This Book","text":"<p>In today\u2019s data-rich world, the ability to extract meaningful insights from information isn\u2019t just an advantage\u2014it\u2019s essential. This book, Introduction to Data Science with Python and AI, aims to empower advanced high-school and early college students with the tools, concepts, and critical thinking skills needed to become fluent in the language of data. Through interactive modules\u2014MicroSims\u2014you\u2019ll build a deep understanding of linear regression and progressively more sophisticated predictive models using Python, NumPy, and PyTorch. Our focus remains on balancing interpretability and predictive performance, helping you discover how simple models can often offer powerful\u2014and explainable\u2014solutions.</p>"},{"location":"about/#why-this-book-matters","title":"Why This Book Matters","text":""},{"location":"about/#1-data-science-skills-are-in-high-demand","title":"1. Data Science Skills Are in High Demand","text":"<p>The U.S. Bureau of Labor Statistics projects that jobs for data scientists will grow by 36% from 2021 to 2031\u2014far exceeding average job growth across all occupations (Harvard Extension School). IBM research also forecasts approximately 2.7 million job openings in data science and data engineering in the near future (Medium).</p>"},{"location":"about/#2-businesses-thrive-with-data-expertise","title":"2. Businesses Thrive with Data Expertise","text":"<p>An empirical study spanning 2.9 million employees across 7,408 investment firms (2008\u20132021) found that firms with more data specialists performed better, particularly when local universities introduced data science programs\u2014a pattern suggestive of a causal link (F.N. London).</p>"},{"location":"about/#3-cross-sector-demand-for-data-literacy","title":"3. Cross-Sector Demand for Data Literacy","text":"<p>Beyond specialized roles, basic data literacy is quickly becoming a core competency across all fields. A global study by Forrester Consulting (sponsored by Tableau) found that 82% of decision-makers expect basic data literacy from employees in every department, with projections that by 2025 nearly 70% of employees will heavily rely on data (TIME).</p>"},{"location":"about/#4-ai-increases-demand-for-complementary-human-skills","title":"4. AI Increases Demand for Complementary Human Skills","text":"<p>Research analyzing 12 million job postings from 2018\u20132023 in the U.S. shows that AI is raising the demand\u2014and wage premiums\u2014for complementary human skills such as digital literacy, teamwork, and resilience, especially in AI-impacted roles like data science (arXiv). This means that learning to work effectively with data and AI tools will remain valuable\u2014and increasingly so.</p>"},{"location":"about/#5-data-driven-innovation-boosts-subject-matter-experts","title":"5. Data-Driven Innovation Boosts Subject Matter Experts","text":"<p>A case study of 85 Subject Matter Expertss in the U.K. highlighted how data science techniques like customer forecasting and predictive maintenance drive productivity, innovation, and job creation\u2014though these benefits hinge on developing both skills and infrastructure (Reddit, arXiv).</p> <p>Through this book, you won\u2019t just learn to code\u2014you\u2019ll gain an essential toolkit for navigating, interrogating, and communicating with data in any field you choose. By starting with clear, hands-on simulations and building up to more advanced techniques, we ensure that every concept you encounter is grounded in understanding, not just syntax.</p> <p>Here\u2019s an additional section you can insert right after the \u201cWhy This Book Matters\u201d part of your document. It highlights why using AI-generated interactive simulations (MicroSims) offers a superior learning experience compared to traditional static textbooks.</p>"},{"location":"about/#why-our-ai-powered-interactive-simulations-outperform-static-textbooks","title":"Why Our AI-Powered Interactive Simulations Outperform Static Textbooks","text":"<p>Traditional textbooks, while valuable as references, often present information in a linear, static, and passive format. This approach leaves students reading about concepts without the opportunity to experiment, test, and immediately see the impact of changing parameters. Our methodology fundamentally changes that dynamic by integrating AI-generated interactive simulations (MicroSims) into the core of the learning experience.</p> <p>Key Advantages:</p> <ol> <li> <p>Active Learning Over Passive Reading    Students don\u2019t just read about a concept\u2014they manipulate variables, observe results, and form hypotheses in real time. This active engagement significantly improves retention compared to passive reading.</p> </li> <li> <p>Personalized Exploration    AI adapts simulations to a student\u2019s pace and curiosity. If a learner struggles with a concept, the system can generate additional guided examples or simplify the scenario. Advanced learners can explore \u201cwhat-if\u201d situations beyond the basic curriculum.</p> </li> <li> <p>Immediate Feedback Loop    Instead of waiting until a homework assignment is graded, students get instant feedback within the simulation. This encourages experimentation and builds confidence.</p> </li> <li> <p>Bridging Theory and Practice    Concepts such as statistical distributions, regression coefficients, and the bias-variance tradeoff become tangible. By adjusting sliders or toggling options, abstract equations transform into visual, intuitive insights.</p> </li> <li> <p>Adaptive Content Updates    AI-generated content allows the textbook to evolve with the field. When new methods or datasets emerge, we can rapidly integrate them into simulations\u2014keeping learning materials relevant without waiting for a new print edition.</p> </li> <li> <p>Data-Driven Instruction    Student interactions within MicroSims can be logged (with privacy safeguards) to help educators identify common misunderstandings and adapt teaching strategies accordingly.</p> </li> <li> <p>Democratizing Access    Because simulations run in the browser, they require no expensive software or specialized hardware\u2014making cutting-edge, interactive learning accessible to a global audience.</p> </li> </ol> <p>The Result: Instead of memorizing definitions and formulas in isolation, learners develop conceptual mastery through guided experimentation, preparing them not only to understand data science today but also to apply it creatively to tomorrow\u2019s problems.</p> <p>Here\u2019s the additional section you can place toward the end of the About This Book page, right before the References section.</p>"},{"location":"about/#open-licensing-for-educator-adaptation","title":"Open Licensing for Educator Adaptation","text":"<p>This textbook is published under the Creative Commons Attribution\u2013NonCommercial\u2013ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED) license. This means you are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format.</li> <li>Adapt \u2014 remix, transform, and build upon the material.</li> </ul> <p>As long as you follow these conditions:</p> <ol> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> </ol>"},{"location":"about/#why-this-matters-for-instructors","title":"Why This Matters for Instructors","text":"<p>The open license ensures that educators can quickly adapt this textbook to match their school\u2019s curriculum, pacing, and student needs without seeking additional permissions.</p> <p>Instructors can add new examples relevant to their region, translate content into different languages, or integrate local datasets and case studies\u2014while still contributing back to the global teaching community.</p> <p>For the full legal text of the license, see: https://creativecommons.org/licenses/by-nc-sa/4.0/</p>"},{"location":"about/#references","title":"References","text":"<ol> <li> <p>https://en.wikipedia.org/wiki/Data_science \u2013 today \u2013 Wikipedia \u2013 Provides foundational context and history of data science, framing the evolution of the field (Wikipedia).</p> </li> <li> <p>https://extension.harvard.edu/blog/why-study-data-science/ \u2013 Jul\u202f21\u202f2023 \u2013 Harvard Extension School blog \u2013 Highlights job growth (36\u202f%) and career opportunities in data science (Harvard Extension School).</p> </li> <li> <p>https://medium.com/analysts-corner/bridging-the-data-science-skills-gap-c90b4d994bff \u2013 last 9 months \u2013 Medium article \u2013 Cites IBM prediction of 2.7 million roles in data science and engineering (Medium).</p> </li> <li> <p>https://www.fnlondon.com/articles/firms-say-they-like-arts-graduates-but-its-the-data-geeks-who-perform\u2011e2d6e034 \u2013 May\u202f5\u202f2025 \u2013 Financial News London \u2013 Reports study showing better investment firm performance tied to hiring more data specialists (F.N. London).</p> </li> <li> <p>https://time.com/6290684/data-literacy-us-national-security/ \u2013 Jun\u202f29\u202f2023 \u2013 TIME \u2013 Summarizes Forrester/Tab\u200bleau finding that 82\u202f% of decision\u2011makers expect data literacy, with 70\u202f% of employees using data heavily by 2025 (TIME).</p> </li> <li> <p>https://arxiv.org/abs/2412.19754 \u2013 Dec\u202f27\u202f2024 \u2013 arXiv preprint \u2013 Shows AI increases demand for complementary skills like digital literacy and resilience, especially in data science roles (arXiv).</p> </li> <li> <p>https://arxiv.org/abs/2305.15454 \u2013 May\u202f24\u202f2023 \u2013 arXiv preprint \u2013 Case studies of 85 UK SMEs showing data science supports productivity, innovation, customer insight, but requires investment in skills and infrastructure (arXiv).</p> </li> <li> <p>https://en.wikipedia.org/wiki/Data_literacy \u2013 6 months ago \u2013 Wikipedia \u2013 Defines \u201cdata literacy\u201d as a fundamental capability involving reading, interpreting, evaluating, and communicating data effectively (Wikipedia).</p> </li> <li> <p>https://en.wikipedia.org/wiki/Analytical_skill \u2013 last month \u2013 Wikipedia \u2013 Describes analytical skill set (including data analysis, critical thinking) as critical across professions (Wikipedia).</p> </li> <li> <p>https://sciencedirect.com/science/article/pii/S0263237322000810 \u2013 2022 \u2013 ScienceDirect \u2013 Miller and Hughes study on market demand for data science skills across six industries (ScienceDirect).</p> </li> </ol> <p>Let me know if you'd like help drafting other sections (e.g. Preface, Tutorials, Chapter intros).</p>"},{"location":"checklist/","title":"Site Checklist","text":"<ol> <li>Customize the fields in your mkdocs.yml file</li> <li>Configure Google Analytics to use the right site ID</li> <li>Make sure that your .gitignore file includes the <code>site</code> directory</li> <li>Test the build</li> <li>Make sure the Edit button appears</li> <li>Make sure that code color heightening renders correctly</li> <li>run <code>git config advice.addIgnoredFile false</code></li> </ol>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn if you have any questions.</p> <p>Thanks! - Dan</p>"},{"location":"course-description/","title":"Course Description for Introduction to Data Science with Python","text":"<p>Course Duration: 10 weeks Target Audience: Advanced high school students and college freshmen Prerequisites: Basic algebra and introductory programming experience recommended</p>"},{"location":"course-description/#course-overview","title":"Course Overview","text":"<p>This introductory course provides students with foundational knowledge and practical skills in data science using Python.  Through hands-on experience with interactive simulations MicroSims and real-world datasets,  students will develop competency in data analysis, visualization, and predictive modeling.  The course emphasizes the critical balance between model explainability and predictive accuracy,  guiding students to identify the simplest effective solutions to data-driven problems.</p>"},{"location":"course-description/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this course, students will be able to:</p> <p>Remember (Knowledge) - Recall fundamental data science terminology and concepts - Identify key Python libraries for data science (NumPy, pandas, matplotlib, PyTorch) - Recognize different types of data and measurement scales - List the steps in the data science workflow</p> <p>Understand (Comprehension) - Explain the relationship between independent and dependent variables - Describe how linear regression models make predictions - Interpret basic statistical measures and visualizations - Summarize the trade-offs between model complexity and interpretability</p> <p>Apply (Application) - Implement basic data cleaning and preprocessing techniques - Create visualizations using Python libraries - Build simple linear regression models - Execute standard data science workflows on new datasets</p> <p>Analyze (Analysis) - Examine datasets to identify patterns and relationships - Compare different modeling approaches for the same problem - Distinguish between correlation and causation in data relationships - Evaluate model performance using appropriate metrics</p> <p>Evaluate (Evaluation) - Assess the quality and reliability of data sources - Critique model assumptions and limitations - Judge the appropriateness of different models for specific problems - Validate model performance and identify potential overfitting</p> <p>Create (Synthesis) - Design experiments to test hypotheses using data - Construct predictive models for real-world scenarios - Develop data-driven solutions to complex problems - Generate original insights from exploratory data analysis</p>"},{"location":"course-description/#sample-weekly-schedule","title":"Sample Weekly Schedule","text":""},{"location":"course-description/#week-1-foundations-of-data-science","title":"Week 1: Foundations of Data Science","text":"<ul> <li>Introduction to data science and its applications</li> <li>Setting up Python environment and Jupyter notebooks</li> <li>First MicroSim: Exploring sample datasets</li> <li>Basic data types and structures in Python</li> </ul>"},{"location":"course-description/#week-2-data-exploration-and-visualization","title":"Week 2: Data Exploration and Visualization","text":"<ul> <li>Loading and examining datasets with pandas</li> <li>Creating basic plots with matplotlib</li> <li>MicroSim: Interactive data visualization</li> <li>Identifying patterns in data through visual exploration</li> </ul>"},{"location":"course-description/#week-3-statistical-foundations","title":"Week 3: Statistical Foundations","text":"<ul> <li>Descriptive statistics and summary measures</li> <li>Understanding distributions and variability</li> <li>MicroSim: Statistical parameter exploration</li> <li>Introduction to probability concepts</li> </ul>"},{"location":"course-description/#week-4-simple-linear-regression","title":"Week 4: Simple Linear Regression","text":"<ul> <li>Mathematical foundations of linear regression</li> <li>Implementing regression from scratch</li> <li>MicroSim: Interactive regression line fitting</li> <li>Interpreting coefficients and model output</li> </ul>"},{"location":"course-description/#week-5-model-evaluation-and-validation","title":"Week 5: Model Evaluation and Validation","text":"<ul> <li>Measuring model performance (R\u00b2, MSE, MAE)</li> <li>Training and testing data splits</li> <li>MicroSim: Cross-validation simulation</li> <li>Understanding overfitting and underfitting</li> </ul>"},{"location":"course-description/#week-6-multiple-linear-regression","title":"Week 6: Multiple Linear Regression","text":"<ul> <li>Extending to multiple predictor variables</li> <li>Feature selection and engineering</li> <li>MicroSim: Multi-dimensional regression explorer</li> <li>Handling categorical variables</li> </ul>"},{"location":"course-description/#week-7-introduction-to-numpy-and-advanced-computation","title":"Week 7: Introduction to NumPy and Advanced Computation","text":"<ul> <li>NumPy arrays and vectorized operations</li> <li>Matrix operations for regression</li> <li>MicroSim: Linear algebra visualization</li> <li>Computational efficiency in data science</li> </ul>"},{"location":"course-description/#week-8-non-linear-models-and-regularization","title":"Week 8: Non-linear Models and Regularization","text":"<ul> <li>Polynomial regression and feature transformation</li> <li>Ridge and Lasso regularization</li> <li>MicroSim: Bias-variance trade-off explorer</li> <li>Model selection strategies</li> </ul>"},{"location":"course-description/#week-9-introduction-to-machine-learning-with-pytorch","title":"Week 9: Introduction to Machine Learning with PyTorch","text":"<ul> <li>Neural networks and deep learning concepts</li> <li>Building simple networks with PyTorch</li> <li>MicroSim: Neural network playground</li> <li>Comparing traditional and deep learning approaches</li> </ul>"},{"location":"course-description/#week-10-capstone-project-and-model-deployment","title":"Week 10: Capstone Project and Model Deployment","text":"<ul> <li>End-to-end data science project</li> <li>Model interpretation and communication</li> <li>MicroSim: Model comparison dashboard</li> <li>Best practices and ethical considerations</li> </ul>"},{"location":"course-description/#assessment-methods","title":"Assessment Methods","text":"<p>Formative Assessment (60%) - Weekly MicroSim exercises and reflections (30%) - Homework assignments applying concepts to new datasets (20%) - Peer review activities and collaborative problem-solving (10%)</p> <p>Summative Assessment (40%) - Midterm project: Complete data analysis report (15%) - Final capstone project: Original predictive modeling solution (20%) - Final examination covering theoretical concepts (5%)</p>"},{"location":"course-description/#required-materials","title":"Required Materials","text":"<ul> <li>Computer with Python 3.8+ installed</li> <li>Access to interactive online textbook with MicroSims</li> <li>Jupyter Notebook environment</li> <li>Required Python packages: pandas, NumPy, matplotlib, scikit-learn, PyTorch</li> </ul>"},{"location":"course-description/#key-learning-principles","title":"Key Learning Principles","text":"<p>Interactive Learning: Each week features hands-on MicroSims that allow students to manipulate parameters and observe results in real-time, reinforcing theoretical concepts through experiential learning.</p> <p>Scaffolded Complexity: The course progresses systematically from simple linear relationships to complex neural networks, ensuring students build confidence before tackling advanced topics.</p> <p>Explainable AI Focus: Throughout the course, emphasis is placed on understanding and interpreting models rather than simply achieving high accuracy, preparing students for ethical and transparent data science practice.</p> <p>Real-world Applications: All examples and projects use authentic datasets and scenarios, helping students connect academic learning to practical problem-solving.</p>"},{"location":"course-description/#course-philosophy","title":"Course Philosophy","text":"<p>This course is built on the principle that effective data science requires both technical competence and critical thinking. Students will learn not just how to build predictive models, but when to use them, how to interpret their results, and how to communicate findings to diverse audiences. The integration of interactive simulations ensures that abstract mathematical concepts become concrete and intuitive, while the progression from simple to complex models helps students appreciate the value of parsimony in modeling.</p> <p>By the end of this course, students will have developed both the technical skills and analytical mindset necessary for success in advanced data science coursework or entry-level positions in data-driven fields.</p>"},{"location":"faqs/","title":"Introduction to Data Science FAQs","text":""},{"location":"faqs/#what-is-data-science-and-why-is-it-important","title":"What is data science, and why is it important?","text":"<p>Data science is an interdisciplinary field that combines domain expertise, programming skills, and knowledge of mathematics and statistics to extract meaningful insights from data. It is important because it enables organizations to make informed decisions, predict trends, and solve complex problems by analyzing large datasets.</p>"},{"location":"faqs/#why-is-python-used-in-data-science","title":"Why is Python used in data science?","text":"<p>Python is widely used in data science due to its simplicity and versatility. It offers a vast ecosystem of libraries and frameworks like NumPy, Pandas, Matplotlib, and scikit-learn, which facilitate data manipulation, analysis, visualization, and machine learning tasks.</p>"},{"location":"faqs/#what-are-jupyter-notebooks","title":"What are Jupyter Notebooks?","text":"<p>Jupyter Notebooks are interactive web-based computing environments that allow you to create and share documents containing live code, equations, visualizations, and narrative text. They are particularly popular in data science, research, and education for their ability to combine code execution with rich documentation.</p> <p>Key Features: - Interactive Code Execution: Run code cells individually and see results immediately - Multiple Language Support: Primarily Python, but also supports R, Julia, Scala, and 40+ other languages - Rich Output Display: Show plots, tables, HTML, images, and interactive widgets inline - Markdown Support: Write formatted text, equations (LaTeX), and documentation alongside code - Easy Sharing: Export to HTML, PDF, or share via GitHub, making collaboration simple</p> <p>Why Use Jupyter Notebooks for Data Science? - Exploratory Data Analysis: Perfect for iterative data exploration and visualization - Prototyping: Quickly test ideas and algorithms before building production code - Documentation: Combine code with explanations, making analysis reproducible and understandable - Education: Ideal for learning and teaching data science concepts with immediate feedback - Presentation: Create compelling data stories with code, visualizations, and narrative</p> <p>Common Use Cases: - Data cleaning and preprocessing - Statistical analysis and modeling - Machine learning experimentation - Creating reproducible research - Building interactive dashboards - Educational tutorials and assignments</p> <p>In this course, you'll use Jupyter Notebooks extensively for hands-on exercises, MicroSims, and project work, allowing you to experiment with data science concepts in an interactive environment.</p>"},{"location":"faqs/#what-are-the-key-python-libraries-for-data-analysis","title":"What are the key Python libraries for data analysis?","text":"<p>The key Python libraries for data analysis include:</p> <ul> <li>NumPy: For numerical computing and array operations.</li> <li>Pandas: For data manipulation and analysis using data structures like DataFrames.</li> <li>Plotly: Modern interactive data visualization within a browser</li> <li>Matplotlib: For creating static, animated, and interactive visualizations.</li> <li>Seaborn: For statistical data visualization built on top of Matplotlib.</li> <li>scikit-learn: For machine learning algorithms and predictive data analysis.</li> </ul>"},{"location":"faqs/#how-do-you-import-a-csv-file-into-a-pandas-dataframe","title":"How do you import a CSV file into a Pandas DataFrame?","text":"<p>You can import a CSV file using the <code>read_csv()</code> function from Pandas:</p> <pre><code>import pandas as pd\n\ndf = pd.read_csv('file_name.csv')\n</code></pre> <p>Replace <code>'file_name.csv'</code> with the path to your CSV file.</p>"},{"location":"faqs/#what-is-a-dataframe-in-pandas","title":"What is a DataFrame in Pandas?","text":"<p>A DataFrame is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled axes (rows and columns). It is similar to a spreadsheet or SQL table and is the primary data structure used in Pandas for data manipulation.</p>"},{"location":"faqs/#how-do-you-handle-missing-data-in-a-dataset","title":"How do you handle missing data in a dataset?","text":"<p>Missing data can be handled by:</p> <ul> <li>Removing missing values: Using <code>dropna()</code> to remove rows or columns with missing values.</li> <li>Imputing missing values: Using <code>fillna()</code> to replace missing values with a specific value, mean, median, or mode.</li> <li>Interpolate missing values: Using <code>interpolate()</code> to estimate missing values based on other data points.</li> </ul>"},{"location":"faqs/#what-is-the-difference-between-numpy-arrays-and-python-lists","title":"What is the difference between NumPy arrays and Python lists?","text":"<p>NumPy arrays are fixed-size, homogeneous collections of elements (all of the same data type) optimized for numerical computations. Python lists are dynamic, heterogeneous collections that can contain elements of different data types. NumPy arrays offer better performance for mathematical operations.</p>"},{"location":"faqs/#how-do-you-select-a-subset-of-data-from-a-dataframe","title":"How do you select a subset of data from a DataFrame?","text":"<p>You can select subsets using two methods:</p> <ol> <li>Label-based indexing</li> <li> <p>Integer-based indexing</p> </li> <li> <p>Label-based indexing with <code>.loc</code>:</p> </li> </ol> <pre><code>df_subset = df.loc[row_labels, column_labels]\n</code></pre> <ul> <li>Integer-based indexing with <code>.iloc</code>:</li> </ul> <pre><code>df_subset = df.iloc[row_indices, column_indices]\n</code></pre>"},{"location":"faqs/#what-is-data-visualization-and-why-is-it-important","title":"What is data visualization, and why is it important?","text":"<p>Data visualization is the graphical representation of data to communicate information clearly and efficiently. It is important because it helps identify patterns, trends, and outliers in data, making complex data more accessible and understandable.</p>"},{"location":"faqs/#how-do-you-create-a-simple-line-plot-using-matplotlib","title":"How do you create a simple line plot using Matplotlib?","text":"<pre><code>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4]\ny = [10, 20, 25, 30]\n\nplt.plot(x, y)\nplt.xlabel('X-axis Label')\nplt.ylabel('Y-axis Label')\nplt.title('Simple Line Plot')\nplt.show()\n</code></pre>"},{"location":"faqs/#what-is-the-purpose-of-the-groupby-function-in-pandas","title":"What is the purpose of the <code>groupby()</code> function in Pandas?","text":"<p>The <code>groupby()</code> function is used to split data into groups based on some criteria, perform operations on each group independently, and then combine the results. It is useful for aggregation, transformation, and filtration of data.</p>"},{"location":"faqs/#how-do-you-merge-two-dataframes-in-pandas","title":"How do you merge two DataFrames in Pandas?","text":"<p>You can merge two DataFrames using the <code>merge()</code> function:</p> <pre><code>merged_df = pd.merge(df1, df2, on='common_column')\n</code></pre> <p>Replace <code>'common_column'</code> with the column name that is common to both DataFrames.</p>"},{"location":"faqs/#what-is-the-difference-between-merge-and-concat-in-pandas","title":"What is the difference between <code>merge()</code> and <code>concat()</code> in Pandas?","text":"<ul> <li><code>merge()</code>: Combines two DataFrames based on the values of common columns (similar to SQL joins).</li> <li><code>concat()</code>: Concatenates DataFrames either vertically or horizontally, stacking them along an axis.</li> </ul>"},{"location":"faqs/#how-do-you-calculate-basic-statistical-measures-like-mean-and-median-in-pandas","title":"How do you calculate basic statistical measures like mean and median in Pandas?","text":"<p>You can use built-in functions:</p> <ul> <li>Mean:</li> </ul> <pre><code>mean_value = df['column_name'].mean()\n</code></pre> <ul> <li>Median:</li> </ul> <pre><code>median_value = df['column_name'].median()\n</code></pre>"},{"location":"faqs/#what-is-the-purpose-of-the-apply-function-in-pandas","title":"What is the purpose of the <code>apply()</code> function in Pandas?","text":"<p>The <code>apply()</code> function allows you to apply a function along an axis of the DataFrame (either rows or columns). It is useful for performing complex operations on DataFrame elements.</p>"},{"location":"faqs/#how-do-you-create-a-pivot-table-in-pandas","title":"How do you create a pivot table in Pandas?","text":"<p>You can create a pivot table using the <code>pivot_table()</code> function:</p> <pre><code>pivot = pd.pivot_table(df, values='value_column', index='index_column', columns='columns_column', aggfunc='mean')\n</code></pre>"},{"location":"faqs/#what-is-the-difference-between-supervised-and-unsupervised-learning","title":"What is the difference between supervised and unsupervised learning?","text":"<ul> <li>Supervised Learning: Involves training a model on labeled data, where the target outcome is known. Examples include regression and classification.</li> <li>Unsupervised Learning: Involves finding patterns in unlabeled data without predefined outcomes. Examples include clustering and dimensionality reduction.</li> </ul>"},{"location":"faqs/#how-do-you-perform-linear-regression-using-scikit-learn","title":"How do you perform linear regression using scikit-learn?","text":"<pre><code>from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n</code></pre>"},{"location":"faqs/#what-is-overfitting-in-machine-learning","title":"What is overfitting in machine learning?","text":"<p>Overfitting occurs when a model learns the training data too well, including its noise and outliers, resulting in poor generalization to new, unseen data. It performs well on training data but poorly on test data.</p>"},{"location":"faqs/#how-can-you-prevent-overfitting","title":"How can you prevent overfitting?","text":"<p>Overfitting can be prevented by:</p> <ul> <li>Cross-validation: Splitting data into training and validation sets.</li> <li>Regularization: Adding penalties for complex models (e.g., Lasso, Ridge).</li> <li>Simplifying the model: Reducing the number of features.</li> <li>Early stopping: Halting training when performance on a validation set starts to degrade.</li> </ul>"},{"location":"faqs/#what-is-cross-validation","title":"What is cross-validation?","text":"<p>Cross-validation is a technique for assessing how a model will generalize to an independent dataset. It involves partitioning the data into subsets, training the model on some subsets, and validating it on the remaining ones.</p>"},{"location":"faqs/#how-do-you-evaluate-the-performance-of-a-regression-model","title":"How do you evaluate the performance of a regression model?","text":"<p>Common metrics include:</p> <ul> <li>Mean Absolute Error (MAE)</li> <li>Mean Squared Error (MSE)</li> <li>Root Mean Squared Error (RMSE)</li> <li>R-squared (Coefficient of Determination)</li> </ul>"},{"location":"faqs/#what-is-the-purpose-of-feature-scaling","title":"What is the purpose of feature scaling?","text":"<p>Feature scaling standardizes the range of independent variables, improving the performance and convergence speed of some machine learning algorithms that are sensitive to the scale of data, such as gradient descent optimization.</p>"},{"location":"faqs/#how-do-you-perform-feature-scaling-in-python","title":"How do you perform feature scaling in Python?","text":"<p>Using scikit-learn's <code>StandardScaler</code>:</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\n</code></pre>"},{"location":"faqs/#what-is-one-hot-encoding","title":"What is one-hot encoding?","text":"<p>One-hot encoding is a process of converting categorical variables into a binary (0 or 1) representation. Each category becomes a new column, and a value of 1 indicates the presence of that category.</p>"},{"location":"faqs/#how-do-you-perform-one-hot-encoding-in-pandas","title":"How do you perform one-hot encoding in Pandas?","text":"<p>Using the <code>get_dummies()</code> function:</p> <pre><code>encoded_df = pd.get_dummies(df, columns=['categorical_column'])\n</code></pre>"},{"location":"faqs/#what-is-a-confusion-matrix","title":"What is a confusion matrix?","text":"<p>A confusion matrix is a table used to evaluate the performance of a classification model. It displays the true positives, true negatives, false positives, and false negatives, providing insight into the types of errors made by the model.</p>"},{"location":"faqs/#how-do-you-calculate-accuracy-precision-and-recall-from-a-confusion-matrix","title":"How do you calculate accuracy, precision, and recall from a confusion matrix?","text":"<ul> <li>Accuracy: (TP + TN) / (TP + TN + FP + FN)</li> <li>Precision: TP / (TP + FP)</li> <li>Recall: TP / (TP + FN)</li> </ul> <p>where:</p> <ul> <li>TP=True Positives</li> <li>TN=True Negatives</li> <li>FP=False Positives</li> <li>FN=False Negatives.</li> </ul>"},{"location":"faqs/#what-is-the-purpose-of-the-train_test_split-function","title":"What is the purpose of the <code>train_test_split</code> function?","text":"<p>The <code>train_test_split</code> function splits a dataset into training and testing sets, allowing you to train the model on one subset and evaluate its performance on another to prevent overfitting.</p>"},{"location":"faqs/#how-do-you-split-data-into-training-and-testing-sets-in-scikit-learn","title":"How do you split data into training and testing sets in scikit-learn?","text":"<pre><code>from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n</code></pre>"},{"location":"faqs/#what-is-the-difference-between-classification-and-regression","title":"What is the difference between classification and regression?","text":"<ul> <li>Classification: Predicts categorical labels or classes.</li> <li>Regression: Predicts continuous numerical values.</li> </ul>"},{"location":"faqs/#how-do-you-handle-categorical-variables-in-machine-learning-models","title":"How do you handle categorical variables in machine learning models?","text":"<p>Categorical variables can be handled by:</p> <ul> <li>Label Encoding: Assigning a unique integer to each category.</li> <li>One-Hot Encoding: Creating binary columns for each category.</li> </ul>"},{"location":"faqs/#what-is-k-means-clustering","title":"What is k-means clustering?","text":"<p>K-means clustering is an unsupervised learning algorithm that partitions data into k clusters, where each data point belongs to the cluster with the nearest mean. It aims to minimize the within-cluster sum of squares.</p>"},{"location":"faqs/#how-do-you-determine-the-optimal-number-of-clusters-in-k-means","title":"How do you determine the optimal number of clusters in k-means?","text":"<p>Common methods include:</p> <ul> <li>Elbow Method: Plotting the explained variance as a function of the number of clusters and looking for an \"elbow\" point.</li> <li>Silhouette Score: Measuring how similar a data point is to its own cluster compared to other clusters.</li> </ul>"},{"location":"faqs/#what-is-principal-component-analysis-pca","title":"What is principal component analysis (PCA)?","text":"<p>PCA is a dimensionality reduction technique that transforms a large set of variables into a smaller one that still contains most of the information by identifying the principal components (directions of maximum variance).</p>"},{"location":"faqs/#how-do-you-perform-pca-in-scikit-learn","title":"How do you perform PCA in scikit-learn?","text":"<pre><code>from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(data)\n</code></pre>"},{"location":"faqs/#what-is-the-bias-variance-tradeoff","title":"What is the bias-variance tradeoff?","text":"<p>The bias-variance tradeoff is the balance between a model's ability to generalize to new data (low variance) and its accuracy on training data (low bias). High bias can lead to underfitting, while high variance can lead to overfitting.</p>"},{"location":"faqs/#what-is-regularization-in-machine-learning","title":"What is regularization in machine learning?","text":"<p>Regularization involves adding a penalty term to the loss function to prevent overfitting by discouraging complex models. Common regularization techniques include Lasso (L1) and Ridge (L2) regression.</p>"},{"location":"faqs/#how-do-you-implement-ridge-regression-in-scikit-learn","title":"How do you implement Ridge regression in scikit-learn?","text":"<pre><code>from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=1.0)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"faqs/#what-is-logistic-regression","title":"What is logistic regression?","text":"<p>Logistic regression is a classification algorithm used to predict binary outcomes (0 or 1) by modeling the probability of a certain class using a logistic function.</p>"},{"location":"faqs/#how-do-you-evaluate-the-performance-of-a-classification-model","title":"How do you evaluate the performance of a classification model?","text":"<p>Common metrics include:</p> <ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1 Score</li> <li>ROC AUC Score</li> </ul>"},{"location":"faqs/#what-is-the-receiver-operating-characteristic-roc-curve","title":"What is the Receiver Operating Characteristic (ROC) curve?","text":"<p>The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1 - specificity) at various threshold settings. It illustrates the diagnostic ability of a binary classifier.</p>"},{"location":"faqs/#how-do-you-handle-imbalanced-datasets","title":"How do you handle imbalanced datasets?","text":"<p>Techniques include:</p> <ul> <li>Resampling Methods: Oversampling the minority class or undersampling the majority class.</li> <li>Synthetic Data Generation: Using methods like SMOTE to generate synthetic examples.</li> <li>Using Appropriate Evaluation Metrics: Focusing on precision, recall, or F1 score instead of accuracy.</li> </ul>"},{"location":"faqs/#what-is-time-series-analysis","title":"What is time series analysis?","text":"<p>Time series analysis involves analyzing data points collected or recorded at specific time intervals to identify trends, cycles, and seasonal variations for forecasting and other purposes.</p>"},{"location":"faqs/#how-do-you-deal-with-date-and-time-data-in-pandas","title":"How do you deal with date and time data in Pandas?","text":"<p>Pandas provides the <code>to_datetime()</code> function to convert strings to datetime objects, and you can use datetime properties and methods to manipulate date and time data.</p> <pre><code>df['date_column'] = pd.to_datetime(df['date_column'])\n</code></pre>"},{"location":"faqs/#what-is-autocorrelation-in-time-series-data","title":"What is autocorrelation in time series data?","text":"<p>Autocorrelation is the correlation of a signal with a delayed copy of itself. In time series data, it measures the relationship between a variable's current value and its past values.</p>"},{"location":"faqs/#how-do-you-perform-forecasting-using-arima-models","title":"How do you perform forecasting using ARIMA models?","text":"<p>Using the <code>statsmodels</code> library:</p> <pre><code>from statsmodels.tsa.arima.model import ARIMA\n\nmodel = ARIMA(time_series_data, order=(p, d, q))\nmodel_fit = model.fit()\nforecast = model_fit.forecast(steps=10)\n</code></pre>"},{"location":"faqs/#what-is-natural-language-processing-nlp","title":"What is natural language processing (NLP)?","text":"<p>NLP is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language, enabling machines to understand, interpret, and generate human language.</p>"},{"location":"faqs/#how-do-you-perform-text-preprocessing-in-nlp","title":"How do you perform text preprocessing in NLP?","text":"<p>Common steps include:</p> <ul> <li>Tokenization: Splitting text into words or sentences.</li> <li>Stop Word Removal: Removing common words that add little meaning.</li> <li>Stemming/Lemmatization: Reducing words to their base or root form.</li> <li>Encoding: Converting text to numerical representation using methods like TF-IDF or word embeddings.</li> </ul>"},{"location":"faqs/#what-is-tf-idf","title":"What is TF-IDF?","text":"<p>Term Frequency-Inverse Document Frequency (TF-IDF) is a numerical statistic that reflects how important a word is to a document in a collection. It balances the frequency of a word in a document with how common the word is across all documents.</p>"},{"location":"faqs/#how-do-you-handle-large-datasets-that-dont-fit-into-memory","title":"How do you handle large datasets that don't fit into memory?","text":"<p>Techniques include:</p> <ul> <li>Data Sampling: Working with a subset of the data.</li> <li>Batch Processing: Processing data in chunks.</li> <li>Distributed Computing: Using tools like Apache Spark.</li> <li>Out-of-core Learning: Using algorithms that can learn from data incrementally.</li> </ul>"},{"location":"faqs/#what-is-a-pipeline-in-scikit-learn","title":"What is a pipeline in scikit-learn?","text":"<p>A pipeline is a sequence of data processing steps assembled into a single object. It ensures that all steps are applied consistently during training and testing, simplifying the workflow.</p> <pre><code>from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('model', LinearRegression())\n])\n</code></pre>"},{"location":"faqs/#how-do-you-save-and-load-trained-models-in-scikit-learn","title":"How do you save and load trained models in scikit-learn?","text":"<p>Using the <code>joblib</code> library:</p> <pre><code>import joblib\n\n# Save model\njoblib.dump(model, 'model.pkl')\n\n# Load model\nmodel = joblib.load('model.pkl')\n</code></pre>"},{"location":"faqs/#what-is-gradient-descent","title":"What is gradient descent?","text":"<p>Gradient descent is an optimization algorithm used to minimize the cost function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient.</p>"},{"location":"faqs/#what-is-the-difference-between-batch-stochastic-and-mini-batch-gradient-descent","title":"What is the difference between batch, stochastic, and mini-batch gradient descent?","text":"<ul> <li>Batch Gradient Descent: Uses the entire dataset to compute gradients.</li> <li>Stochastic Gradient Descent (SGD): Uses one sample at a time.</li> <li>Mini-Batch Gradient Descent: Uses a small subset (batch) of the data.</li> </ul>"},{"location":"faqs/#how-do-you-handle-multicollinearity-in-regression-analysis","title":"How do you handle multicollinearity in regression analysis?","text":"<p>Techniques include:</p> <ul> <li>Removing correlated features.</li> <li>Principal Component Analysis (PCA) to reduce dimensionality.</li> <li>Regularization methods like Ridge regression.</li> </ul>"},{"location":"faqs/#what-is-the-central-limit-theorem","title":"What is the Central Limit Theorem?","text":"<p>The Central Limit Theorem states that the sampling distribution of the sample means approaches a normal distribution as the sample size becomes large, regardless of the population's distribution.</p>"},{"location":"faqs/#what-is-hypothesis-testing","title":"What is hypothesis testing?","text":"<p>Hypothesis testing is a statistical method used to decide whether there is enough evidence to reject a null hypothesis in favor of an alternative hypothesis based on sample data.</p>"},{"location":"faqs/#what-is-p-value","title":"What is p-value?","text":"<p>A p-value is the probability of observing results at least as extreme as those measured when the null hypothesis is true. A low p-value indicates that the observed data is unlikely under the null hypothesis.</p>"},{"location":"faqs/#how-do-you-perform-a-t-test-in-python","title":"How do you perform a t-test in Python?","text":"<p>Using <code>scipy.stats</code>:</p> <pre><code>from scipy import stats\n\nt_statistic, p_value = stats.ttest_ind(sample1, sample2)\n</code></pre>"},{"location":"faqs/#what-is-the-difference-between-type-i-and-type-ii-errors","title":"What is the difference between Type I and Type II errors?","text":"<ul> <li>Type I Error: Rejecting a true null hypothesis (false positive).</li> <li>Type II Error: Failing to reject a false null hypothesis (false negative).</li> </ul>"},{"location":"faqs/#what-is-an-anova-test","title":"What is an ANOVA test?","text":"<p>Analysis of Variance (ANOVA) is a statistical method used to compare means across three or more groups to see if at least one mean is different from the others.</p>"},{"location":"faqs/#how-do-you-perform-an-anova-test-in-python","title":"How do you perform an ANOVA test in Python?","text":"<p>Using <code>scipy.stats</code>:</p> <pre><code>from scipy import stats\n\nf_statistic, p_value = stats.f_oneway(group1, group2, group3)\n</code></pre>"},{"location":"faqs/#what-is-bootstrapping-in-statistics","title":"What is bootstrapping in statistics?","text":"<p>Bootstrapping is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It allows estimation of the sampling distribution of almost any statistic.</p>"},{"location":"faqs/#what-is-the-law-of-large-numbers","title":"What is the law of large numbers?","text":"<p>The law of large numbers states that as the number of trials increases, the sample mean will converge to the expected value (population mean).</p>"},{"location":"faqs/#what-is-a-probability-distribution","title":"What is a probability distribution?","text":"<p>A probability distribution describes how the values of a random variable are distributed. It defines the probabilities of different outcomes.</p>"},{"location":"faqs/#what-are-common-probability-distributions-used-in-data-science","title":"What are common probability distributions used in data science?","text":"<ul> <li>Normal Distribution</li> <li>Binomial Distribution</li> <li>Poisson Distribution</li> <li>Exponential Distribution</li> </ul>"},{"location":"faqs/#how-do-you-generate-random-numbers-following-a-normal-distribution-in-numpy","title":"How do you generate random numbers following a normal distribution in NumPy?","text":"<pre><code>import numpy as np\n\nrandom_numbers = np.random.normal(loc=mean, scale=std_dev, size=num_samples)\n</code></pre>"},{"location":"faqs/#what-is-the-curse-of-dimensionality","title":"What is the curse of dimensionality?","text":"<p>The curse of dimensionality refers to various phenomena that arise when analyzing data in high-dimensional spaces, often leading to challenges like overfitting and increased computational cost.</p>"},{"location":"faqs/#how-do-you-reduce-dimensionality","title":"How do you reduce dimensionality?","text":"<p>Techniques include:</p> <ul> <li>Feature Selection: Choosing a subset of relevant features.</li> <li>Feature Extraction: Transforming data into a lower-dimensional space (e.g., PCA).</li> </ul>"},{"location":"faqs/#what-is-the-difference-between-bagging-and-boosting","title":"What is the difference between bagging and boosting?","text":"<ul> <li>Bagging: Combines multiple models (usually of the same type) trained on different subsets of the data to reduce variance.</li> <li>Boosting: Sequentially trains models, where each new model focuses on correcting errors made by previous ones, reducing bias.</li> </ul>"},{"location":"faqs/#what-is-a-decision-tree","title":"What is a decision tree?","text":"<p>A decision tree is a flowchart-like structure used for classification and regression that splits data into branches based on feature values to make predictions.</p>"},{"location":"faqs/#how-do-you-prevent-a-decision-tree-from-overfitting","title":"How do you prevent a decision tree from overfitting?","text":"<p>By:</p> <ul> <li>Pruning: Removing branches that have little power in predicting target variables.</li> <li>Setting a maximum depth: Limiting the depth of the tree.</li> <li>Setting a minimum number of samples per leaf.</li> </ul>"},{"location":"faqs/#what-is-random-forest","title":"What is random forest?","text":"<p>Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees.</p>"},{"location":"faqs/#how-do-you-implement-a-random-forest-classifier-in-scikit-learn","title":"How do you implement a random forest classifier in scikit-learn?","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"faqs/#what-is-ensemble-learning","title":"What is ensemble learning?","text":"<p>Ensemble learning combines predictions from multiple machine learning algorithms to produce a more accurate prediction than any individual model.</p>"},{"location":"faqs/#what-is-a-neural-network","title":"What is a neural network?","text":"<p>A neural network is a computational model inspired by the human brain, consisting of layers of interconnected nodes (neurons) that can learn complex patterns through training.</p>"},{"location":"faqs/#what-is-the-difference-between-deep-learning-and-machine-learning","title":"What is the difference between deep learning and machine learning?","text":"<ul> <li>Machine Learning: Involves algorithms that parse data, learn from it, and make decisions.</li> <li>Deep Learning: A subset of machine learning using neural networks with multiple layers to model complex patterns.</li> </ul>"},{"location":"faqs/#how-do-you-handle-class-imbalance-in-classification-problems","title":"How do you handle class imbalance in classification problems?","text":"<p>By:</p> <ul> <li>Resampling the dataset: Oversampling the minority class or undersampling the majority class.</li> <li>Using appropriate evaluation metrics: Such as ROC AUC, precision-recall curve.</li> <li>Using algorithms that handle imbalance: Like XGBoost.</li> </ul>"},{"location":"faqs/#what-is-the-purpose-of-the-map-function-in-pandas","title":"What is the purpose of the <code>map()</code> function in Pandas?","text":"<p>The <code>map()</code> function is used to map values of a Series according to an input mapping or function, useful for substituting values or applying a function element-wise.</p>"},{"location":"faqs/#how-do-you-sort-a-dataframe-in-pandas","title":"How do you sort a DataFrame in Pandas?","text":"<p>Using the <code>sort_values()</code> function:</p> <pre><code>sorted_df = df.sort_values(by='column_name', ascending=True)\n</code></pre>"},{"location":"faqs/#what-is-the-difference-between-apply-and-applymap-in-pandas","title":"What is the difference between <code>apply()</code> and <code>applymap()</code> in Pandas?","text":"<ul> <li><code>apply()</code>: Applies a function along an axis of the DataFrame (rows or columns).</li> <li><code>applymap()</code>: Applies a function element-wise to the entire DataFrame.</li> </ul>"},{"location":"faqs/#how-do-you-remove-duplicates-from-a-dataframe","title":"How do you remove duplicates from a DataFrame?","text":"<p>Using the <code>drop_duplicates()</code> function:</p> <pre><code>df_unique = df.drop_duplicates()\n</code></pre>"},{"location":"faqs/#what-is-an-outlier-and-how-do-you-detect-them","title":"What is an outlier, and how do you detect them?","text":"<p>An outlier is a data point significantly different from others. Detection methods include:</p> <ul> <li>Statistical methods: Using Z-scores or IQR.</li> <li>Visualization: Box plots or scatter plots.</li> </ul>"},{"location":"faqs/#how-do-you-handle-outliers-in-data","title":"How do you handle outliers in data?","text":"<p>By:</p> <ul> <li>Removing them: If they are errors.</li> <li>Transforming data: Using log or square root transformations.</li> <li>Using robust algorithms: That are less sensitive to outliers.</li> </ul>"},{"location":"faqs/#what-is-data-normalization","title":"What is data normalization?","text":"<p>Data normalization scales numerical data into a specific range, typically [0,1], ensuring that each feature contributes equally to the analysis.</p>"},{"location":"faqs/#how-do-you-perform-data-normalization-in-scikit-learn","title":"How do you perform data normalization in scikit-learn?","text":"<p>Using <code>MinMaxScaler</code>:</p> <pre><code>from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_data = scaler.fit_transform(data)\n</code></pre>"},{"location":"faqs/#what-is-a-heatmap-and-when-do-you-use-it","title":"What is a heatmap, and when do you use it?","text":"<p>A heatmap is a graphical representation of data where individual values are represented as colors. It is used to visualize correlation matrices or to display patterns in data.</p>"},{"location":"faqs/#how-do-you-create-a-heatmap-in-seaborn","title":"How do you create a heatmap in Seaborn?","text":"<pre><code>import seaborn as sns\n\nsns.heatmap(data, annot=True)\n</code></pre>"},{"location":"faqs/#what-is-a-pairplot-in-seaborn","title":"What is a pairplot in Seaborn?","text":"<p>A pairplot creates a grid of Axes such that each variable in the data is shared across the y-axes across a single row and the x-axes across a single column, visualizing pairwise relationships.</p> <pre><code>sns.pairplot(df)\n</code></pre>"},{"location":"faqs/#how-do-you-interpret-a-correlation-coefficient","title":"How do you interpret a correlation coefficient?","text":"<p>A correlation coefficient measures the strength and direction of a linear relationship between two variables. Values range from -1 to 1:</p> <ul> <li>-1: Perfect negative correlation.</li> <li>0: No correlation.</li> <li>1: Perfect positive correlation.</li> </ul>"},{"location":"faqs/#what-is-the-purpose-of-the-describe-function-in-pandas","title":"What is the purpose of the <code>describe()</code> function in Pandas?","text":"<p>The <code>describe()</code> function generates descriptive statistics, including count, mean, standard deviation, min, max, and quartile values for numerical columns.</p>"},{"location":"faqs/#how-do-you-handle-datetime-features-for-machine-learning-models","title":"How do you handle date/time features for machine learning models?","text":"<p>By extracting meaningful components:</p> <ul> <li>Year, Month, Day</li> <li>Weekday</li> <li>Hour, Minute, Second</li> <li>Time since a specific date</li> </ul>"},{"location":"faqs/#what-is-the-difference-between-loc-and-iloc-in-pandas","title":"What is the difference between <code>.loc</code> and <code>.iloc</code> in Pandas?","text":"<ul> <li><code>.loc</code>: Label-based indexing to select data by row and column labels.</li> <li><code>.iloc</code>: Integer-based indexing to select data by row and column positions.</li> </ul>"},{"location":"faqs/#how-do-you-rename-columns-in-a-dataframe","title":"How do you rename columns in a DataFrame?","text":"<p>Using the <code>rename()</code> function:</p> <pre><code>df.rename(columns={'old_name': 'new_name'}, inplace=True)\n</code></pre>"},{"location":"faqs/#what-is-the-purpose-of-the-astype-function-in-pandas","title":"What is the purpose of the <code>astype()</code> function in Pandas?","text":"<p>The <code>astype()</code> function is used to change the data type of a Series or DataFrame columns.</p> <pre><code>df['column_name'] = df['column_name'].astype('float')\n</code></pre>"},{"location":"faqs/#how-do-you-detect-missing-values-in-a-dataframe","title":"How do you detect missing values in a DataFrame?","text":"<p>Using <code>isnull()</code> or <code>isna()</code> functions:</p> <pre><code>missing_values = df.isnull().sum()\n</code></pre>"},{"location":"faqs/#what-is-an-ensemble-method-in-machine-learning","title":"What is an ensemble method in machine learning?","text":"<p>An ensemble method combines predictions from multiple machine learning models to improve performance over a single model. Examples include Random Forest, Gradient Boosting.</p>"},{"location":"faqs/#how-do-you-implement-gradient-boosting-in-scikit-learn","title":"How do you implement Gradient Boosting in scikit-learn?","text":"<pre><code>from sklearn.ensemble import GradientBoostingClassifier\n\nmodel = GradientBoostingClassifier()\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"faqs/#what-is-xgboost","title":"What is XGBoost?","text":"<p>XGBoost (Extreme Gradient Boosting) is an optimized gradient boosting library designed to be highly efficient, flexible, and portable, widely used for its performance and speed.</p>"},{"location":"faqs/#how-do-you-install-and-use-xgboost-in-python","title":"How do you install and use XGBoost in Python?","text":"<p>Install using pip:</p> <pre><code>bash\npip install xgboost\n</code></pre> <p>Use in code:</p> <pre><code>import xgboost as xgb\n\nmodel = xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"faqs/#what-is-cross-entropy-loss","title":"What is cross-entropy loss?","text":"<p>Cross-entropy loss measures the performance of a classification model whose output is a probability between 0 and 1. It increases as the predicted probability diverges from the actual label.</p>"},{"location":"faqs/#how-do-you-calculate-the-learning-rate-in-gradient-descent","title":"How do you calculate the learning rate in gradient descent?","text":"<p>The learning rate is a hyperparameter that you set manually. It determines the step size at each iteration while moving toward a minimum of a loss function.</p>"},{"location":"faqs/#what-is-the-difference-between-epochs-batches-and-iterations","title":"What is the difference between epochs, batches, and iterations?","text":"<ul> <li>Epoch: One complete pass through the entire training dataset.</li> <li>Batch: A subset of the training data used in one iteration.</li> <li>Iteration: One update of the model's parameters.</li> </ul>"},{"location":"faqs/#how-do-you-perform-hyperparameter-tuning","title":"How do you perform hyperparameter tuning?","text":"<p>By:</p> <ul> <li>Grid Search: Exhaustively searching through a specified subset of hyperparameters.</li> <li>Random Search: Randomly sampling hyperparameter combinations.</li> <li>Bayesian Optimization: Using probabilistic models to select hyperparameters.</li> </ul>"},{"location":"faqs/#what-is-the-purpose-of-the-pipeline-module-in-scikit-learn","title":"What is the purpose of the <code>pipeline</code> module in scikit-learn?","text":"<p>It allows you to chain preprocessing steps and estimators in a sequential manner, ensuring consistent application of transformations during training and testing.</p>"},{"location":"faqs/#how-do-you-evaluate-a-clustering-algorithm","title":"How do you evaluate a clustering algorithm?","text":"<p>Using metrics like:</p> <ul> <li>Silhouette Score</li> <li>Calinski-Harabasz Index</li> <li>Davies-Bouldin Index</li> </ul>"},{"location":"faqs/#what-is-a-dummy-variable-trap","title":"What is a dummy variable trap?","text":"<p>The dummy variable trap occurs when multicollinearity is introduced in a regression model due to the inclusion of dummy variables that are linearly dependent. It can be avoided by dropping one dummy variable.</p>"},{"location":"faqs/#how-do-you-create-a-correlation-matrix-in-pandas","title":"How do you create a correlation matrix in Pandas?","text":"<pre><code>corr_matrix = df.corr()\n</code></pre>"},{"location":"faqs/#what-is-an-roc-curve-and-how-do-you-plot-it","title":"What is an ROC curve, and how do you plot it?","text":"<p>An ROC (Receiver Operating Characteristic) curve plots the true positive rate against the false positive rate at various threshold settings. You can plot it using scikit-learn:</p> <pre><code>from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_scores)\nplt.plot(fpr, tpr)\n</code></pre>"},{"location":"faqs/#what-is-a-type-i-error","title":"What is a type I error?","text":"<p>A type I error occurs when the null hypothesis is true, but we incorrectly reject it (false positive).</p>"},{"location":"faqs/#what-is-a-type-ii-error","title":"What is a type II error?","text":"<p>A type II error occurs when the null hypothesis is false, but we fail to reject it (false negative).</p>"},{"location":"faqs/#how-do-you-calculate-the-p-value-in-a-hypothesis-test","title":"How do you calculate the p-value in a hypothesis test?","text":"<p>Using statistical tests from libraries like <code>scipy.stats</code>, which return the p-value as part of the output.</p>"},{"location":"faqs/#what-is-the-difference-between-parametric-and-non-parametric-tests","title":"What is the difference between parametric and non-parametric tests?","text":"<ul> <li>Parametric Tests: Assume underlying statistical distributions (e.g., t-test).</li> <li>Non-Parametric Tests: Do not assume any specific distribution (e.g., Mann-Whitney U test).</li> </ul>"},{"location":"faqs/#how-do-you-perform-a-chi-squared-test-in-python","title":"How do you perform a chi-squared test in Python?","text":"<p>Using <code>scipy.stats</code>:</p> <pre><code>from scipy.stats import chi2_contingency\n\nchi2, p, dof, expected = chi2_contingency(observed_values)\n</code></pre>"},{"location":"faqs/#what-is-the-purpose-of-the-seaborn-library","title":"What is the purpose of the <code>seaborn</code> library?","text":"<p>Seaborn is a Python data visualization library based on Matplotlib that provides a high-level interface for drawing attractive statistical graphics.</p>"},{"location":"faqs/#how-do-you-create-a-box-plot-in-seaborn","title":"How do you create a box plot in Seaborn?","text":"<pre><code>import seaborn as sns\n\nsns.boxplot(x='categorical_column', y='numerical_column', data=df)\n</code></pre>"},{"location":"faqs/#what-is-a-violin-plot","title":"What is a violin plot?","text":"<p>A violin plot combines a box plot and a kernel density plot to provide a richer depiction of the data distribution.</p>"},{"location":"faqs/#how-do-you-handle-multivariate-time-series-data","title":"How do you handle multivariate time series data?","text":"<p>By:</p> <ul> <li>Using models designed for multivariate data: Like VAR (Vector Autoregression).</li> <li>Feature engineering: Creating lag features for each variable.</li> </ul>"},{"location":"faqs/#what-is-an-ab-test","title":"What is an A/B test?","text":"<p>An A/B test is an experiment comparing two variants (A and B) to determine which one performs better regarding a specific metric.</p>"},{"location":"faqs/#how-do-you-analyze-ab-test-results","title":"How do you analyze A/B test results?","text":"<p>By:</p> <ul> <li>Calculating the difference in metrics between groups.</li> <li>Performing statistical tests: Like t-tests or chi-squared tests.</li> <li>Checking for statistical significance: Using p-values and confidence intervals.</li> </ul>"},{"location":"faqs/#what-is-the-bonferroni-correction","title":"What is the Bonferroni correction?","text":"<p>A method to adjust p-values when multiple comparisons are made to reduce the chances of obtaining false-positive results (Type I errors).</p>"},{"location":"faqs/#what-is-survivorship-bias","title":"What is survivorship bias?","text":"<p>Survivorship bias occurs when analyses are conducted only on surviving subjects, leading to skewed results due to the overlooking of those that did not survive or were not included.</p>"},{"location":"faqs/#what-is-data-leakage","title":"What is data leakage?","text":"<p>Data leakage occurs when information from outside the training dataset is used to create the model, leading to overly optimistic performance estimates that won't generalize to new data.</p>"},{"location":"faqs/#how-do-you-prevent-data-leakage","title":"How do you prevent data leakage?","text":"<p>By:</p> <ul> <li>Separating training and testing data properly.</li> <li>Performing data preprocessing steps within cross-validation.</li> <li>Avoiding using future data in model training.</li> </ul>"},{"location":"faqs/#what-is-a-hash-table","title":"What is a hash table?","text":"<p>A hash table is a data structure that implements an associative array, mapping keys to values using a hash function to compute an index into an array of buckets.</p>"},{"location":"faqs/#what-is-memoization","title":"What is memoization?","text":"<p>Memoization is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again.</p>"},{"location":"faqs/#how-do-you-reverse-a-linked-list","title":"How do you reverse a linked list?","text":"<p>By iterating through the list and reversing the pointers of each node to point to the previous node.</p>"},{"location":"faqs/#what-is-the-time-complexity-of-quicksort","title":"What is the time complexity of quicksort?","text":"<p>The average time complexity is O(n log n), while the worst-case is O(n^2).</p>"},{"location":"faqs/#what-is-a-generator-in-python","title":"What is a generator in Python?","text":"<p>A generator is a special type of function that returns an iterator object which can iterate over a sequence of values. It uses the <code>yield</code> keyword.</p> <pre><code>def my_generator():\n    yield value\n</code></pre>"},{"location":"faqs/#how-do-you-handle-exceptions-in-python","title":"How do you handle exceptions in Python?","text":"<p>Using try-except blocks:</p> <pre><code>try:\n    # Code that may raise an exception\nexcept ExceptionType as e:\n    # Code to handle the exception\n</code></pre>"},{"location":"faqs/#what-is-a-decorator-in-python","title":"What is a decorator in Python?","text":"<p>A decorator is a function that modifies the behavior of another function or method. It allows for the addition of functionality to existing code in a modular way.</p> <pre><code>def decorator_function(func):\n    def wrapper():\n        # Code before function call\n        func()\n        # Code after function call\n    return wrapper\n</code></pre>"},{"location":"faqs/#how-do-you-read-and-write-json-files-in-python","title":"How do you read and write JSON files in Python?","text":"<p>Using the <code>json</code> module:</p> <pre><code>import json\n\n# Read JSON\nwith open('file.json', 'r') as f:\n    data = json.load(f)\n\n# Write JSON\nwith open('file.json', 'w') as f:\n    json.dump(data, f)\n</code></pre>"},{"location":"faqs/#what-is-multithreading-and-how-do-you-implement-it-in-python","title":"What is multithreading, and how do you implement it in Python?","text":"<p>Multithreading allows concurrent execution of threads (lightweight processes) to improve performance. In Python, you can use the <code>threading</code> module:</p> <pre><code>import threading\n\ndef function_to_run():\n    pass\n\nthread = threading.Thread(target=function_to_run)\nthread.start()\n</code></pre>"},{"location":"faqs/#what-is-the-global-interpreter-lock-gil-in-python","title":"What is the Global Interpreter Lock (GIL) in Python?","text":"<p>The GIL is a mutex that protects access to Python objects, preventing multiple native threads from executing Python bytecodes at once. It simplifies memory management but can limit performance in CPU-bound multi-threaded programs.</p>"},{"location":"faqs/#how-do-you-handle-file-operations-in-python","title":"How do you handle file operations in Python?","text":"<p>Using <code>open()</code>:</p> <pre><code>with open('file.txt', 'r') as file:\n    content = file.read()\n</code></pre>"},{"location":"faqs/#what-are-lambda-functions-in-python","title":"What are lambda functions in Python?","text":"<p>Lambda functions are anonymous functions defined using the <code>lambda</code> keyword, useful for short, simple functions.</p> <pre><code>add = lambda x, y: x + y\n</code></pre>"},{"location":"faqs/#how-do-you-work-with-databases-in-python","title":"How do you work with databases in Python?","text":"<p>By using database connectors and ORMs like:</p> <ul> <li>SQLite: Using <code>sqlite3</code> module.</li> <li>MySQL: Using <code>mysql-connector-python</code>.</li> <li>ORMs: Using libraries like SQLAlchemy.</li> </ul>"},{"location":"faqs/#what-is-the-purpose-of-virtual-environments-in-python","title":"What is the purpose of virtual environments in Python?","text":"<p>Virtual environments allow you to create isolated Python environments with specific packages and dependencies, preventing conflicts between projects.</p> <pre><code>bash\npython -m venv myenv\n</code></pre>"},{"location":"faqs/#how-do-you-install-packages-in-python","title":"How do you install packages in Python?","text":"<p>Using <code>pip</code>:</p> <pre><code>bash\npip install package_name\n</code></pre>"},{"location":"faqs/#what-are-the-common-data-types-in-python","title":"What are the common data types in Python?","text":"<ul> <li>Numeric Types: int, float, complex</li> <li>Sequence Types: list, tuple, range</li> <li>Text Type: str</li> <li>Mapping Type: dict</li> <li>Set Types: set, frozenset</li> <li>Boolean Type: bool</li> </ul>"},{"location":"faqs/#how-do-you-create-a-class-in-python","title":"How do you create a class in Python?","text":"<pre><code>class MyClass:\n    def __init__(self, attribute):\n        self.attribute = attribute\n</code></pre>"},{"location":"faqs/#what-is-inheritance-in-python","title":"What is inheritance in Python?","text":"<p>Inheritance allows a class (child) to inherit attributes and methods from another class (parent), promoting code reusability.</p> <pre><code>class ChildClass(ParentClass):\n    pass\n</code></pre>"},{"location":"faqs/#what-is-polymorphism-in-python","title":"What is polymorphism in Python?","text":"<p>Polymorphism allows methods to have the same name but behave differently in different classes. It enables methods to be used interchangeably.</p> <p>o1</p>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#glossary-of-terms-for-introduction-to-data-science-with-python","title":"Glossary of Terms for Introduction to Data Science with Python","text":""},{"location":"glossary/#ac","title":"A\u2013C","text":""},{"location":"glossary/#accuracy","title":"Accuracy","text":"<p>A metric used to evaluate classification models, representing the proportion of correct predictions over the total number of predictions.</p> <p>Example: In a spam email classifier, if the model correctly identifies 90 out of 100 emails, the accuracy is 90%.</p>"},{"location":"glossary/#algorithm","title":"Algorithm","text":"<p>A step-by-step procedure or set of rules designed to perform a specific task or solve a problem.</p> <p>Example: Implementing the k-means clustering algorithm to group similar data points in an unsupervised learning task.</p>"},{"location":"glossary/#anaconda","title":"Anaconda","text":"<p>A free and open-source distribution of Python and R programming languages for scientific computing and data science.</p> <p>Example: Using Anaconda to manage Python packages and environments for data analysis projects in the course.</p>"},{"location":"glossary/#analytics","title":"Analytics","text":"<p>The process of examining datasets to draw conclusions about the information they contain, often using specialized software and statistical techniques.</p> <p>Example: Performing customer behavior analytics using Pandas and Matplotlib to improve marketing strategies.</p>"},{"location":"glossary/#anomaly-detection","title":"Anomaly Detection","text":"<p>The process of identifying unusual patterns or observations in data that do not conform to expected behavior.</p> <p>Example: Detecting fraudulent credit card transactions using an isolation forest model.</p>"},{"location":"glossary/#api-application-programming-interface","title":"API (Application Programming Interface)","text":"<p>A set of functions and protocols that allows software applications to communicate with each other.</p> <p>Example: Using the OpenWeather API to import real-time temperature data into a Python program.</p>"},{"location":"glossary/#application-layer","title":"Application Layer","text":"<p>The highest level in a computing system that interacts directly with user-facing applications and services.</p> <p>Example: A Python script running in Jupyter Notebook is executed at the application layer.</p>"},{"location":"glossary/#area-under-the-curve-auc","title":"Area Under the Curve (AUC)","text":"<p>A performance metric for classification models that measures the ability to distinguish between classes, calculated from the ROC curve.</p> <p>Example: A model with an AUC of 0.95 is better at distinguishing positive from negative cases than one with 0.70.</p>"},{"location":"glossary/#array","title":"Array","text":"<p>A data structure that stores a collection of items, typically of the same type, at contiguous memory locations.</p> <p>Example: Using NumPy arrays for fast vectorized mathematical computations.</p>"},{"location":"glossary/#artificial-intelligence-ai","title":"Artificial Intelligence (AI)","text":"<p>The field of computer science focused on creating systems capable of performing tasks that normally require human intelligence.</p> <p>Example: Building a neural network to recognize handwritten digits.</p>"},{"location":"glossary/#association-rule-mining","title":"Association Rule Mining","text":"<p>A method for finding relationships between variables in large datasets.</p> <p>Example: Identifying that customers who buy bread often also purchase butter.</p>"},{"location":"glossary/#attribute","title":"Attribute","text":"<p>A property or characteristic of an object, often represented as a column in a dataset.</p> <p>Example: In a dataset of houses, \"number of bedrooms\" is an attribute.</p>"},{"location":"glossary/#autocorrelation","title":"Autocorrelation","text":"<p>A measure of how related a variable is with a lagged version of itself over time.</p> <p>Example: Detecting repeating seasonal patterns in monthly sales data.</p>"},{"location":"glossary/#bagging-bootstrap-aggregating","title":"Bagging (Bootstrap Aggregating)","text":"<p>A machine learning ensemble technique that combines predictions from multiple models trained on different subsets of the data.</p> <p>Example: Using bagging with decision trees to create a random forest classifier.</p>"},{"location":"glossary/#bar-chart","title":"Bar Chart","text":"<p>A visualization that uses rectangular bars to represent data values for different categories.</p> <p>Example: Displaying average exam scores for different majors in a bar chart.</p>"},{"location":"glossary/#baseline-model","title":"Baseline Model","text":"<p>A simple model used as a reference point for comparing the performance of more complex models.</p> <p>Example: Using the mean value of the target variable as predictions to compare against a regression model.</p>"},{"location":"glossary/#batch-processing","title":"Batch Processing","text":"<p>A method of processing large volumes of data in groups instead of in real time.</p> <p>Example: Running a nightly script to clean and aggregate all transaction data from the previous day.</p>"},{"location":"glossary/#bayes-theorem","title":"Bayes\u2019 Theorem","text":"<p>A formula used to update probabilities based on new evidence.</p> <p>Example: Updating the probability of having a disease after a positive test result.</p>"},{"location":"glossary/#bias-in-machine-learning","title":"Bias (in Machine Learning)","text":"<p>The error introduced when a model makes assumptions that oversimplify the problem, potentially leading to underfitting.</p> <p>Example: Using a linear model for a highly non-linear dataset can introduce high bias.</p>"},{"location":"glossary/#bias-variance-tradeoff","title":"Bias-Variance Tradeoff","text":"<p>The balance between underfitting (high bias) and overfitting (high variance) when building predictive models.</p> <p>Example: Choosing a model complexity that minimizes both bias and variance.</p>"},{"location":"glossary/#big-data","title":"Big Data","text":"<p>Extremely large datasets that require specialized storage and processing methods.</p> <p>Example: Analyzing petabytes of social media data for sentiment analysis.</p>"},{"location":"glossary/#bin","title":"Bin","text":"<p>A grouping of continuous numerical values into intervals for analysis or visualization.</p> <p>Example: Grouping ages into bins like 0\u201318, 19\u201335, and 36\u201360 for analysis.</p>"},{"location":"glossary/#binary-classification","title":"Binary Classification","text":"<p>A classification problem with only two possible outcomes.</p> <p>Example: Predicting whether an email is spam or not spam.</p>"},{"location":"glossary/#binary-variable","title":"Binary Variable","text":"<p>A variable with only two possible values, often represented as 0 and 1.</p> <p>Example: \"Passed Exam\" variable coded as 1 for pass and 0 for fail.</p>"},{"location":"glossary/#box-plot","title":"Box Plot","text":"<p>A graphical summary of data distribution showing median, quartiles, and potential outliers.</p> <p>Example: Using a box plot to compare exam scores across different classes.</p>"},{"location":"glossary/#categorical-data","title":"Categorical Data","text":"<p>Data that represents discrete groups or categories.</p> <p>Example: \"Car color\" with values red, blue, or green.</p>"},{"location":"glossary/#causal-relationship","title":"Causal Relationship","text":"<p>A relationship where a change in one variable directly produces a change in another.</p> <p>Example: Increasing advertising budget directly increasing sales.</p>"},{"location":"glossary/#central-limit-theorem-clt","title":"Central Limit Theorem (CLT)","text":"<p>A statistical theory stating that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases.</p> <p>Example: Using the CLT to justify using normal-based confidence intervals.</p>"},{"location":"glossary/#class-in-classification","title":"Class (in Classification)","text":"<p>A label assigned to a group of similar data points in a classification task.</p> <p>Example: \"Cat\" and \"Dog\" are two classes in an animal image classifier.</p>"},{"location":"glossary/#classification","title":"Classification","text":"<p>The process of predicting a categorical label for new observations based on training data.</p> <p>Example: Using logistic regression to classify emails as spam or not spam.</p>"},{"location":"glossary/#classification-report","title":"Classification Report","text":"<p>A summary of a classification model\u2019s performance, including precision, recall, and F1-score.</p> <p>Example: Generating a classification report in scikit-learn after model training.</p>"},{"location":"glossary/#clustering","title":"Clustering","text":"<p>An unsupervised learning method that groups data points into clusters based on similarity.</p> <p>Example: Segmenting customers into groups based on purchasing habits.</p>"},{"location":"glossary/#coefficient","title":"Coefficient","text":"<p>A numerical value representing the strength and direction of the relationship between a predictor and the response variable in a regression model.</p> <p>Example: In a linear regression, a coefficient of 2.5 for \"hours studied\" means each extra hour increases predicted score by 2.5 points.</p>"},{"location":"glossary/#collinearity","title":"Collinearity","text":"<p>A situation where two or more predictor variables are highly correlated, which can affect model stability.</p> <p>Example: Including both height in inches and height in centimeters in a regression model creates collinearity.</p>"},{"location":"glossary/#column","title":"Column","text":"<p>A vertical arrangement of data values in a table, representing a single attribute.</p> <p>Example: In a Pandas DataFrame, each column holds one variable\u2019s data.</p>"},{"location":"glossary/#confusion-matrix","title":"Confusion Matrix","text":"<p>A table used to evaluate classification performance by showing counts of true positives, false positives, true negatives, and false negatives.</p> <p>Example: A confusion matrix showing that a model misclassified 5 out of 100 test emails.</p>"},{"location":"glossary/#correlation","title":"Correlation","text":"<p>A statistical measure that describes the strength and direction of a linear relationship between two variables.</p> <p>Example: A correlation coefficient of 0.9 between height and weight indicates a strong positive relationship.</p>"},{"location":"glossary/#correlation-coefficient","title":"Correlation Coefficient","text":"<p>A numerical value between -1 and 1 that indicates the degree of linear association between two variables.</p> <p>Example: A value of -0.75 shows a strong negative correlation.</p>"},{"location":"glossary/#cross-validation","title":"Cross-Validation","text":"<p>A technique for assessing how well a model generalizes by dividing data into multiple training and testing subsets.</p> <p>Example: Using 5-fold cross-validation to evaluate a regression model\u2019s accuracy.</p>"},{"location":"glossary/#csv-comma-separated-values","title":"CSV (Comma-Separated Values)","text":"<p>A simple file format for storing tabular data where each line represents a row and values are separated by commas.</p> <p>Example: Importing a CSV file of sales data into Pandas for analysis.</p>"},{"location":"glossary/#dh","title":"D\u2013H","text":""},{"location":"glossary/#data-cleaning","title":"Data Cleaning","text":"<p>The process of detecting and correcting inaccurate, incomplete, or irrelevant data in a dataset.</p> <p>Example: Removing duplicate rows and correcting misspelled city names in a dataset.</p>"},{"location":"glossary/#data-exploration","title":"Data Exploration","text":"<p>The initial phase of data analysis where patterns, trends, and relationships are identified through visualization and statistics.</p> <p>Example: Using Pandas and Matplotlib to examine sales trends by month.</p>"},{"location":"glossary/#data-frame","title":"Data Frame","text":"<p>A two-dimensional labeled data structure in Pandas that can hold different data types in columns.</p> <p>Example: Loading a CSV file into a Pandas DataFrame for manipulation.</p>"},{"location":"glossary/#data-mining","title":"Data Mining","text":"<p>The process of discovering patterns, correlations, and insights from large datasets using statistical and computational techniques.</p> <p>Example: Finding product purchase patterns from transaction logs.</p>"},{"location":"glossary/#data-normalization","title":"Data Normalization","text":"<p>Adjusting values in a dataset to a common scale without distorting differences in ranges.</p> <p>Example: Scaling features between 0 and 1 before training a machine learning model.</p>"},{"location":"glossary/#data-preprocessing","title":"Data Preprocessing","text":"<p>Transforming raw data into a clean and usable format for analysis or modeling.</p> <p>Example: Encoding categorical variables as integers before running a regression.</p>"},{"location":"glossary/#data-science","title":"Data Science","text":"<p>An interdisciplinary field that combines statistics, programming, and domain knowledge to extract insights from data.</p> <p>Example: Using Python to analyze and visualize health survey data.</p>"},{"location":"glossary/#data-type","title":"Data Type","text":"<p>A classification specifying the kind of value a variable can hold, such as integer, float, or string.</p> <p>Example: In Python, <code>3</code> is an integer, and <code>3.14</code> is a float.</p>"},{"location":"glossary/#dataset","title":"Dataset","text":"<p>A structured collection of data, typically organized in rows and columns.</p> <p>Example: The Iris dataset is commonly used for classification demonstrations.</p>"},{"location":"glossary/#decision-tree","title":"Decision Tree","text":"<p>A model that makes decisions by splitting data into branches based on feature values.</p> <p>Example: Predicting loan approval using a decision tree classifier.</p>"},{"location":"glossary/#deep-learning","title":"Deep Learning","text":"<p>A subfield of machine learning that uses multi-layered neural networks to model complex patterns.</p> <p>Example: Training a convolutional neural network to recognize handwritten digits.</p>"},{"location":"glossary/#dependent-variable","title":"Dependent Variable","text":"<p>The outcome variable being predicted or explained in a model.</p> <p>Example: Predicting \"house price\" based on features like size and location.</p>"},{"location":"glossary/#descriptive-statistics","title":"Descriptive Statistics","text":"<p>Statistical methods for summarizing and describing data features.</p> <p>Example: Calculating mean, median, and standard deviation for exam scores.</p>"},{"location":"glossary/#dimension-reduction","title":"Dimension Reduction","text":"<p>Techniques for reducing the number of variables while preserving relevant information.</p> <p>Example: Using Principal Component Analysis (PCA) to reduce feature count before clustering.</p>"},{"location":"glossary/#discrete-data","title":"Discrete Data","text":"<p>Data that can only take on specific, distinct values.</p> <p>Example: Number of students in a classroom.</p>"},{"location":"glossary/#distribution","title":"Distribution","text":"<p>The way values of a variable are spread or arranged.</p> <p>Example: A bell-shaped distribution for students\u2019 test scores.</p>"},{"location":"glossary/#dummy-variable","title":"Dummy Variable","text":"<p>A binary variable created to represent categorical data for modeling purposes.</p> <p>Example: Encoding \"Gender\" as 0 for male and 1 for female.</p>"},{"location":"glossary/#eda-exploratory-data-analysis","title":"EDA (Exploratory Data Analysis)","text":"<p>The process of visually and statistically summarizing a dataset to uncover patterns and insights.</p> <p>Example: Plotting histograms and scatter plots to explore data before modeling.</p>"},{"location":"glossary/#epoch","title":"Epoch","text":"<p>One complete pass through the entire training dataset in machine learning.</p> <p>Example: Training a neural network for 50 epochs to achieve better accuracy.</p>"},{"location":"glossary/#evaluation-metric","title":"Evaluation Metric","text":"<p>A standard of measurement used to assess model performance.</p> <p>Example: Mean Squared Error (MSE) for regression models.</p>"},{"location":"glossary/#evidence-based-decision","title":"Evidence-Based Decision","text":"<p>A decision guided by analysis and data rather than intuition alone.</p> <p>Example: Allocating marketing budget based on data-driven campaign performance.</p>"},{"location":"glossary/#explanatory-variable","title":"Explanatory Variable","text":"<p>A variable used to predict or explain the dependent variable.</p> <p>Example: In predicting crop yield, rainfall amount is an explanatory variable.</p>"},{"location":"glossary/#exponential-smoothing","title":"Exponential Smoothing","text":"<p>A forecasting method that applies decreasing weights to older observations.</p> <p>Example: Forecasting monthly sales using exponential smoothing.</p>"},{"location":"glossary/#feature","title":"Feature","text":"<p>An individual measurable property of the data used in modeling.</p> <p>Example: \"Age\" and \"Income\" as features in predicting spending habits.</p>"},{"location":"glossary/#feature-engineering","title":"Feature Engineering","text":"<p>The process of creating new features or transforming existing ones to improve model performance.</p> <p>Example: Creating a \"BMI\" feature from height and weight columns.</p>"},{"location":"glossary/#feature-scaling","title":"Feature Scaling","text":"<p>Adjusting feature values to the same scale to ensure fair model training.</p> <p>Example: Standardizing all features to have zero mean and unit variance.</p>"},{"location":"glossary/#feature-selection","title":"Feature Selection","text":"<p>Choosing the most relevant features to improve model efficiency and accuracy.</p> <p>Example: Removing features with low correlation to the target variable.</p>"},{"location":"glossary/#f1-score","title":"F1-Score","text":"<p>A metric that combines precision and recall into a single value.</p> <p>Example: An F1-score of 0.85 indicates a balanced model performance.</p>"},{"location":"glossary/#false-negative","title":"False Negative","text":"<p>A prediction that incorrectly classifies a positive case as negative.</p> <p>Example: A medical test failing to detect a disease when it is present.</p>"},{"location":"glossary/#false-positive","title":"False Positive","text":"<p>A prediction that incorrectly classifies a negative case as positive.</p> <p>Example: A spam filter marking a legitimate email as spam.</p>"},{"location":"glossary/#feature-matrix","title":"Feature Matrix","text":"<p>A two-dimensional array containing feature values for all observations in a dataset.</p> <p>Example: A NumPy array where each row is a sample and each column is a feature.</p>"},{"location":"glossary/#forecasting","title":"Forecasting","text":"<p>Predicting future values based on historical data.</p> <p>Example: Using time series models to forecast next month\u2019s sales.</p>"},{"location":"glossary/#function-python","title":"Function (Python)","text":"<p>A reusable block of code that performs a specific task.</p> <p>Example: Defining a function to calculate the mean of a list.</p>"},{"location":"glossary/#gaussian-distribution","title":"Gaussian Distribution","text":"<p>A symmetric, bell-shaped probability distribution characterized by mean and standard deviation.</p> <p>Example: Heights of adult men following a Gaussian distribution.</p>"},{"location":"glossary/#generalization","title":"Generalization","text":"<p>The ability of a model to perform well on new, unseen data.</p> <p>Example: A model that predicts accurately on both training and test datasets generalizes well.</p>"},{"location":"glossary/#gradient-descent","title":"Gradient Descent","text":"<p>An optimization algorithm used to minimize a function by iteratively moving toward the lowest point.</p> <p>Example: Training linear regression by adjusting weights with gradient descent.</p>"},{"location":"glossary/#ground-truth","title":"Ground Truth","text":"<p>The actual, verified values used to evaluate predictions.</p> <p>Example: Comparing model predictions to actual customer purchase data.</p>"},{"location":"glossary/#groupby-pandas","title":"GroupBy (Pandas)","text":"<p>A Pandas method for splitting data into groups for aggregation or transformation.</p> <p>Example: Grouping sales data by region and summing total revenue.</p>"},{"location":"glossary/#heatmap","title":"Heatmap","text":"<p>A graphical representation of data values using color shading.</p> <p>Example: A correlation heatmap showing relationships between features.</p>"},{"location":"glossary/#heuristic","title":"Heuristic","text":"<p>A rule-of-thumb strategy for solving problems quickly, though not always optimally.</p> <p>Example: Using a decision tree depth limit of 5 as a heuristic for speed.</p>"},{"location":"glossary/#histogram","title":"Histogram","text":"<p>A plot that groups numerical data into intervals (bins) and shows their frequency.</p> <p>Example: Plotting the distribution of exam scores in bins of 10 points.</p>"},{"location":"glossary/#hyperparameter","title":"Hyperparameter","text":"<p>A parameter set before training that controls model behavior.</p> <p>Example: Setting the learning rate in gradient descent.</p>"},{"location":"glossary/#im","title":"I\u2013M","text":""},{"location":"glossary/#imbalanced-dataset","title":"Imbalanced Dataset","text":"<p>A dataset where some classes have significantly more samples than others.</p> <p>Example: A fraud detection dataset with 99% non-fraud and 1% fraud cases.</p>"},{"location":"glossary/#imputation","title":"Imputation","text":"<p>The process of replacing missing data with substituted values.</p> <p>Example: Filling missing ages with the mean age of the dataset.</p>"},{"location":"glossary/#independent-variable","title":"Independent Variable","text":"<p>A variable used as an input to predict another variable.</p> <p>Example: Study time as an independent variable in predicting test scores.</p>"},{"location":"glossary/#index-pandas","title":"Index (Pandas)","text":"<p>Labels that identify rows in a Pandas DataFrame or Series.</p> <p>Example: Setting the \"date\" column as the index for a time series.</p>"},{"location":"glossary/#inferential-statistics","title":"Inferential Statistics","text":"<p>Statistical methods for making predictions or inferences about a population from a sample.</p> <p>Example: Using a sample of voters to predict an election outcome.</p>"},{"location":"glossary/#information-gain","title":"Information Gain","text":"<p>A measure of how much a feature improves classification by reducing uncertainty.</p> <p>Example: A decision tree choosing a feature with the highest information gain for the first split.</p>"},{"location":"glossary/#interpolation","title":"Interpolation","text":"<p>Estimating unknown values within the range of known data points.</p> <p>Example: Estimating missing temperature readings between two known days.</p>"},{"location":"glossary/#iteration","title":"Iteration","text":"<p>A single pass through a loop or process in programming.</p> <p>Example: Each pass through a <code>for</code> loop is an iteration.</p>"},{"location":"glossary/#jupyter-notebook","title":"Jupyter Notebook","text":"<p>An interactive environment for writing and running Python code, combining code, visualizations, and text.</p> <p>Example: Running data analysis and visualizations in a Jupyter Notebook.</p>"},{"location":"glossary/#json-javascript-object-notation","title":"JSON (JavaScript Object Notation)","text":"<p>A lightweight data format for storing and exchanging structured data.</p> <p>Example: Importing JSON-formatted API data into Pandas.</p>"},{"location":"glossary/#k-fold-cross-validation","title":"k-Fold Cross-Validation","text":"<p>A method of splitting data into k subsets for training and testing to evaluate model performance.</p> <p>Example: Using 10-fold cross-validation to assess a regression model.</p>"},{"location":"glossary/#k-means-clustering","title":"k-Means Clustering","text":"<p>An unsupervised learning algorithm that groups data into k clusters based on similarity.</p> <p>Example: Segmenting customers into 4 clusters using purchase history.</p>"},{"location":"glossary/#kernel-in-computing","title":"Kernel (in Computing)","text":"<p>The central component of an operating system or computational environment.</p> <p>Example: Restarting the Python kernel in Jupyter Notebook to clear variables.</p>"},{"location":"glossary/#keyword-argument-python","title":"Keyword Argument (Python)","text":"<p>An argument passed to a function by explicitly naming the parameter.</p> <p>Example: Calling <code>plot(x, y, color=\"blue\")</code> uses a keyword argument.</p>"},{"location":"glossary/#kolmogorov-smirnov-test","title":"Kolmogorov-Smirnov Test","text":"<p>A statistical test to compare a sample distribution with a reference probability distribution.</p> <p>Example: Checking if a dataset follows a normal distribution.</p>"},{"location":"glossary/#label-in-machine-learning","title":"Label (in Machine Learning)","text":"<p>The output or target variable in supervised learning.</p> <p>Example: \"Species\" in the Iris dataset is the label.</p>"},{"location":"glossary/#label-encoding","title":"Label Encoding","text":"<p>Converting categorical values into numeric codes.</p> <p>Example: Encoding \"low\", \"medium\", \"high\" as 0, 1, 2.</p>"},{"location":"glossary/#lasso-regression","title":"Lasso Regression","text":"<p>A linear regression method with L1 regularization that can reduce coefficients to zero.</p> <p>Example: Using Lasso to perform feature selection in a high-dimensional dataset.</p>"},{"location":"glossary/#learning-rate","title":"Learning Rate","text":"<p>A hyperparameter controlling how much to adjust model weights during training.</p> <p>Example: Setting a learning rate of 0.01 for gradient descent.</p>"},{"location":"glossary/#least-squares-method","title":"Least Squares Method","text":"<p>A method for estimating regression coefficients by minimizing the sum of squared residuals.</p> <p>Example: Fitting a line to data points using least squares.</p>"},{"location":"glossary/#legend-in-visualization","title":"Legend (in Visualization)","text":"<p>An element in a chart that explains the meaning of colors, symbols, or line styles.</p> <p>Example: A legend identifying which line corresponds to each city in a temperature chart.</p>"},{"location":"glossary/#library-python","title":"Library (Python)","text":"<p>A collection of modules that provide specific functionality.</p> <p>Example: NumPy is a library for numerical computing.</p>"},{"location":"glossary/#linear-regression","title":"Linear Regression","text":"<p>A method for modeling the relationship between a dependent variable and one or more independent variables using a linear equation.</p> <p>Example: Predicting house prices from square footage.</p>"},{"location":"glossary/#logistic-regression","title":"Logistic Regression","text":"<p>A statistical model used for binary classification that predicts probabilities using a logistic function.</p> <p>Example: Predicting whether a student passes an exam based on study hours.</p>"},{"location":"glossary/#loss-function","title":"Loss Function","text":"<p>A function that measures the error between predicted and actual values.</p> <p>Example: Mean Squared Error is a loss function for regression.</p>"},{"location":"glossary/#machine-learning","title":"Machine Learning","text":"<p>A subset of AI where models improve their performance by learning from data.</p> <p>Example: Training a decision tree to classify loan applications.</p>"},{"location":"glossary/#mae-mean-absolute-error","title":"MAE (Mean Absolute Error)","text":"<p>A regression metric measuring the average absolute difference between predicted and actual values.</p> <p>Example: An MAE of 5 means predictions are off by 5 units on average.</p>"},{"location":"glossary/#map-function-python","title":"Map Function (Python)","text":"<p>A function that applies another function to each item in an iterable.</p> <p>Example: Using <code>map(str.upper, words)</code> to convert all words to uppercase.</p>"},{"location":"glossary/#matplotlib","title":"Matplotlib","text":"<p>A Python library for creating static, animated, and interactive visualizations.</p> <p>Example: Plotting a line chart of sales over time using Matplotlib.</p>"},{"location":"glossary/#matrix","title":"Matrix","text":"<p>A two-dimensional array of numbers arranged in rows and columns.</p> <p>Example: A 3\u00d73 NumPy array representing a matrix.</p>"},{"location":"glossary/#mean","title":"Mean","text":"<p>The average value of a dataset, found by summing all values and dividing by the count.</p> <p>Example: The mean of 2, 4, and 6 is 4.</p>"},{"location":"glossary/#mean-squared-error-mse","title":"Mean Squared Error (MSE)","text":"<p>A regression metric that measures the average squared difference between predicted and actual values.</p> <p>Example: An MSE of 9 means the average squared error is 9 units.</p>"},{"location":"glossary/#median","title":"Median","text":"<p>The middle value when data is ordered from smallest to largest.</p> <p>Example: The median of 1, 3, 5 is 3.</p>"},{"location":"glossary/#microsimulation","title":"MicroSimulation","text":"<p>An interactive simulation that runs in your browser that helps you learn a data science concept.</p> <p>Example: You can visualize the least squares method of liner regression by changing the slope and intercept of a line through a series of points.</p>"},{"location":"glossary/#min-max-scaling","title":"Min-Max Scaling","text":"<p>A feature scaling technique that rescales values to a given range, usually [0, 1].</p> <p>Example: Converting exam scores from a 0\u2013100 scale to 0\u20131.</p>"},{"location":"glossary/#missing-data","title":"Missing Data","text":"<p>Values not recorded in a dataset.</p> <p>Example: A blank entry for \"age\" in a survey response.</p>"},{"location":"glossary/#mode","title":"Mode","text":"<p>The most frequently occurring value in a dataset.</p> <p>Example: In 2, 3, 3, 4, 5, the mode is 3.</p> <p>Example: Creating a scikit-learn pipeline to standardize data and train a model in a single workflow.</p> <p>A mathematical representation of a process or system built from data to make predictions or decisions.</p> <p>Example: A linear regression equation predicting house prices.</p>"},{"location":"glossary/#model-complexity","title":"Model Complexity","text":"<p>The level of detail and number of parameters in a model.</p> <p>Example: A deep neural network is more complex than a simple linear regression.</p>"},{"location":"glossary/#model-evaluation","title":"Model Evaluation","text":"<p>The process of assessing a model\u2019s performance using metrics and validation techniques.</p> <p>Example: Evaluating a classification model with precision and recall.</p>"},{"location":"glossary/#model-overfitting","title":"Model Overfitting","text":"<p>When a model learns noise in the training data, reducing performance on new data.</p> <p>Example: A decision tree that memorizes training examples but fails on test data.</p>"},{"location":"glossary/#model-underfitting","title":"Model Underfitting","text":"<p>When a model is too simple to capture the underlying structure of the data.</p> <p>Example: Using a straight line to fit highly curved data.</p>"},{"location":"glossary/#module-python","title":"Module (Python)","text":"<p>A file containing Python definitions and functions.</p> <p>Example: Importing the <code>math</code> module to use mathematical functions.</p>"},{"location":"glossary/#multicollinearity","title":"Multicollinearity","text":"<p>A situation where predictor variables in a regression model are highly correlated with each other.</p> <p>Example: Including both temperature in Celsius and Fahrenheit in the same model.</p>"},{"location":"glossary/#multiple-linear-regression","title":"Multiple Linear Regression","text":"<p>A linear regression model with two or more independent variables.</p> <p>Example: Predicting house price using square footage, number of bedrooms, and location.</p>"},{"location":"glossary/#ns","title":"N\u2013S","text":""},{"location":"glossary/#naive-bayes","title":"Naive Bayes","text":"<p>A probabilistic classification algorithm based on Bayes\u2019 theorem with the assumption of feature independence.</p> <p>Example: Classifying text documents into categories using Naive Bayes.</p>"},{"location":"glossary/#natural-language-processing-nlp","title":"Natural Language Processing (NLP)","text":"<p>A field of AI focused on enabling computers to understand and process human language.</p> <p>Example: Using NLP to analyze sentiment in customer reviews.</p>"},{"location":"glossary/#neural-network","title":"Neural Network","text":"<p>A computational model inspired by the human brain, consisting of interconnected nodes (neurons) organized in layers.</p> <p>Example: A neural network classifying handwritten digits.</p>"},{"location":"glossary/#noise-data","title":"Noise (Data)","text":"<p>Random variations or irrelevant information in data that obscure patterns.</p> <p>Example: Sensor measurement errors in temperature readings.</p>"},{"location":"glossary/#nominal-data","title":"Nominal Data","text":"<p>Categorical data without an inherent order.</p> <p>Example: Car brands such as Toyota, Ford, and Honda.</p>"},{"location":"glossary/#normal-distribution","title":"Normal Distribution","text":"<p>A symmetric, bell-shaped probability distribution characterized by mean and standard deviation.</p> <p>Example: Adult human heights often approximate a normal distribution.</p>"},{"location":"glossary/#normalization","title":"Normalization","text":"<p>The process of scaling numerical data to a standard range or format.</p> <p>Example: Scaling all features to a 0\u20131 range before training.</p>"},{"location":"glossary/#null-hypothesis","title":"Null Hypothesis","text":"<p>A default statistical assumption that there is no effect or relationship between variables.</p> <p>Example: Testing whether two teaching methods result in the same average test score.</p>"},{"location":"glossary/#numpy","title":"NumPy","text":"<p>A Python library for numerical computing, providing array objects and mathematical functions.</p> <p>Example: Performing matrix multiplication using NumPy arrays.</p>"},{"location":"glossary/#observation","title":"Observation","text":"<p>A single record or row in a dataset.</p> <p>Example: One student's exam scores in a class dataset.</p>"},{"location":"glossary/#one-hot-encoding","title":"One-Hot Encoding","text":"<p>A method of converting categorical variables into binary indicator variables.</p> <p>Example: Encoding \"red\", \"blue\", \"green\" into three separate binary columns.</p>"},{"location":"glossary/#open-source-software","title":"Open Source Software","text":"<p>Software with source code made freely available for modification and distribution.</p> <p>Example: Pandas is open source.</p>"},{"location":"glossary/#optimization","title":"Optimization","text":"<p>The process of adjusting model parameters to minimize or maximize an objective function.</p> <p>Example: Using gradient descent to minimize prediction error.</p>"},{"location":"glossary/#outlier","title":"Outlier","text":"<p>A data point significantly different from other observations.</p> <p>Example: A monthly sales value 10 times higher than all others.</p>"},{"location":"glossary/#overfitting","title":"Overfitting","text":"<p>When a model fits training data too closely, capturing noise rather than general patterns.</p> <p>Example: A polynomial regression curve that perfectly passes through all training points but fails on test data.</p>"},{"location":"glossary/#overfitting-prevention","title":"Overfitting Prevention","text":"<p>Techniques used to reduce overfitting, such as regularization, pruning, and cross-validation.</p> <p>Example: Using Lasso regression to reduce unnecessary model complexity.</p>"},{"location":"glossary/#p-value","title":"p-Value","text":"<p>A statistical measure of the probability of obtaining results at least as extreme as the observed results, assuming the null hypothesis is true.</p> <p>Example: A p-value of 0.03 suggests statistical significance at the 5% level.</p>"},{"location":"glossary/#pandas","title":"Pandas","text":"<p>A Python library for data manipulation and analysis with DataFrame and Series objects.</p> <p>Example: Loading and cleaning a CSV dataset with Pandas.</p>"},{"location":"glossary/#parameter-model","title":"Parameter (Model)","text":"<p>A value learned from data that defines how the model makes predictions.</p> <p>Example: The slope in a linear regression equation.</p>"},{"location":"glossary/#parameter-tuning","title":"Parameter Tuning","text":"<p>Adjusting model hyperparameters to optimize performance.</p> <p>Example: Testing multiple learning rates to find the best one.</p>"},{"location":"glossary/#parsing","title":"Parsing","text":"<p>Breaking down data or text into structured components for processing.</p> <p>Example: Parsing JSON data from an API response.</p>"},{"location":"glossary/#pearson-correlation-coefficient","title":"Pearson Correlation Coefficient","text":"<p>A statistic measuring the linear relationship between two variables.</p> <p>Example: A Pearson coefficient of 0.8 indicates a strong positive relationship.</p>"},{"location":"glossary/#performance-metric","title":"Performance Metric","text":"<p>A quantitative measure used to evaluate the effectiveness of a model.</p> <p>Example: Accuracy, precision, and recall are performance metrics for classification.</p>"},{"location":"glossary/#pipeline-machine-learning","title":"Pipeline (Machine Learning)","text":"<p>A sequence of data processing and modeling steps applied consistently to training and test data.</p> <p>Example: A pipeline for scaling features and then applying logistic regression.</p>"},{"location":"glossary/#pivot-table","title":"Pivot Table","text":"<p>A table that summarizes data by grouping and aggregating values.</p> <p>Example: Summarizing sales by region and month using a Pandas pivot table.</p>"},{"location":"glossary/#polynomial-regression","title":"Polynomial Regression","text":"<p>A regression method where the relationship between variables is modeled as an nth-degree polynomial.</p> <p>Example: Fitting a quadratic curve to non-linear data.</p>"},{"location":"glossary/#population","title":"Population","text":"<p>The entire set of items or individuals of interest in a study.</p> <p>Example: All registered voters in a country.</p>"},{"location":"glossary/#precision","title":"Precision","text":"<p>The proportion of positive predictions that are actually correct.</p> <p>Example: A precision of 0.9 means 90% of predicted positives were correct.</p>"},{"location":"glossary/#predictive-modeling","title":"Predictive Modeling","text":"<p>The process of creating models to forecast outcomes based on historical data.</p> <p>Example: Using past sales data to predict next month\u2019s revenue.</p>"},{"location":"glossary/#predictor-variable","title":"Predictor Variable","text":"<p>An independent variable used to forecast the dependent variable.</p> <p>Example: Advertising spend as a predictor of sales.</p>"},{"location":"glossary/#preprocessing","title":"Preprocessing","text":"<p>Preparing raw data for analysis or modeling through cleaning, transformation, and encoding.</p> <p>Example: Removing missing values and scaling features.</p>"},{"location":"glossary/#pre-trained-model","title":"Pre-Trained Model","text":"<p>A model that has been previously trained on a large dataset and can be fine-tuned for a new task.</p> <p>Example: Using a pre-trained image classifier for a smaller dataset.</p>"},{"location":"glossary/#probability","title":"Probability","text":"<p>A measure of the likelihood that an event will occur, ranging from 0 to 1.</p> <p>Example: A probability of 0.75 means a 75% chance of occurrence.</p>"},{"location":"glossary/#probability-distribution","title":"Probability Distribution","text":"<p>A function that describes the likelihood of all possible outcomes.</p> <p>Example: A uniform distribution gives equal probability to all values.</p>"},{"location":"glossary/#pytorch","title":"PyTorch","text":"<p>An open-source machine learning library for deep learning and tensor computation.</p> <p>Example: Building a neural network in PyTorch for image recognition.</p>"},{"location":"glossary/#quantile","title":"Quantile","text":"<p>A cut point dividing data into equal-sized intervals.</p> <p>Example: The median is the 0.5 quantile.</p>"},{"location":"glossary/#quartile","title":"Quartile","text":"<p>One of three points that divide data into four equal groups.</p> <p>Example: The first quartile is the 25th percentile.</p>"},{"location":"glossary/#query-database","title":"Query (Database)","text":"<p>A request for specific information from a database.</p> <p>Example: Using SQL to retrieve rows where sales exceed \\$500.</p>"},{"location":"glossary/#r2-coefficient-of-determination","title":"R\u00b2 (Coefficient of Determination)","text":"<p>A metric indicating the proportion of variance in the dependent variable explained by the model.</p> <p>Example: An R\u00b2 of 0.85 means 85% of the variation is explained by the model.</p>"},{"location":"glossary/#random-forest","title":"Random Forest","text":"<p>An ensemble learning method combining multiple decision trees for better performance.</p> <p>Example: Classifying emails using a random forest model.</p>"},{"location":"glossary/#recall","title":"Recall","text":"<p>The proportion of actual positives correctly identified by the model.</p> <p>Example: A recall of 0.8 means the model identified 80% of actual positives.</p>"},{"location":"glossary/#recursive-feature-elimination-rfe","title":"Recursive Feature Elimination (RFE)","text":"<p>A method for selecting features by recursively removing the least important ones.</p> <p>Example: Using RFE to reduce feature count before training.</p>"},{"location":"glossary/#regression","title":"Regression","text":"<p>A statistical method for modeling relationships between variables to predict numerical outcomes.</p> <p>Example: Predicting car prices from mileage and age.</p>"},{"location":"glossary/#regularization","title":"Regularization","text":"<p>A technique for reducing model complexity to prevent overfitting by adding a penalty term to the loss function.</p> <p>Example: L2 regularization in Ridge regression.</p>"},{"location":"glossary/#residual","title":"Residual","text":"<p>The difference between the observed value and the value predicted by a model.</p> <p>Example: If actual sales are 200 and predicted sales are 180, the residual is 20.</p>"},{"location":"glossary/#root-mean-squared-error-rmse","title":"Root Mean Squared Error (RMSE)","text":"<p>A regression metric measuring the square root of the average squared prediction error.</p> <p>Example: An RMSE of 3 means predictions are off by 3 units on average.</p>"},{"location":"glossary/#sample","title":"Sample","text":"<p>A subset of a population used for analysis.</p> <p>Example: Surveying 500 people from a city of 100,000 residents.</p>"},{"location":"glossary/#sampling","title":"Sampling","text":"<p>Selecting a subset of data from a larger dataset or population.</p> <p>Example: Randomly selecting 100 customers for a feedback survey.</p>"},{"location":"glossary/#sampling-bias","title":"Sampling Bias","text":"<p>A bias introduced when the sample is not representative of the population.</p> <p>Example: Surveying only morning shoppers to estimate daily spending.</p>"},{"location":"glossary/#scatter-plot","title":"Scatter Plot","text":"<p>A graph showing data points on an x-y axis to visualize relationships between variables.</p> <p>Example: Plotting height against weight to explore correlation.</p>"},{"location":"glossary/#scikit-learn","title":"Scikit-learn","text":"<p>A Python library for machine learning, providing tools for modeling, preprocessing, and evaluation.</p> <p>Example: Building a decision tree classifier with Scikit-learn.</p>"},{"location":"glossary/#scripting","title":"Scripting","text":"<p>Writing and executing code to automate tasks.</p> <p>Example: Writing a Python script to download and clean data files.</p>"},{"location":"glossary/#series-pandas","title":"Series (Pandas)","text":"<p>A one-dimensional labeled array in Pandas.</p> <p>Example: A Series of student grades with names as labels.</p>"},{"location":"glossary/#standard-deviation","title":"Standard Deviation","text":"<p>A measure of the dispersion of values around the mean.</p> <p>Example: A standard deviation of 2 means most values fall within \u00b12 units of the mean.</p>"},{"location":"glossary/#standardization","title":"Standardization","text":"<p>Scaling features so they have zero mean and unit variance.</p> <p>Example: Standardizing exam scores before analysis.</p>"},{"location":"glossary/#tz","title":"T\u2013Z","text":""},{"location":"glossary/#target-variable","title":"Target Variable","text":"<p>The variable a model aims to predict.</p> <p>Example: Predicting \"exam score\" as the target variable using study hours and sleep.</p>"},{"location":"glossary/#t-statistic","title":"t-Statistic","text":"<p>A value used in hypothesis testing to determine if sample means differ significantly.</p> <p>Example: Using a t-statistic to compare average weights of two groups.</p>"},{"location":"glossary/#tensor","title":"Tensor","text":"<p>A multi-dimensional array used in deep learning frameworks like PyTorch.</p> <p>Example: Representing a batch of images as a 4D tensor.</p>"},{"location":"glossary/#test-data","title":"Test Data","text":"<p>A dataset used to evaluate model performance after training.</p> <p>Example: Testing a spam filter on previously unseen emails.</p>"},{"location":"glossary/#test-train-split","title":"Test-Train Split","text":"<p>The process of dividing data into separate training and testing subsets.</p> <p>Example: Using 80% of data for training and 20% for testing.</p>"},{"location":"glossary/#text-mining","title":"Text Mining","text":"<p>Extracting useful information from text data through statistical and computational methods.</p> <p>Example: Identifying frequent keywords in news articles.</p>"},{"location":"glossary/#time-series","title":"Time Series","text":"<p>A sequence of data points collected over time intervals.</p> <p>Example: Daily stock prices over a year.</p>"},{"location":"glossary/#tokenization","title":"Tokenization","text":"<p>Breaking text into smaller units such as words or phrases.</p> <p>Example: Splitting \"Data Science is fun\" into [\"Data\", \"Science\", \"is\", \"fun\"].</p>"},{"location":"glossary/#training-data","title":"Training Data","text":"<p>The dataset used to fit or train a model.</p> <p>Example: Using past sales data to train a revenue prediction model.</p>"},{"location":"glossary/#training-epoch","title":"Training Epoch","text":"<p>One complete pass of the training dataset through the model during learning.</p> <p>Example: Training a neural network for 10 epochs.</p>"},{"location":"glossary/#transformation","title":"Transformation","text":"<p>Applying a mathematical function to change data format or scale.</p> <p>Example: Applying a logarithmic transformation to skewed data.</p>"},{"location":"glossary/#tree-based-models","title":"Tree-Based Models","text":"<p>Models that use decision trees or ensembles of trees for prediction.</p> <p>Example: Random forest and gradient boosting are tree-based models.</p>"},{"location":"glossary/#trend-time-series","title":"Trend (Time Series)","text":"<p>A long-term movement or pattern in time series data.</p> <p>Example: Increasing monthly sales over several years.</p>"},{"location":"glossary/#true-negative","title":"True Negative","text":"<p>A case where a model correctly predicts a negative outcome.</p> <p>Example: A medical test correctly identifying a healthy patient.</p>"},{"location":"glossary/#true-positive","title":"True Positive","text":"<p>A case where a model correctly predicts a positive outcome.</p> <p>Example: A cancer detection test correctly identifying a patient with cancer.</p>"},{"location":"glossary/#t-test","title":"t-Test","text":"<p>A statistical test comparing the means of two groups.</p> <p>Example: Testing whether two different diets result in different average weight loss.</p>"},{"location":"glossary/#underfitting","title":"Underfitting","text":"<p>When a model is too simple to capture the underlying data patterns.</p> <p>Example: Using a straight line to predict a highly curved dataset.</p>"},{"location":"glossary/#univariate-analysis","title":"Univariate Analysis","text":"<p>Analysis of a single variable to summarize and find patterns.</p> <p>Example: Plotting a histogram of exam scores.</p>"},{"location":"glossary/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>A machine learning approach where models find structure in data without labeled outcomes.</p> <p>Example: Using k-means clustering to group customers.</p>"},{"location":"glossary/#validation-data","title":"Validation Data","text":"<p>A dataset used during training to tune model hyperparameters.</p> <p>Example: Using validation data to choose the number of decision tree splits.</p>"},{"location":"glossary/#value-counts-pandas","title":"Value Counts (Pandas)","text":"<p>A method to count occurrences of each unique value in a Pandas Series.</p> <p>Example: Counting how many times each grade appears in a class.</p>"},{"location":"glossary/#variable","title":"Variable","text":"<p>A storage location identified by a name that holds a value.</p> <p>Example: In Python, <code>age = 20</code> assigns 20 to the variable <code>age</code>.</p>"},{"location":"glossary/#variance","title":"Variance","text":"<p>A measure of the spread of data points around the mean.</p> <p>Example: A variance of 4 means average squared deviations are 4 units\u00b2.</p>"},{"location":"glossary/#vectorization","title":"Vectorization","text":"<p>Performing operations on entire arrays rather than using loops.</p> <p>Example: Adding two NumPy arrays without explicit loops.</p>"},{"location":"glossary/#visualization","title":"Visualization","text":"<p>The graphical representation of data to reveal patterns and insights.</p> <p>Example: Using Matplotlib to plot a scatter diagram of height vs. weight.</p>"},{"location":"glossary/#visual-studio-code","title":"Visual Studio Code","text":"<p>A free integrated development environment that is used widely by programmers and data science science professionals.</p> <p>Visual Studio Code (VS-Code) also has many extensions for editing different languages and data types.</p> <p>Other examples of AI-based IDEs include Cursor and Windsurf.  The Cline extension is also useful.</p> <p>Example: We use VS-Code to edit, run, debug and test our Python code.</p>"},{"location":"glossary/#weighted-average","title":"Weighted Average","text":"<p>An average where each value contributes according to its assigned weight.</p> <p>Example: Calculating a final grade with different weights for assignments and exams.</p>"},{"location":"glossary/#weight-model","title":"Weight (Model)","text":"<p>A parameter that determines the influence of a feature in a model\u2019s prediction.</p> <p>Example: A weight of 0.5 for \"hours studied\" in a regression model.</p>"},{"location":"glossary/#white-noise-time-series","title":"White Noise (Time Series)","text":"<p>A random sequence of values with no predictable pattern.</p> <p>Example: Fluctuations in daily stock prices without a trend.</p>"},{"location":"glossary/#wilcoxon-test","title":"Wilcoxon Test","text":"<p>A non-parametric test for comparing paired samples.</p> <p>Example: Comparing pre- and post-training test scores without assuming normality.</p>"},{"location":"glossary/#yaml-yaml-aint-markup-language","title":"YAML (YAML Ain\u2019t Markup Language)","text":"<p>A human-readable data serialization format.</p> <p>Example: Storing configuration settings in a YAML file.</p>"},{"location":"glossary/#z-score","title":"z-Score","text":"<p>A standardized score indicating how many standard deviations a value is from the mean.</p> <p>Example: A z-score of 2 means the value is two standard deviations above the mean.</p>"},{"location":"glossary/#zero-inflated-data","title":"Zero-Inflated Data","text":"<p>Data with an excess number of zero values compared to a standard distribution.</p> <p>Example: A dataset of monthly purchases where many customers have zero purchases.</p>"},{"location":"glossary/#zero-shot-learning","title":"Zero-Shot Learning","text":"<p>A machine learning method where a model makes predictions for classes it was not explicitly trained on.</p> <p>Example: A text classifier identifying a new topic without prior examples.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p>"},{"location":"how-we-built-this-site/#image-generation-and-compression","title":"Image Generation and Compression","text":"<p>I have used ChatGPT to create most of my images.  However, they are too large for most websites.  To compress them down I used  https://tinypng.com/ which is a free tool  for compressing png images without significant loss of quality.  The files created with ChatGPT are typically around 1-2 MB.  After  using the TinyPNG site the size is typically around 200-300KB.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"Site References","text":"<ol> <li>mkdocs - https://www.mkdocs.org/ - this is our tool for building the website.  It converts Markdown into HTML in the <code>site</code> directory.</li> <li>mkdocs material theme - https://squidfunk.github.io/mkdocs-material/ - this is the theme for our site.  The theme adds the user interface elements that give our site the look and feel.  It also has the features such as social cards.</li> <li>GitHub Pages - https://pages.github.com/ - this is the free tool for hosting public websites created by mkdocs</li> <li>Markdown - https://www.mkdocs.org/user-guide/writing-your-docs/#writing-with-markdown - this is the format we use for text.  It allows us to have headers, lists, tables, links and images without learning HTML.</li> <li>Deploy Mkdocs GitHub Action - https://github.com/marketplace/actions/deploy-mkdocs - this is the tool we use to automatically build our site after edits are checked in with Git.</li> <li>Git Book - https://git-scm.com/book/en/v2 - a useful book on Git.  Just read the first two chapters to learn how to check in new code.</li> <li>Conda - https://conda.io/ - this is a command line tool that keeps our Python libraries organized for each project.</li> <li>VS Code - https://code.visualstudio.com/ - this is the integrated development environment we use to mange the files on our website.</li> <li>Markdown Paste - https://marketplace.visualstudio.com/items?itemName=telesoho.vscode-markdown-paste-image - this is the VS code extension we use to make sure we keep the markdown format generated by ChatGPT.</li> </ol>"},{"location":"chapters/","title":"Course Chapters - Table of Contents","text":"<p>This course provides a comprehensive introduction to data science using Python, progressing from foundational concepts to advanced machine learning techniques. Each chapter includes interactive MicroSims to reinforce learning through hands-on experience.</p>"},{"location":"chapters/#course-structure-overview","title":"Course Structure Overview","text":"<p>Duration: 10 weeks Target Audience: Advanced high school students and college freshmen Prerequisites: Basic algebra and introductory programming experience</p>"},{"location":"chapters/#chapter-progression","title":"Chapter Progression","text":""},{"location":"chapters/#foundation-phase-weeks-1-3","title":"Foundation Phase (Weeks 1-3)","text":""},{"location":"chapters/#chapter-0-setup","title":"Chapter 0: Setup","text":"<ul> <li>Python environment and Jupyter notebooks setup</li> <li>Conda virtual environment configuration</li> <li>Required package installation</li> <li>Development environment best practices</li> </ul>"},{"location":"chapters/#chapter-1-foundations-of-data-science","title":"Chapter 1: Foundations of Data Science","text":"<ul> <li>Introduction to data science and its applications</li> <li>Setting up Python environment and Jupyter notebooks</li> <li>First MicroSim: Exploring sample datasets</li> <li>Basic data types and structures in Python</li> <li>Understanding the data science workflow</li> <li>Data science roles and career paths</li> <li>Ethics and best practices in data science</li> </ul>"},{"location":"chapters/#chapter-2-data-exploration-and-visualization","title":"Chapter 2: Data Exploration and Visualization","text":"<ul> <li>Loading and examining datasets with pandas</li> <li>Creating basic plots with matplotlib</li> <li>MicroSim: Interactive data visualization</li> <li>Identifying patterns in data through visual exploration</li> <li>Data profiling and quality assessment</li> <li>Handling missing values and outliers</li> <li>Exploratory data analysis techniques</li> </ul>"},{"location":"chapters/#chapter-3-data-visualization-techniques","title":"Chapter 3: Data Visualization Techniques","text":"<ul> <li>Principles of effective data visualization</li> <li>Matplotlib fundamentals and customization</li> <li>Plotly for interactive visualizations</li> <li>Statistical plots and distributions</li> <li>Time series visualization</li> <li>Multi-dimensional data representation</li> <li>MicroSim: Visualization parameter explorer</li> </ul>"},{"location":"chapters/#statistical-foundation-phase-weeks-4-5","title":"Statistical Foundation Phase (Weeks 4-5)","text":""},{"location":"chapters/#chapter-4-statistical-foundations","title":"Chapter 4: Statistical Foundations","text":"<ul> <li>Descriptive statistics and summary measures</li> <li>Understanding distributions and variability</li> <li>MicroSim: Statistical parameter exploration</li> <li>Introduction to probability concepts</li> <li>Central limit theorem and sampling distributions</li> <li>Hypothesis testing fundamentals</li> <li>Correlation vs. causation</li> </ul>"},{"location":"chapters/#chapter-5-simple-linear-regression","title":"Chapter 5: Simple Linear Regression","text":"<ul> <li>Mathematical foundations of linear regression</li> <li>Implementing regression from scratch</li> <li>MicroSim: Interactive regression line fitting</li> <li>Interpreting coefficients and model output</li> <li>Assumptions of linear regression</li> <li>Residual analysis and diagnostics</li> <li>Making predictions with linear models</li> </ul>"},{"location":"chapters/#model-development-phase-weeks-6-8","title":"Model Development Phase (Weeks 6-8)","text":""},{"location":"chapters/#chapter-6-model-evaluation-and-validation","title":"Chapter 6: Model Evaluation and Validation","text":"<ul> <li>Measuring model performance (R\u00b2, MSE, MAE)</li> <li>Training and testing data splits</li> <li>MicroSim: Cross-validation simulation</li> <li>Understanding overfitting and underfitting</li> <li>Bias-variance trade-off</li> <li>Model selection criteria</li> <li>Performance metrics for different problem types</li> </ul>"},{"location":"chapters/#chapter-7-multiple-linear-regression","title":"Chapter 7: Multiple Linear Regression","text":"<ul> <li>Extending to multiple predictor variables</li> <li>Feature selection and engineering</li> <li>MicroSim: Multi-dimensional regression explorer</li> <li>Handling categorical variables</li> <li>Interaction effects and polynomial terms</li> <li>Multicollinearity detection and treatment</li> <li>Model interpretation in multiple dimensions</li> </ul>"},{"location":"chapters/#chapter-8-introduction-to-numpy-and-advanced-computation","title":"Chapter 8: Introduction to NumPy and Advanced Computation","text":"<ul> <li>NumPy arrays and vectorized operations</li> <li>Matrix operations for regression</li> <li>MicroSim: Linear algebra visualization</li> <li>Computational efficiency in data science</li> <li>Broadcasting and array manipulation</li> <li>Mathematical functions and statistics</li> <li>Integration with pandas and matplotlib</li> </ul>"},{"location":"chapters/#advanced-modeling-phase-weeks-9-10","title":"Advanced Modeling Phase (Weeks 9-10)","text":""},{"location":"chapters/#chapter-9-non-linear-models-and-feature-engineering","title":"Chapter 9: Non-linear Models and Feature Engineering","text":"<ul> <li>Polynomial regression and feature transformation</li> <li>Understanding non-linear relationships</li> <li>MicroSim: Polynomial degree explorer</li> <li>Feature engineering techniques</li> <li>Basis functions and kernel methods</li> <li>Model complexity and interpretation trade-offs</li> <li>When to use non-linear approaches</li> </ul>"},{"location":"chapters/#chapter-10-regularization-techniques","title":"Chapter 10: Regularization Techniques","text":"<ul> <li>Ridge and Lasso regularization</li> <li>MicroSim: Bias-variance trade-off explorer</li> <li>Model selection strategies</li> <li>Cross-validation for hyperparameter tuning</li> <li>Elastic Net and other regularization methods</li> <li>Feature selection through regularization</li> <li>Preventing overfitting in complex models</li> </ul>"},{"location":"chapters/#machine-learning-phase-advanced-topics","title":"Machine Learning Phase (Advanced Topics)","text":""},{"location":"chapters/#chapter-11-introduction-to-machine-learning","title":"Chapter 11: Introduction to Machine Learning","text":"<ul> <li>Supervised vs. unsupervised learning</li> <li>Classification and regression problems</li> <li>Decision trees and ensemble methods</li> <li>MicroSim: Algorithm comparison explorer</li> <li>Feature importance and selection</li> <li>Model interpretability techniques</li> <li>Introduction to scikit-learn</li> </ul>"},{"location":"chapters/#chapter-12-neural-networks-and-deep-learning","title":"Chapter 12: Neural Networks and Deep Learning","text":"<ul> <li>Neural networks and deep learning concepts</li> <li>Perceptrons and multi-layer networks</li> <li>Activation functions and backpropagation</li> <li>MicroSim: Neural network playground</li> <li>Training neural networks</li> <li>Common architectures and applications</li> <li>When to use neural networks vs. traditional methods</li> </ul>"},{"location":"chapters/#chapter-13-introduction-to-machine-learning-with-pytorch","title":"Chapter 13: Introduction to Machine Learning with PyTorch","text":"<ul> <li>Building simple networks with PyTorch</li> <li>Tensors and automatic differentiation</li> <li>Creating and training models</li> <li>MicroSim: PyTorch model builder</li> <li>Comparing traditional and deep learning approaches</li> <li>GPU acceleration and optimization</li> <li>Model saving and deployment</li> </ul>"},{"location":"chapters/#chapter-14-advanced-model-evaluation","title":"Chapter 14: Advanced Model Evaluation","text":"<ul> <li>Comprehensive performance metrics</li> <li>ROC curves and AUC analysis</li> <li>Confusion matrices and classification reports</li> <li>MicroSim: Metric comparison explorer</li> <li>Statistical significance testing</li> <li>Model comparison techniques</li> <li>Reporting and communicating results</li> </ul>"},{"location":"chapters/#chapter-15-capstone-project-and-model-deployment","title":"Chapter 15: Capstone Project and Model Deployment","text":"<ul> <li>End-to-end data science project planning</li> <li>Model interpretation and communication</li> <li>MicroSim: Model comparison dashboard</li> <li>Best practices and ethical considerations</li> <li>Model deployment strategies</li> <li>Documentation and reproducibility</li> <li>Presenting data science findings</li> </ul>"},{"location":"chapters/#special-topics","title":"Special Topics","text":""},{"location":"chapters/#matplotlib-vs-plotly-comparison","title":"Matplotlib vs Plotly Comparison","text":"<p>Detailed comparison of visualization libraries for AI-generated plots and animations, including pros and cons for different use cases.</p>"},{"location":"chapters/#learning-methodology","title":"Learning Methodology","text":"<p>Each chapter incorporates: - Interactive MicroSims for hands-on parameter exploration - Real-world datasets and practical applications - Progressive complexity building from simple to advanced concepts - Explainable AI focus emphasizing model interpretability - Code examples with complete implementations</p>"},{"location":"chapters/#course-philosophy","title":"Course Philosophy","text":"<p>This course emphasizes the balance between model explainability and predictive accuracy, guiding students to identify the simplest effective solutions to data-driven problems. The integration of interactive simulations ensures abstract mathematical concepts become concrete and intuitive.</p>"},{"location":"chapters/matplotlib-vs-plotly/","title":"Comparison of Matplotlib and Plotly for GenAI-Created Plots and Animations","text":"<p>The wonderful thing about using Python for data science is the vast selection of libraries that are available to use for free.  Unfortunately, this also comes with a tradeoff.  You have to have a deep understanding of each library, what it's original intended purpose was and what its limitations are.</p> <p>In this section we will look at two of the most popular Python libraries for generating charts and other visualizations: Mathplotlib and [Plotly](../glossary.md#pl</p>"},{"location":"chapters/matplotlib-vs-plotly/#matplotlib","title":"Matplotlib","text":"<p>Matplotlib is a versatile and widely-used Python library for creating static, animated, and interactive visualizations.</p>"},{"location":"chapters/matplotlib-vs-plotly/#pros","title":"Pros","text":"<ol> <li>Simplicity and Customization:</li> <li>Great for generating static, publication-quality plots with fine-grained control.</li> <li> <p>Straightforward API for generating standard visualizations like line plots, bar charts, and scatter plots.</p> </li> <li> <p>Broad Ecosystem Support:</p> </li> <li>Integrates well with NumPy, pandas, and other scientific libraries.</li> <li> <p>Supported by many GenAI frameworks for generating data visualizations.</p> </li> <li> <p>Animations:</p> </li> <li>Provides tools for creating animations (e.g., <code>FuncAnimation</code>).</li> <li> <p>Ideal for embedding animations in applications or saving them as GIFs or videos.</p> </li> <li> <p>Customization:</p> </li> <li>Allows deep customization of every aspect of the plot.</li> <li> <p>Perfect for generating AI-tailored visualizations that require specific formats or aesthetics.</p> </li> <li> <p>Lightweight and Efficient:</p> </li> <li>Better for lightweight tasks where interactivity is not required.</li> </ol>"},{"location":"chapters/matplotlib-vs-plotly/#cons","title":"Cons","text":"<ol> <li>Steep Learning Curve:</li> <li>Customizing plots can become verbose and complicated, especially for advanced layouts.</li> <li> <p>Syntax can feel tedious for beginners or for generating multiple visualizations programmatically.</p> </li> <li> <p>Limited Interactivity:</p> </li> <li>Interactivity is minimal compared to modern libraries like Plotly.</li> <li> <p>Interactive plots require third-party tools (e.g., <code>mpld3</code>) and are often less intuitive.</p> </li> <li> <p>Outdated Animations:</p> </li> <li>Animations are not as smooth or interactive as those created by Plotly.</li> </ol>"},{"location":"chapters/matplotlib-vs-plotly/#plotly","title":"Plotly","text":"<p>Plotly is a modern library for creating highly interactive and dynamic visualizations.</p>"},{"location":"chapters/matplotlib-vs-plotly/#pros_1","title":"Pros","text":"<ol> <li>Interactivity:</li> <li>All visualizations are interactive by default (e.g., zooming, panning, tooltips).</li> <li> <p>Excellent for dashboards, presentations, and GenAI-generated insights.</p> </li> <li> <p>Ease of Use:</p> </li> <li>Simple syntax for creating complex plots, suitable for AI-generated visualizations.</li> <li> <p>Works seamlessly with data from pandas, NumPy, and other libraries.</p> </li> <li> <p>Browser-Based Rendering:</p> </li> <li>Plots render in web browsers using JavaScript, making them highly portable and shareable.</li> <li> <p>Supports embedding in Jupyter Notebooks, web apps, and standalone HTML files.</p> </li> <li> <p>Built-in Animations:</p> </li> <li>Easy to create smooth, interactive animations with native support.</li> <li> <p>Ideal for demonstrating dynamic AI models or processes.</p> </li> <li> <p>Wide Range of Charts:</p> </li> <li>Includes advanced visualizations like 3D plots, heatmaps, choropleth maps, and Sankey diagrams.</li> <li>Perfect for showing complex GenAI outputs in an intuitive way.</li> </ol>"},{"location":"chapters/matplotlib-vs-plotly/#cons_1","title":"Cons","text":"<ol> <li>Heavier and Slower:</li> <li>More resource-intensive due to JavaScript-based interactivity.</li> <li> <p>Can slow down with large datasets or complex visualizations.</p> </li> <li> <p>Limited Fine-Grained Control:</p> </li> <li>While customizable, it lacks the deep control over plot details that Matplotlib offers.</li> <li> <p>Certain niche visualizations might be harder to implement.</p> </li> <li> <p>Dependency on JavaScript:</p> </li> <li> <p>Requires JavaScript runtime for rendering, which might not be ideal for all environments.</p> </li> <li> <p>Animation Complexity:</p> </li> <li>While animations are smoother, creating complex animations programmatically can be less intuitive than with Matplotlib.</li> </ol>"},{"location":"chapters/matplotlib-vs-plotly/#which-to-choose-for-genai","title":"Which to Choose for GenAI?","text":"<ol> <li>Static Plots:</li> <li>Use Matplotlib for quick, customizable, high-quality static plots.</li> <li> <p>Example: Generating high-resolution images for reports or papers.</p> </li> <li> <p>Interactive and Animated Plots:</p> </li> <li>Use Plotly for dynamic and interactive plots.</li> <li> <p>Example: Interactive GenAI dashboards or showcasing dynamic AI model predictions.</p> </li> <li> <p>Collaborative and Web-Based Use:</p> </li> <li> <p>Use Plotly if your plots need to be shared on the web or included in interactive applications.</p> </li> <li> <p>Complex Animations:</p> </li> <li>Use Matplotlib for complex, programmatically controlled animations.</li> <li>Use Plotly for simple, interactive animations with smooth transitions.</li> </ol>"},{"location":"chapters/matplotlib-vs-plotly/#conclusion","title":"Conclusion","text":"<p>Both libraries are valuable for different contexts: - Matplotlib shines in fine-grained control and efficient static or programmatic visualizations. - Plotly is the go-to for interactivity, browser-based plots, and user-friendly animations.</p> <p>For GenAI, combining both libraries strategically (e.g., static plots with Matplotlib and interactive plots with Plotly) can provide the best of both worlds.</p>"},{"location":"chapters/00-setup/","title":"Setting up Python, Visual Studio Code and Jupyter Notebooks","text":"<p>In this course will will use, Python, Visual Studio Code and Jupyter Notebooks to do our classroom work. We selected these tools because they are the most popular development environments in data science today.  You are free to use other tools in this course, however you may need to use generative AI to translate our code into other systems. In addition, we strongly recommend each student create their own personal GitHub repository to store their work.  Because GitHub is backed up the students only need to check their code into GitHub using either a command line or Source Control section of Visual Studio Code.</p> <p>We will be using the following tools for our desktop setup:</p> <ol> <li>Visual Studio Code - integrated development environment</li> <li>Conda - virtual environment</li> <li>Pip - Python installer package</li> </ol>"},{"location":"chapters/00-setup/#conda","title":"Conda","text":"<p>Create a \"Data Science\" conda environment.</p> <pre><code>conda create -n \"ds\" python=3\nconda activate ds\n</code></pre>"},{"location":"chapters/00-setup/#installing-jupyter-notebooks","title":"Installing Jupyter Notebooks","text":"<p>Jupyter Notebooks are essential for this course as they provide an interactive environment for data science work. There are several ways to install and use Jupyter Notebooks:</p>"},{"location":"chapters/00-setup/#method-1-install-via-conda-recommended","title":"Method 1: Install via Conda (Recommended)","text":"<p>After activating your conda environment, install Jupyter:</p> <pre><code>conda activate ds\nconda install jupyter\n</code></pre>"},{"location":"chapters/00-setup/#method-2-install-via-pip","title":"Method 2: Install via Pip","text":"<p>Alternatively, you can install using pip:</p> <pre><code>pip install jupyter\n</code></pre>"},{"location":"chapters/00-setup/#method-3-install-jupyterlab-enhanced-interface","title":"Method 3: Install JupyterLab (Enhanced Interface)","text":"<p>For a more modern interface, you can install JupyterLab:</p> <pre><code>pip install jupyterlab\n</code></pre>"},{"location":"chapters/00-setup/#running-jupyter-notebooks","title":"Running Jupyter Notebooks","text":""},{"location":"chapters/00-setup/#starting-jupyter-notebook-server","title":"Starting Jupyter Notebook Server","text":"<p>To start the Jupyter Notebook server:</p> <pre><code># Activate your environment first\nconda activate ds\n\n# Start Jupyter Notebook\njupyter notebook\n</code></pre> <p>This will: 1. Start a local server (usually at <code>http://localhost:8888</code>) 2. Automatically open your web browser to the Jupyter interface 3. Display your file system where you can create new notebooks or open existing ones</p>"},{"location":"chapters/00-setup/#starting-jupyterlab","title":"Starting JupyterLab","text":"<p>If you installed JupyterLab:</p> <pre><code>jupyter lab\n</code></pre>"},{"location":"chapters/00-setup/#using-jupyter-notebooks-in-visual-studio-code","title":"Using Jupyter Notebooks in Visual Studio Code","text":"<p>Visual Studio Code provides excellent built-in support for Jupyter Notebooks, offering a seamless development experience.</p>"},{"location":"chapters/00-setup/#installing-the-jupyter-extension","title":"Installing the Jupyter Extension","text":"<ol> <li>Open Visual Studio Code</li> <li>Go to the Extensions view (<code>Ctrl+Shift+X</code> or <code>Cmd+Shift+X</code>)</li> <li>Search for \"Jupyter\" </li> <li>Install the official \"Jupyter\" extension by Microsoft</li> </ol>"},{"location":"chapters/00-setup/#working-with-notebooks-in-vs-code","title":"Working with Notebooks in VS Code","text":"<p>Creating a New Notebook: 1. Open VS Code 2. Create a new file with <code>.ipynb</code> extension (e.g., <code>my_analysis.ipynb</code>) 3. VS Code will automatically recognize it as a Jupyter notebook</p> <p>Selecting Python Interpreter: 1. Open a notebook file 2. Click on \"Select Kernel\" in the top-right corner 3. Choose your conda environment (<code>ds</code>) as the Python interpreter</p> <p>Running Code Cells: - Run Single Cell: Click the play button next to a cell or press <code>Shift+Enter</code> - Run All Cells: Use <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code>) and search \"Jupyter: Run All Cells\" - Add New Cell: Click the <code>+ Code</code> or <code>+ Markdown</code> buttons between cells</p>"},{"location":"chapters/00-setup/#advantages-of-using-jupyter-in-vs-code","title":"Advantages of Using Jupyter in VS Code","text":"<ul> <li>Integrated Development: Code editing, debugging, and notebook execution in one interface</li> <li>Git Integration: Easy version control for notebook files</li> <li>IntelliSense: Code completion and syntax highlighting</li> <li>Variable Explorer: View variables and data structures in real-time</li> <li>Debugging Support: Set breakpoints and debug notebook code</li> <li>Extensions: Access to VS Code's rich extension ecosystem</li> </ul>"},{"location":"chapters/00-setup/#installing-essential-data-science-packages","title":"Installing Essential Data Science Packages","text":"<p>Install the core packages you'll need for this course:</p> <pre><code># Activate your environment\nconda activate ds\n\n# Install essential data science packages\npip install pandas numpy matplotlib seaborn scikit-learn jupyter\n\n# Optional: Install additional useful packages\npip install plotly ipywidgets\n</code></pre>"},{"location":"chapters/00-setup/#transcript","title":"Transcript","text":"<pre><code>Retrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n\n==&gt; WARNING: A newer version of conda exists. &lt;==\n  current version: 23.5.2\n  latest version: 24.9.2\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\nOr to minimize the number of packages updated during conda update use\n\n     conda install conda=24.9.2\n\n\n## Package Plan ##\n\n  environment location: /Users/danmccreary/miniconda3/envs/ds\n\n  added / updated specs:\n    - python=3\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2024.9.24  |       hca03da5_0         131 KB\n    expat-2.6.3                |       h313beb8_0         154 KB\n    libmpdec-4.0.0             |       h80987f9_0          69 KB\n    openssl-3.0.15             |       h80987f9_0         4.3 MB\n    pip-24.2                   |  py313hca03da5_0         2.4 MB\n    python-3.13.0              |h4862095_100_cp313        13.7 MB\n    python_abi-3.13            |          0_cp313           7 KB\n    setuptools-75.1.0          |  py313hca03da5_0         1.9 MB\n    tzdata-2024b               |       h04d1e81_0         115 KB\n    wheel-0.44.0               |  py313hca03da5_0         139 KB\n    ------------------------------------------------------------\n                                           Total:        23.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n  bzip2              pkgs/main/osx-arm64::bzip2-1.0.8-h80987f9_6 \n  ca-certificates    pkgs/main/osx-arm64::ca-certificates-2024.9.24-hca03da5_0 \n  expat              pkgs/main/osx-arm64::expat-2.6.3-h313beb8_0 \n  libcxx             pkgs/main/osx-arm64::libcxx-14.0.6-h848a8c0_0 \n  libffi             pkgs/main/osx-arm64::libffi-3.4.4-hca03da5_1 \n  libmpdec           pkgs/main/osx-arm64::libmpdec-4.0.0-h80987f9_0 \n  ncurses            pkgs/main/osx-arm64::ncurses-6.4-h313beb8_0 \n  openssl            pkgs/main/osx-arm64::openssl-3.0.15-h80987f9_0 \n  pip                pkgs/main/osx-arm64::pip-24.2-py313hca03da5_0 \n  python             pkgs/main/osx-arm64::python-3.13.0-h4862095_100_cp313 \n  python_abi         pkgs/main/osx-arm64::python_abi-3.13-0_cp313 \n  readline           pkgs/main/osx-arm64::readline-8.2-h1a28f6b_0 \n  setuptools         pkgs/main/osx-arm64::setuptools-75.1.0-py313hca03da5_0 \n  sqlite             pkgs/main/osx-arm64::sqlite-3.45.3-h80987f9_0 \n  tk                 pkgs/main/osx-arm64::tk-8.6.14-h6ba3021_0 \n  tzdata             pkgs/main/noarch::tzdata-2024b-h04d1e81_0 \n  wheel              pkgs/main/osx-arm64::wheel-0.44.0-py313hca03da5_0 \n  xz                 pkgs/main/osx-arm64::xz-5.4.6-h80987f9_1 \n  zlib               pkgs/main/osx-arm64::zlib-1.2.13-h18a0788_1 \n\n\nProceed ([y]/n)? y\n\n\nDownloading and Extracting Packages\n\nPreparing transaction: done                                                                          \nVerifying transaction: done                                                                          \nExecuting transaction: done                                                                        \n#                                                                                                    \n# To activate this environment, use                                                                  \n#                                                                                                    \n#     $ conda activate ds                                                                            \n#                                                                                                    \n# To deactivate an active environment, use                                                           \n#\n#     $ conda deactivate\n</code></pre>"},{"location":"chapters/00-setup/#pip-install-transcript","title":"Pip Install Transcript","text":"<p>(ds) src/line-plot $ pip install matplotlib</p> <pre><code>Collecting matplotlib\n  Downloading matplotlib-3.9.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\nCollecting contourpy&gt;=1.0.1 (from matplotlib)\n  Downloading contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.4 kB)\nCollecting cycler&gt;=0.10 (from matplotlib)\n  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting fonttools&gt;=4.22.0 (from matplotlib)\n  Downloading fonttools-4.55.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (164 kB)\nCollecting kiwisolver&gt;=1.3.1 (from matplotlib)\n  Downloading kiwisolver-1.4.7-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\nCollecting numpy&gt;=1.23 (from matplotlib)\n  Downloading numpy-2.1.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\nCollecting packaging&gt;=20.0 (from matplotlib)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting pillow&gt;=8 (from matplotlib)\n  Downloading pillow-11.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.1 kB)\nCollecting pyparsing&gt;=2.3.1 (from matplotlib)\n  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\nCollecting python-dateutil&gt;=2.7 (from matplotlib)\n  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting six&gt;=1.5 (from python-dateutil&gt;=2.7-&gt;matplotlib)\n  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\nDownloading matplotlib-3.9.2-cp313-cp313-macosx_11_0_arm64.whl (7.8 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.8/7.8 MB 35.2 MB/s eta 0:00:00\nDownloading contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl (255 kB)\nUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\nDownloading fonttools-4.55.0-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.8/2.8 MB 19.8 MB/s eta 0:00:00\nDownloading kiwisolver-1.4.7-cp313-cp313-macosx_11_0_arm64.whl (63 kB)\nDownloading numpy-2.1.3-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 5.1/5.1 MB 33.8 MB/s eta 0:00:00\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\nDownloading pillow-11.0.0-cp313-cp313-macosx_11_0_arm64.whl (3.0 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.0/3.0 MB 28.6 MB/s eta 0:00:00\nDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\nUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\nUsing cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: six, pyparsing, pillow, packaging, numpy, kiwisolver, fonttools, cycler, python-dateutil, contourpy, matplotlib\nSuccessfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 numpy-2.1.3 packaging-24.2 pillow-11.0.0 pyparsing-3.2.0 python-dateutil-2.9.0.post0 six-1.16.0\n(ds) src/line-plot $ python line-plot.py   \n2024-11-15 07:14:21.701 python[53332:2841291] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-11-15 07:14:21.701 python[53332:2841291] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n</code></pre>"},{"location":"chapters/01-foundations/","title":"Foundations of Data Science","text":""},{"location":"chapters/01-foundations/#introduction-to-data-science-and-its-applications","title":"Introduction to Data Science and Its Applications","text":"<p>Data science is the discipline of extracting meaningful insights from data by combining statistics, programming, and domain expertise. It powers many of the services and tools we use every day\u2014from recommendation engines on streaming platforms to real-time fraud detection in banking. Governments, businesses, and non-profits alike depend on data science to make evidence-based decisions and improve efficiency.</p> <p>Applications of data science span nearly every field:</p> <ul> <li>Healthcare: Predicting disease risks, optimizing treatment effectiveness, and analyzing healthcare costs.</li> <li>Finance: Credit scoring, algorithmic trading, and fraud detection.</li> <li>Retail: Personalized recommendations and demand forecasting.</li> <li>Transportation: Route optimization and autonomous vehicle navigation.</li> <li>Environmental Science: Climate modeling and resource management.</li> </ul>"},{"location":"chapters/01-foundations/#first-lab-exploring-sample-datasets","title":"First Lab: Exploring Sample Datasets","text":"<p>To begin, we will explore real datasets. A simple but practical task is to generate a CSV file of per-capita annual healthcare costs for 2023 across the 100 largest countries. You will then use Python to:</p> <ol> <li>Load the data into a Pandas DataFrame.</li> <li>Compute summary statistics such as mean, median, and standard deviation.</li> <li>Create visualizations such as bar charts and scatter plots.</li> <li>Ask ChatGPT (or another LLM) to interpret the results and suggest insights.</li> </ol> <p>World Bank Per Capita Healthcare Costs</p> <p>Here is a sample of what this data looks like:</p> <pre><code>Country Name,Country Code,health_exp_pc_ppp_2022\nAfrica Eastern and Southern,AFE,228\nAfghanistan,AFG,383\nAfrica Western and Central,AFW,201\nAngola,AGO,217\nAlbania,ALB,1186\nAndorra,AND,5136\nArab World,ARB,776\nUnited Arab Emirates,ARE,3814\nArgentina,ARG,2664\nArmenia,ARM,1824\nAntigua and Barbuda,ATG,1436\n</code></pre> <p>Note that this list from the World Bank contains not only countries but also regions.</p> <p>This exercise introduces data cleaning, exploration, and visualization, which form the foundation of every data science project.</p> <p>Suggested MicroSim: Exploring Data Points (students add/remove points on a scatter plot to see how the distribution changes).</p>"},{"location":"chapters/01-foundations/#why-python-for-data-science","title":"Why Python for Data Science?","text":"<p>Python is the most widely used programming language for data science. It is popular because of:</p> <ul> <li>A rich ecosystem of libraries (NumPy, Pandas, scikit-learn, Matplotlib, PyTorch).</li> <li>Readable, beginner-friendly syntax.</li> <li>Strong community support and open-source resources.</li> </ul> <p>Over the past 15 years, Python has steadily risen to become the dominant language in data science. Other languages such as R, Java, and Julia are used in specific contexts, but Python\u2019s versatility has made it the industry standard.</p> <p>Here is an interactive time-series chart showing the change in popularity of different languages used in data science.  You can hover over each year to see what percent each language had in data science that year.</p>"},{"location":"chapters/01-foundations/#key-insights-from-chart","title":"Key Insights from Chart:","text":"<ol> <li>Python's Rise: Python showed steady growth from 2010-2018, then accelerated dramatically after 2018 due to AI/ML boom, reaching 25%+ market share by 2025.</li> <li>R's Stability: R maintained consistent popularity (3-5%) throughout the period, remaining strong in academic and statistical research domains.</li> <li>SQL's Persistence: SQL showed steady growth and remained essential for data manipulation, reaching ~8% by 2025.</li> <li>Java's Decline: Java's popularity in data science decreased from ~20% to ~7% as Python gained dominance in ML/AI applications.</li> <li>JavaScript's Growth: JavaScript emerged as a data visualization tool, growing from ~2% to ~6% by 2025.</li> </ol> <p>Note</p> <p>This chart was generated by Generative AI using Claude Sonnet 4.0 using the Chart.js JavaScript library.  You can view the Data Science Programming Language Trends MicroSim to learn more.</p>"},{"location":"chapters/01-foundations/#understanding-the-data-science-workflow","title":"Understanding the Data Science Workflow","text":"<p>Every data science project follows a structured workflow:</p> <p>This workflow is iterative. A failed model often sends us back to collect new data or engineer better features.</p> <p>Above is an interactive infographic that allows you to explore the six steps in a typical data science workflow.  For each step, hover over the step and view the text description below the step.</p> <ol> <li>Define the problem \u2013 Clarify what question is being answered.</li> <li>Collect data \u2013 Gather raw data from reliable sources.</li> <li>Clean and preprocess data \u2013 Handle missing values, errors, and inconsistencies.</li> <li>Explore and visualize \u2013 Use plots and descriptive statistics to understand patterns.</li> <li>Modeling and Analysis \u2013 Build predictive or explanatory models.</li> <li>Deploy and communicate results \u2013 Share findings with stakeholders.</li> </ol>"},{"location":"chapters/01-foundations/#four-types-of-data-representations","title":"Four Types of Data Representations","text":"<p>In this course we will be looking at many ways to represent both raw data as well as connected knowledge.  Here is an interactive illustration of these four ways we represent different types of information.</p> <p>These types are:</p> <ol> <li>Images - Visual data represented as pixel arrays with RGB color values. Each pixel contains red, green, and blue color components. Common in computer vision, medical imaging, satellite imagery, and photo recognition. Neural networks like CNNs are specifically designed to process this type of spatial data structure.</li> <li>Sequences - Sequences: Ordered data where position and timing matter critically. Examples include time series data, natural language text, DNA sequences, audio signals, and stock prices. RNNs, LSTMs, and Transformers are designed to capture temporal dependencies and patterns in sequential data.</li> <li>Tabular -  Structured data organized in rows and columns, similar to spreadsheets or databases. Each row represents an observation and each column represents a feature or variable. This is the most common data type in traditional machine learning, handled well by algorithms like random forests, SVM, and gradient boosting.  We can use Python data frames to manipulate tabular data.</li> <li>Graph - Graph: Network data representing relationships and connections between entities. Nodes represent objects (people, websites, molecules) while edges represent relationships (friendships, links, bonds). Used in social network analysis, recommendation systems, knowledge graphs, and molecular modeling. Graph Neural Networks (GNNs) are specialized for this data type.</li> </ol> <p>Future chapters will focus on different ways we represent this information and how our models vary based on the type of data we are working with.</p>"},{"location":"chapters/01-foundations/#basic-atomic-data-types-and-structures-in-python","title":"Basic Atomic Data Types and Structures in Python","text":"<p>Before analyzing data, students must understand how Python stores fundamental atomic entities like numbers and string.  In this course we will look at some of the core Python atomic atomic data types include:</p> <ul> <li>Integers (whole numbers, e.g., <code>42</code>)</li> <li>Floats (decimal numbers, e.g., <code>3.14</code>)</li> <li>Strings (text, e.g., <code>\"data science\"</code>)</li> <li>Booleans (<code>True</code> or <code>False</code>)</li> </ul> <p>Core data structures include:</p> <ul> <li>Lists \u2013 ordered, mutable collections (e.g., <code>[1,2,3]</code>)</li> <li>Tuples \u2013 ordered, immutable collections (e.g., <code>(1,2,3)</code>)</li> <li>Dictionaries \u2013 key-value pairs (e.g., <code>{\"name\": \"Alice\", \"age\": 20}</code>)</li> <li>Sets \u2013 unordered, unique elements (e.g., <code>{1,2,3}</code>)</li> </ul> <p>Later in the course, we will rely heavily on NumPy arrays and Pandas DataFrames, which are optimized for data manipulation.</p>"},{"location":"chapters/01-foundations/#head","title":"&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD","text":""},{"location":"chapters/01-foundations/#understanding-the-data-science-workflow_1","title":"Understanding the Data Science Workflow","text":"<p>Every data science project follows a structured workflow:</p> <ol> <li>Define the problem \u2013 Clarify what question is being answered.</li> <li>Collect data \u2013 Gather raw data from reliable sources.</li> <li>Clean and preprocess data \u2013 Handle missing values, errors, and inconsistencies.</li> <li>Explore and visualize \u2013 Use plots and descriptive statistics to understand patterns.</li> <li>Modeling \u2013 Build predictive or explanatory models.</li> <li>Evaluate \u2013 Use metrics to test accuracy and generalizability.</li> <li>Deploy and communicate results \u2013 Share findings with stakeholders.</li> </ol> <p>This workflow is iterative. A failed model often sends us back to collect new data or engineer better features.</p> <p>7836e01 (updates)</p>"},{"location":"chapters/01-foundations/#microsim-data-science-workflow-infographic","title":"MicroSim \u2013 Data Science Workflow Infographic","text":"<p>Students can explore an interactive infographic where clicking each stage of the workflow reveals its purpose, key tools, and example questions.</p>"},{"location":"chapters/01-foundations/#head_1","title":"&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD","text":"<p>7836e01 (updates)</p>"},{"location":"chapters/01-foundations/#data-science-roles-and-career-paths","title":"Data Science Roles and Career Paths","text":"<p>Data science is a team effort, involving many specialized roles:</p> <ul> <li>Data Scientist: Builds models, interprets results, and communicates insights.</li> <li>Data Engineer: Designs pipelines and storage systems for reliable data access.</li> <li>Machine Learning Engineer: Deploys and optimizes models in production systems.</li> <li>Business Analyst: Translates data insights into actionable strategies.</li> <li>Ethics &amp; Compliance Specialist: Ensures fairness, transparency, and privacy in projects.</li> </ul> <p>These roles often overlap, and many entry-level positions expect a blend of programming, statistics, and communication skills.</p>"},{"location":"chapters/01-foundations/#head_2","title":"&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD","text":"<p>7836e01 (updates)</p>"},{"location":"chapters/01-foundations/#ethics-and-best-practices-in-data-science","title":"Ethics and Best Practices in Data Science","text":"<p>Data science has great potential, but also significant risks. Poorly designed or biased models can reinforce inequalities or cause harm. To practice ethical data science, we must:</p> <ul> <li>Protect privacy: Respect data ownership and confidentiality.</li> <li>Avoid bias: Check datasets and models for fairness across subgroups.</li> <li>Be transparent: Document methods and assumptions clearly.</li> <li>Ensure reproducibility: Use version control and pipelines so results can be verified.</li> <li>Balance efficiency and responsibility: Consider environmental and social impacts.</li> </ul> <p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p>"},{"location":"chapters/01-foundations/#sample-hands-on-lab-exploring-sample-datasets-with-python-dataframes","title":"Sample Hands-On Lab: Exploring Sample Datasets with Python Dataframes","text":"<p>To begin, we will explore a real-world datasets.  Let's say a friend of yours complained that the healthcare costs in the country that you live it were unreasonably high compared to other countries.  Can you provide evidence to prove or disprove this claim?</p> <p>A simple but practical task is to generate a CSV file of per-capita annual healthcare costs for 2023 across the 100 largest countries. </p> <p>You will then use Python to:</p> <ol> <li>Load the data into a Pandas DataFrame.</li> <li>Compute summary statistics such as mean, median, and standard deviation.</li> <li>Create visualizations such as bar charts and scatter plots.</li> <li>Ask ChatGPT (or another LLM) to interpret the results and suggest insights.</li> </ol> <p>Here is a sample of what this data looks like:</p> <pre><code>Country Name,Country Code,Health_Exp_Per_Capita_2022\nAfrica Eastern and Southern,AFE,228\nAfghanistan,AFG,383\nAfrica Western and Central,AFW,201\nAngola,AGO,217\nAlbania,ALB,1186\nAndorra,AND,5136\nArab World,ARB,776\nUnited Arab Emirates,ARE,3814\nArgentina,ARG,2664\nArmenia,ARM,1824\nAntigua and Barbuda,ATG,1436\n</code></pre> <p>You can download this sample data here: Worldwide Healthcare Costs Per Capita for 2022</p> <p>Note that this list from the World Bank includes not just countries, but also regions like \"Africa Wester and Central\". The third column is in US dollars</p> <p>This exercise introduces data cleaning, exploration, and visualization, which form the foundation of every data science project.</p> <p>\u2705 This completes the Foundations of Data Science chapter, preparing students for Week 1 of the course.</p> <p>=======</p> <p>\u2705 This completes the Foundations of Data Science chapter, preparing students for Week 1 of the course.</p> <p>7836e01 (updates)</p>"},{"location":"chapters/02-data-exploration/","title":"Data Exploration and Visualization","text":"<ol> <li>Loading and examining datasets with pandas</li> <li>Creating basic plots with matplotlib</li> <li>MicroSim: Interactive data visualization</li> <li>Identifying patterns in data through visual exploration</li> <li>Data profiling and quality assessment</li> <li>Handling missing values and outliers</li> <li>Exploratory data analysis techniques</li> </ol>"},{"location":"chapters/02-data-exploration/ydata-profiling/","title":"YData Profiling Tutorial: Comprehensive Data Analysis","text":""},{"location":"chapters/02-data-exploration/ydata-profiling/#overview","title":"Overview","text":"<p>YData Profiling (formerly pandas-profiling) is a powerful Python library that generates comprehensive reports for exploratory data analysis. This tutorial demonstrates its capabilities using a synthetic e-commerce customer dataset designed to showcase various data quality issues and patterns that YData Profiling excels at detecting.</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#installation","title":"Installation","text":"<p>First, install YData Profiling:</p> <pre><code>pip install ydata-profiling\n</code></pre> <p>For Jupyter notebooks, you might also want:</p> <pre><code>pip install ydata-profiling[notebook]\n</code></pre>"},{"location":"chapters/02-data-exploration/ydata-profiling/#dataset-overview","title":"Dataset Overview","text":"<p>Our tutorial dataset contains 503 rows of e-commerce customer data with 16 columns featuring:</p> <ul> <li>Missing values in multiple columns (ages, income, phone numbers, etc.)</li> <li>Data quality issues (age outliers, inconsistent phone formatting)</li> <li>Various data types (numeric, categorical, datetime, boolean, text)</li> <li>High cardinality categorical variables (cities)</li> <li>Correlations between variables (age and product preferences)</li> <li>Duplicate rows for detection testing</li> <li>Skewed distributions (income follows log-normal distribution)</li> </ul>"},{"location":"chapters/02-data-exploration/ydata-profiling/#basic-usage","title":"Basic Usage","text":""},{"location":"chapters/02-data-exploration/ydata-profiling/#1-generate-a-simple-report","title":"1. Generate a Simple Report","text":"<pre><code>import pandas as pd\nfrom ydata_profiling import ProfileReport\n\n# Load the dataset\ndf = pd.read_csv('ecommerce_customer_data.csv')\n\n# Generate basic profile report\nprofile = ProfileReport(df, title=\"E-commerce Customer Data Analysis\")\n\n# Save to HTML file\nprofile.to_file(\"basic_report.html\")\n\n# Display in Jupyter notebook\n# profile.to_notebook_iframe()\n</code></pre>"},{"location":"chapters/02-data-exploration/ydata-profiling/#2-customized-report-with-advanced-configuration","title":"2. Customized Report with Advanced Configuration","text":"<pre><code># Advanced configuration for more detailed analysis\nprofile = ProfileReport(\n    df,\n    title=\"Advanced E-commerce Data Analysis\",\n    dataset={\n        \"description\": \"Synthetic e-commerce customer dataset for YData Profiling demonstration\",\n        \"creator\": \"Data Science Tutorial\",\n        \"author\": \"Tutorial Author\"\n    },\n    variables={\n        \"descriptions\": {\n            \"customer_id\": \"Unique identifier for each customer\",\n            \"age\": \"Customer age in years\",\n            \"annual_income\": \"Customer's annual income in USD\",\n            \"total_spent\": \"Total amount spent by customer\",\n            \"satisfaction_score\": \"Customer satisfaction rating (1-10)\"\n        }\n    },\n    correlations={\n        \"pearson\": {\"calculate\": True},\n        \"spearman\": {\"calculate\": True},\n        \"kendall\": {\"calculate\": False},  # Skip Kendall for performance\n        \"phi_k\": {\"calculate\": True},\n        \"cramers\": {\"calculate\": True},\n    },\n    missing_diagrams={\n        \"bar\": True,\n        \"matrix\": True,\n        \"heatmap\": True,\n        \"dendrogram\": True,\n    },\n    duplicates={\n        \"head\": 10,  # Show first 10 duplicate rows\n        \"key\": None  # Check entire row for duplicates\n    },\n    samples={\n        \"head\": 5,\n        \"tail\": 5,\n        \"random\": 10\n    },\n    reject_variables=False,  # Don't automatically reject any variables\n    infer_dtypes=True,      # Automatically infer better data types\n    interactions={\n        \"continuous\": True,   # Analyze continuous variable interactions\n        \"targets\": []        # Specify target variables if doing supervised learning\n    }\n)\n\nprofile.to_file(\"advanced_report.html\")\n</code></pre>"},{"location":"chapters/02-data-exploration/ydata-profiling/#key-features-demonstrated","title":"Key Features Demonstrated","text":""},{"location":"chapters/02-data-exploration/ydata-profiling/#1-data-types-and-overview","title":"1. Data Types and Overview","text":"<p>YData Profiling automatically detects and categorizes:</p> <ul> <li>Numerical variables: age, annual_income, total_spent, satisfaction_score</li> <li>Categorical variables: gender, education_level, favorite_category</li> <li>DateTime variables: registration_date</li> <li>Boolean variables: premium_member</li> <li>Text variables: last_review</li> <li>High cardinality categorical: city (60+ unique values)</li> </ul>"},{"location":"chapters/02-data-exploration/ydata-profiling/#2-missing-data-analysis","title":"2. Missing Data Analysis","text":"<p>The report provides multiple visualizations for missing data:</p> <ul> <li>Bar chart: Shows missing count per column</li> <li>Matrix plot: Visualizes missing data patterns</li> <li>Heatmap: Shows correlations in missingness</li> <li>Dendrogram: Clusters variables by missing patterns</li> </ul> <p>Our dataset includes strategic missing values: - 25 missing ages (5%) - 35 missing incomes (7%) - 40 missing credit scores (8%) - 25 missing phone numbers (5%)</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#3-data-quality-issues-detection","title":"3. Data Quality Issues Detection","text":"<p>YData Profiling automatically identifies:</p> <p>Outliers:  - Age outliers (150 and 5 years old) are flagged as extreme values - Income distribution shows high-value outliers</p> <p>Inconsistent Formatting: - Phone numbers in multiple formats: (xxx) xxx-xxxx, xxx-xxx-xxxx, xxx.xxx.xxxx, xxxxxxxxxx - Gender entries with inconsistent capitalization: Male, M, m, male</p> <p>Data Type Issues: - Suggests better data types for mixed-format columns</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#4-distribution-analysis","title":"4. Distribution Analysis","text":"<p>For each numerical variable, the report shows:</p> <ul> <li>Descriptive statistics: mean, median, std, quartiles</li> <li>Distribution plots: histograms with optional normal distribution overlay</li> <li>Skewness and kurtosis: measures of distribution shape</li> </ul> <p>Our dataset demonstrates: - Normal distribution: age (with outliers) - Log-normal distribution: annual_income (right-skewed) - Poisson-like distribution: total_purchases - Gamma distribution: total_spent</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#5-correlation-analysis","title":"5. Correlation Analysis","text":"<p>Multiple correlation methods reveal relationships:</p> <ul> <li>Pearson: Linear relationships between continuous variables</li> <li>Spearman: Monotonic relationships (rank-based)</li> <li>Phi-K: Correlation for categorical variables</li> <li>Cram\u00e9r's V: Association between categorical variables</li> </ul> <p>Expected correlations in our dataset: - Age and favorite product category - Income and total spent - Education level and income</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#6-categorical-variable-analysis","title":"6. Categorical Variable Analysis","text":"<p>For categorical variables, the report provides:</p> <ul> <li>Frequency tables: Count and percentage for each category</li> <li>Bar charts: Visual representation of category distributions</li> <li>Cardinality warnings: Flags for high-cardinality variables like 'city'</li> </ul>"},{"location":"chapters/02-data-exploration/ydata-profiling/#7-duplicate-detection","title":"7. Duplicate Detection","text":"<p>The report identifies: - 3 duplicate rows intentionally added to the dataset - Exact matches across all columns - Percentage of duplicates: Impact on dataset size</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#8-text-analysis","title":"8. Text Analysis","text":"<p>For text columns like 'last_review': - Length distribution: Character count statistics - Sample values: Examples of text entries - Completeness: Percentage of non-null text entries</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#advanced-configuration-options","title":"Advanced Configuration Options","text":""},{"location":"chapters/02-data-exploration/ydata-profiling/#minimal-configuration-for-large-datasets","title":"Minimal Configuration for Large Datasets","text":"<pre><code># For large datasets, use minimal configuration for faster processing\nprofile = ProfileReport(\n    df,\n    title=\"Quick Analysis\",\n    minimal=True,  # Faster processing, fewer features\n    correlations={\n        \"pearson\": {\"calculate\": True},\n        \"spearman\": {\"calculate\": False},\n        \"kendall\": {\"calculate\": False},\n        \"phi_k\": {\"calculate\": False},\n        \"cramers\": {\"calculate\": False},\n    },\n    missing_diagrams={\n        \"bar\": True,\n        \"matrix\": False,\n        \"heatmap\": False,\n        \"dendrogram\": False,\n    }\n)\n</code></pre>"},{"location":"chapters/02-data-exploration/ydata-profiling/#sensitive-data-configuration","title":"Sensitive Data Configuration","text":"<pre><code># For datasets with sensitive information\nprofile = ProfileReport(\n    df,\n    title=\"Sensitive Data Analysis\",\n    samples={\"head\": 0, \"tail\": 0, \"random\": 0},  # Don't show actual data\n    duplicates={\"head\": 0},  # Don't show duplicate examples\n    sensitive=True  # Additional privacy protections\n)\n</code></pre>"},{"location":"chapters/02-data-exploration/ydata-profiling/#interpreting-the-report","title":"Interpreting the Report","text":""},{"location":"chapters/02-data-exploration/ydata-profiling/#1-executive-summary","title":"1. Executive Summary","text":"<p>The report begins with high-level insights: - Dataset dimensions (503 rows \u00d7 16 columns) - Missing cells percentage - Duplicate rows count - Data types distribution</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#2-variable-analysis","title":"2. Variable Analysis","text":"<p>Each variable gets detailed analysis: - Distinct count: Unique values - Missing count: Null values - Memory usage: Storage requirements - Type-specific metrics: Based on variable type</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#3-warnings-and-alerts","title":"3. Warnings and Alerts","text":"<p>YData Profiling automatically flags: - High cardinality: Variables with many unique values - High correlation: Potentially redundant variables - Skewed distributions: Variables needing transformation - Constant values: Variables with no variation - Missing values: Variables with significant missingness</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#best-practices","title":"Best Practices","text":""},{"location":"chapters/02-data-exploration/ydata-profiling/#1-performance-optimization","title":"1. Performance Optimization","text":"<p>For large datasets: - Use <code>minimal=True</code> for quick overview - Disable expensive correlation calculations - Limit sample sizes - Use <code>lazy=False</code> for immediate computation</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#2-customization-tips","title":"2. Customization Tips","text":"<ul> <li>Add variable descriptions for better documentation</li> <li>Configure correlation methods based on data types</li> <li>Customize missing data visualizations</li> <li>Set appropriate duplicate detection keys</li> </ul>"},{"location":"chapters/02-data-exploration/ydata-profiling/#3-integration-workflow","title":"3. Integration Workflow","text":"<pre><code># Typical data science workflow integration\ndef analyze_dataset(df, output_path=\"profile_report.html\"):\n    \"\"\"Generate comprehensive data profile report.\"\"\"\n\n    # Basic data info\n    print(f\"Dataset shape: {df.shape}\")\n    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n\n    # Generate profile\n    profile = ProfileReport(\n        df,\n        title=f\"Data Analysis Report - {datetime.now().strftime('%Y-%m-%d')}\",\n        minimal=False,\n        correlations={\"phi_k\": {\"calculate\": True}},\n        missing_diagrams={\"matrix\": True, \"bar\": True}\n    )\n\n    # Save report\n    profile.to_file(output_path)\n    print(f\"Report saved to: {output_path}\")\n\n    return profile\n\n# Usage\nprofile = analyze_dataset(df, \"customer_analysis_report.html\")\n</code></pre>"},{"location":"chapters/02-data-exploration/ydata-profiling/#common-use-cases","title":"Common Use Cases","text":""},{"location":"chapters/02-data-exploration/ydata-profiling/#1-initial-data-exploration","title":"1. Initial Data Exploration","text":"<p>Perfect for understanding new datasets before analysis: - Data quality assessment - Variable relationship discovery - Missing data patterns - Distribution characteristics</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#2-data-quality-monitoring","title":"2. Data Quality Monitoring","text":"<p>Regular profiling for ongoing data pipelines: - Detect data drift - Monitor missing value trends - Track distribution changes - Identify new data quality issues</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#3-documentation-generation","title":"3. Documentation Generation","text":"<p>Automated documentation for datasets: - Share with stakeholders - Document data characteristics - Support reproducible research - Create data dictionaries</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#conclusion","title":"Conclusion","text":"<p>YData Profiling provides comprehensive automated exploratory data analysis that would take hours to perform manually. This tutorial dataset demonstrates its ability to:</p> <ul> <li>Automatically detect various data types and quality issues</li> <li>Generate publication-ready visualizations</li> <li>Identify patterns and relationships</li> <li>Provide actionable insights for data cleaning</li> <li>Create comprehensive documentation</li> </ul> <p>The tool is invaluable for data scientists, analysts, and anyone working with datasets who needs quick, thorough data understanding.</p>"},{"location":"chapters/02-data-exploration/ydata-profiling/#next-steps","title":"Next Steps","text":"<p>After reviewing the YData Profiling report:</p> <ol> <li>Address data quality issues: Clean outliers, standardize formats</li> <li>Handle missing values: Decide on imputation or removal strategies  </li> <li>Feature engineering: Use correlation insights for feature selection</li> <li>Distribution analysis: Consider transformations for skewed variables</li> <li>Duplicate handling: Remove or investigate duplicate records</li> </ol> <p>YData Profiling provides the foundation for informed data preprocessing and analysis decisions.</p>"},{"location":"chapters/03-data-visualization/","title":"Data Visualization Techniques","text":"<ol> <li>Principles of effective data visualization</li> <li>Matplotlib fundamentals and customization</li> <li>Plotly for interactive visualizations</li> <li>Statistical plots and distributions</li> <li>Time series visualization</li> <li>Multi-dimensional data representation</li> <li>MicroSim: Visualization parameter explorer</li> </ol>"},{"location":"chapters/04-statistics/","title":"Statistical Foundations","text":"<ol> <li>Descriptive statistics and summary measures</li> <li>Understanding distributions and variability</li> <li>MicroSim: Statistical parameter exploration</li> <li>Introduction to probability concepts</li> <li>Central limit theorem and sampling distributions</li> <li>Hypothesis testing fundamentals</li> <li>Correlation vs. causation</li> </ol>"},{"location":"chapters/05-linear-regression/","title":"Simple Linear Regression","text":"<ol> <li>Mathematical foundations of linear regression</li> <li>Implementing regression from scratch</li> <li>MicroSim: Interactive regression line fitting</li> <li>Interpreting coefficients and model output</li> <li>Assumptions of linear regression</li> <li>Residual analysis and diagnostics</li> <li>Making predictions with linear models</li> </ol>"},{"location":"chapters/06-models/","title":"Model Evaluation and Validation","text":"<ol> <li>Measuring model performance (R\u00b2, MSE, MAE)</li> <li>Training and testing data splits</li> <li>MicroSim: Cross-validation simulation</li> <li>Understanding overfitting and underfitting</li> <li>Bias-variance trade-off</li> <li>Model selection criteria</li> <li>Performance metrics for different problem types</li> </ol>"},{"location":"chapters/07-multiple-linear-regression/","title":"Multiple Linear Regression","text":"<ol> <li>Extending to multiple predictor variables</li> <li>Feature selection and engineering</li> <li>MicroSim: Multi-dimensional regression explorer</li> <li>Handling categorical variables</li> <li>Interaction effects and polynomial terms</li> <li>Multicollinearity detection and treatment</li> <li>Model interpretation in multiple dimensions</li> </ol>"},{"location":"chapters/08-numpy/","title":"Introduction to NumPy and Advanced Computation","text":"<ol> <li>NumPy arrays and vectorized operations</li> <li>Matrix operations for regression</li> <li>MicroSim: Linear algebra visualization</li> <li>Computational efficiency in data science</li> <li>Broadcasting and array manipulation</li> <li>Mathematical functions and statistics</li> <li>Integration with pandas and matplotlib</li> </ol>"},{"location":"chapters/09-nonlinear-models/","title":"Non-linear Models and Feature Engineering","text":"<ol> <li>Polynomial regression and feature transformation</li> <li>Understanding non-linear relationships</li> <li>MicroSim: Polynomial degree explorer</li> <li>Feature engineering techniques</li> <li>Basis functions and kernel methods</li> <li>Model complexity and interpretation trade-offs</li> <li>When to use non-linear approaches</li> </ol>"},{"location":"chapters/10-regularization/","title":"Regularization Techniques","text":"<ol> <li>Ridge and Lasso regularization</li> <li>MicroSim: Bias-variance trade-off explorer</li> <li>Model selection strategies</li> <li>Cross-validation for hyperparameter tuning</li> <li>Elastic Net and other regularization methods</li> <li>Feature selection through regularization</li> <li>Preventing overfitting in complex models</li> </ol>"},{"location":"chapters/11-machine-learning/","title":"Introduction to Machine Learning","text":"<ol> <li>Supervised vs. unsupervised learning</li> <li>Classification and regression problems</li> <li>Decision trees and ensemble methods</li> <li>MicroSim: Algorithm comparison explorer</li> <li>Feature importance and selection</li> <li>Model interpretability techniques</li> <li>Introduction to scikit-learn</li> </ol>"},{"location":"chapters/12-neural-networks/","title":"Neural Networks and Deep Learning","text":"<ol> <li>Neural networks and deep learning concepts</li> <li>Perceptrons and multi-layer networks</li> <li>Activation functions and backpropagation</li> <li>MicroSim: Neural network playground</li> <li>Training neural networks</li> <li>Common architectures and applications</li> <li>When to use neural networks vs. traditional methods</li> </ol>"},{"location":"chapters/13-pytorch/","title":"Introduction to Machine Learning with PyTorch","text":"<ol> <li>Building simple networks with PyTorch</li> <li>Tensors and automatic differentiation</li> <li>Creating and training models</li> <li>MicroSim: PyTorch model builder</li> <li>Comparing traditional and deep learning approaches</li> <li>GPU acceleration and optimization</li> <li>Model saving and deployment</li> </ol>"},{"location":"chapters/14-model-evaluation/","title":"Advanced Model Evaluation","text":"<ol> <li>Comprehensive performance metrics</li> <li>ROC curves and AUC analysis</li> <li>Confusion matrices and classification reports</li> <li>MicroSim: Metric comparison explorer</li> <li>Statistical significance testing</li> <li>Model comparison techniques</li> <li>Reporting and communicating results</li> </ol>"},{"location":"chapters/15-projects/","title":"Capstone Project and Model Deployment","text":"<ol> <li>End-to-end data science project planning</li> <li>Model interpretation and communication</li> <li>MicroSim: Model comparison dashboard</li> <li>Best practices and ethical considerations</li> <li>Model deployment strategies</li> <li>Documentation and reproducibility</li> <li>Presenting data science findings</li> </ol>"},{"location":"labs/","title":"List of Labs","text":""},{"location":"labs/#load-csv-data-into-a-python-dataframe","title":"Load CSV Data Into A Python Dataframe","text":"<p>Go to Lab 1</p>"},{"location":"labs/#explore-data","title":"Explore Data","text":"<p>Go to Lab 2</p>"},{"location":"labs/01-dataframe/","title":"Lab 1: Dataframes","text":""},{"location":"labs/01-dataframe/#steps","title":"Steps","text":"<p>These steps assume you have setup your desktop using an IDE such as Visual Studio Code. See the Setup Chapter for details.</p>"},{"location":"labs/01-dataframe/#step-1-load-the-following-dataset-using-your-ide-such-as-visual-studio-code","title":"Step 1: Load the following dataset using your IDE such as Visual Studio Code","text":""},{"location":"labs/01-dataframe/#step-2-load-the-rainbow-csv-extension-into-visual-studio-code","title":"Step 2: Load the Rainbow CSV Extension into Visual Studio Code","text":""},{"location":"labs/01-dataframe/#step-3-load-python-code","title":"Step 3: Load Python Code","text":"<pre><code># Import the pandas library for data manipulation\nimport pandas as pd\n\n# Load the CSV file into a pandas DataFrame\n# This assumes the CSV file is in the same directory as this script\ndf = pd.read_csv('healthcare-per-capita-2022.csv')\n\n# Count the number of rows (lines) in the DataFrame\nline_count = len(df)\n\n# Display the first few rows to verify the data loaded correctly\nprint(\"First 5 rows of the data:\")\nprint(df.head())\n\n# Print the total number of lines\nprint(f\"\\nTotal number of lines in the CSV file: {line_count}\")\n\n# Optional: Display basic information about the DataFrame\nprint(f\"\\nDataFrame shape (rows, columns): {df.shape}\")\nprint(f\"Column names: {list(df.columns)}\")\n</code></pre> <p>If you get the following <code>Module Not Found</code> error, you must make sure that you use pip to install the pandas library.</p> <pre><code>import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n</code></pre> <pre><code>(ds) $ pip install pandas\n</code></pre> <p>Note that the '(ds)' in the prompt means you are working with your ds (data science) virtual Python environment.</p>"},{"location":"labs/01-dataframe/#step-4-run-python-code","title":"Step 4: Run Python Code","text":"<pre><code>python count-lines.py\n</code></pre> <p>Result:</p> <pre><code>python count-lines.py \nFirst 5 rows of the data:\n                  Country_Name Country_Code  Health_Exp_PerCapita_2022\n0  Africa Eastern and Southern          AFE                        228\n1                  Afghanistan          AFG                        383\n2   Africa Western and Central          AFW                        201\n3                       Angola          AGO                        217\n4                      Albania          ALB                       1186\n\nTotal number of lines in the CSV file: 238\n\nDataFrame shape (rows, columns): (238, 3)\nColumn names: ['Country_Name', 'Country_Code', 'Health_Exp_PerCapita_2022']\n</code></pre>"},{"location":"labs/02-explore-data/","title":"Lab 2: Introduction to DataFrames - Loading and Exploring Data","text":""},{"location":"labs/02-explore-data/#objectives","title":"Objectives","text":"<p>Students will learn to: - Load CSV data into a pandas DataFrame - Explore basic DataFrame properties and methods - Display and examine data structure</p>"},{"location":"labs/02-explore-data/#lab-steps","title":"Lab Steps","text":""},{"location":"labs/02-explore-data/#step-1-load-the-data","title":"Step 1: Load the Data","text":"<pre><code>import pandas as pd\n\n# Load the healthcare data\ndf = pd.read_csv('healthcare-per-capita-2022.csv')\n\n# Display the DataFrame\nprint(\"Healthcare Per Capita Data:\")\nprint(df)\n</code></pre> <pre><code>                    Country_Name Country_Code  Health_Exp_PerCapita_2022\n0    Africa Eastern and Southern          AFE                        228\n1                    Afghanistan          AFG                        383\n2     Africa Western and Central          AFW                        201\n3                         Angola          AGO                        217\n4                        Albania          ALB                       1186\n..                           ...          ...                        ...\n233                        Samoa          WSM                        396\n234                  Yemen, Rep.          YEM                        109\n235                 South Africa          ZAF                       1341\n236                       Zambia          ZMB                        208\n237                     Zimbabwe          ZWE                         96\n</code></pre>"},{"location":"labs/02-explore-data/#step-2-explore-dataframe-shape-and-info","title":"Step 2: Explore DataFrame Shape and Info","text":"<pre><code># Check the shape (rows, columns)\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Number of rows: {df.shape[0]}\")\nprint(f\"Number of columns: {df.shape[1]}\")\n\n# Get basic information about the DataFrame\nprint(\"\\nDataFrame Info:\")\ndf.info()\n</code></pre>"},{"location":"labs/02-explore-data/#step-3-examine-column-names-and-data-types","title":"Step 3: Examine Column Names and Data Types","text":"<pre><code># Display column names\nprint(\"Column names:\")\nprint(df.columns.tolist())\n\n# Check data types\nprint(\"\\nData types:\")\nprint(df.dtypes)\n</code></pre> <pre><code>Dataset shape: (238, 3)\nNumber of rows: 238\nNumber of columns: 3\n\nDataFrame Info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 238 entries, 0 to 237\nData columns (total 3 columns):\n #   Column                     Non-Null Count  Dtype \n---  ------                     --------------  ----- \n 0   Country_Name               238 non-null    object\n 1   Country_Code               238 non-null    object\n 2   Health_Exp_PerCapita_2022  238 non-null    int64 \ndtypes: int64(1), object(2)\nmemory usage: 5.7+ KB\n</code></pre>"},{"location":"labs/02-explore-data/#step-4-preview-the-data","title":"Step 4: Preview the Data","text":"<pre><code># Look at first 5 rows\nprint(\"First 5 rows:\")\nprint(df.head())\n\n# Look at last 5 rows\nprint(\"\\nLast 5 rows:\")\nprint(df.tail())\n</code></pre> <p>Results:</p> <pre><code>First 5 rows:\n                  Country_Name Country_Code  Health_Exp_PerCapita_2022\n0  Africa Eastern and Southern          AFE                        228\n1                  Afghanistan          AFG                        383\n2   Africa Western and Central          AFW                        201\n3                       Angola          AGO                        217\n4                      Albania          ALB                       1186\n\nLast 5 rows:\n     Country_Name Country_Code  Health_Exp_PerCapita_2022\n233         Samoa          WSM                        396\n234   Yemen, Rep.          YEM                        109\n235  South Africa          ZAF                       1341\n236        Zambia          ZMB                        208\n237      Zimbabwe          ZWE                         96\n</code></pre>"},{"location":"labs/02-explore-data/#step-5-get-basic-information-about-the-dataframe","title":"Step 5: Get basic information about the DataFrame","text":"<pre><code>print(\"\\nDataFrame Info:\")\ndf.info()\n</code></pre> <pre><code>DataFrame Info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 238 entries, 0 to 237\nData columns (total 3 columns):\n #   Column                     Non-Null Count  Dtype \n---  ------                     --------------  ----- \n 0   Country_Name               238 non-null    object\n 1   Country_Code               238 non-null    object\n 2   Health_Exp_PerCapita_2022  238 non-null    int64 \ndtypes: int64(1), object(2)\n</code></pre>"},{"location":"labs/02-explore-data/#look-at-a-random-sample-of-5-rows","title":"Look at a random sample of 5 rows","text":"<pre><code>print(\"\\nRandom sample of 5 rows:\")\nprint(df.sample(5))\n</code></pre>"},{"location":"labs/02-explore-data/#step-5-basic-data-exploration","title":"Step 5: Basic Data Exploration","text":"<pre><code># Get basic statistics for numerical columns\nprint(\"Basic statistics:\")\nprint(df.describe())\n\n# Check for missing values\nprint(\"\\nMissing values per column:\")\nprint(df.isnull().sum())\n\n# Count unique values in each column\nprint(\"\\nUnique values per column:\")\nfor col in df.columns:\n    print(f\"{col}: {df[col].nunique()} unique values\")\n</code></pre>"},{"location":"labs/02-explore-data/#questions-for-students","title":"Questions for Students","text":"<ol> <li>How many countries are included in this dataset?</li> <li>What is the data type of each column?</li> <li>Are there any missing values in the dataset?</li> <li>What country has the highest healthcare expenditure per capita?</li> <li>What is the average healthcare expenditure per capita across all countries?</li> </ol>"},{"location":"labs/02-explore-data/#expected-output-discussion","title":"Expected Output Discussion","text":"<p>Students should observe:</p> <ul> <li>The dataset has 238 rows (countries) and 3 columns</li> <li>Country_Name and Country_Code are text (object) data types</li> <li>Health_Exp_PerCapita_2022 is numerical (integer)</li> <li>Whether there are any missing values to handle</li> </ul>"},{"location":"labs/02-explore-data/#extension-activities","title":"Extension Activities","text":"<p>For advanced students:</p> <ul> <li>Sort the data by healthcare expenditure</li> <li>Find countries with expenditure above/below certain thresholds</li> <li>Create simple filtering operations</li> </ul> <p>This lab builds naturally from counting rows to actually working with the data structure,  introducing essential pandas concepts while keeping the complexity manageable for beginners.</p>"},{"location":"labs/03-statistics/","title":"Lab 3 - Statistics","text":""},{"location":"labs/03-statistics/#lab-3-basic-statistical-analysis-with-dataframes","title":"Lab 3: Basic Statistical Analysis with DataFrames","text":""},{"location":"labs/03-statistics/#objectives","title":"Objectives","text":"<p>Students will learn to: - Find minimum and maximum values in a DataFrame - Calculate basic statistical measures (mean, median, standard deviation) - Identify specific rows based on conditions - Use pandas methods for statistical analysis</p>"},{"location":"labs/03-statistics/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Lab 2 (Loading and exploring DataFrames)</li> <li>Understanding of basic statistical concepts</li> </ul>"},{"location":"labs/03-statistics/#lab-steps","title":"Lab Steps","text":""},{"location":"labs/03-statistics/#step-1-load-and-prepare-the-data","title":"Step 1: Load and Prepare the Data","text":"<pre><code>import pandas as pd\n\n# Load the healthcare data\ndf = pd.read_csv('healthcarepercapita2022.csv')\n\n# Display basic info to remind ourselves of the data structure\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nFirst few rows:\")\nprint(df.head())\n</code></pre>"},{"location":"labs/03-statistics/#step-2-find-the-country-with-lowest-healthcare-expenditure","title":"Step 2: Find the Country with Lowest Healthcare Expenditure","text":"<pre><code># Method 1: Using min() and boolean indexing\nmin_expenditure = df['Health_Exp_PerCapita_2022'].min()\nlowest_country = df[df['Health_Exp_PerCapita_2022'] == min_expenditure]\n\nprint(\"Country with LOWEST healthcare expenditure per capita:\")\nprint(f\"Country: {lowest_country['Country_Name'].iloc[0]}\")\nprint(f\"Expenditure: ${min_expenditure:,.2f}\")\n\n# Alternative method using idxmin()\nmin_index = df['Health_Exp_PerCapita_2022'].idxmin()\nprint(f\"\\nAlternative method - Lowest: {df.loc[min_index, 'Country_Name']} (${min_expenditure:,.2f})\")\n</code></pre>"},{"location":"labs/03-statistics/#step-3-find-the-country-with-highest-healthcare-expenditure","title":"Step 3: Find the Country with Highest Healthcare Expenditure","text":"<pre><code># Method 1: Using max() and boolean indexing\nmax_expenditure = df['Health_Exp_PerCapita_2022'].max()\nhighest_country = df[df['Health_Exp_PerCapita_2022'] == max_expenditure]\n\nprint(\"\\nCountry with HIGHEST healthcare expenditure per capita:\")\nprint(f\"Country: {highest_country['Country_Name'].iloc[0]}\")\nprint(f\"Expenditure: ${max_expenditure:,.2f}\")\n\n# Alternative method using idxmax()\nmax_index = df['Health_Exp_PerCapita_2022'].idxmax()\nprint(f\"\\nAlternative method - Highest: {df.loc[max_index, 'Country_Name']} (${max_expenditure:,.2f})\")\n</code></pre>"},{"location":"labs/03-statistics/#step-4-calculate-mean-healthcare-expenditure","title":"Step 4: Calculate Mean Healthcare Expenditure","text":"<pre><code># Calculate the average (mean)\nmean_expenditure = df['Health_Exp_PerCapita_2022'].mean()\n\nprint(f\"\\nAverage (Mean) healthcare expenditure per capita:\")\nprint(f\"${mean_expenditure:,.2f}\")\n\n# Round to 2 decimal places for cleaner display\nprint(f\"Rounded: ${round(mean_expenditure, 2):,.2f}\")\n</code></pre>"},{"location":"labs/03-statistics/#step-5-calculate-median-healthcare-expenditure","title":"Step 5: Calculate Median Healthcare Expenditure","text":"<pre><code># Calculate the median (middle value)\nmedian_expenditure = df['Health_Exp_PerCapita_2022'].median()\n\nprint(f\"\\nMedian healthcare expenditure per capita:\")\nprint(f\"${median_expenditure:,.2f}\")\n\n# Compare mean vs median\nprint(f\"\\nComparison:\")\nprint(f\"Mean:   ${mean_expenditure:,.2f}\")\nprint(f\"Median: ${median_expenditure:,.2f}\")\nif mean_expenditure &gt; median_expenditure:\n    print(\"Mean &gt; Median: Data is likely right-skewed (few very high values)\")\nelif mean_expenditure &lt; median_expenditure:\n    print(\"Mean &lt; Median: Data is likely left-skewed (few very low values)\")\nelse:\n    print(\"Mean \u2248 Median: Data is likely normally distributed\")\n</code></pre>"},{"location":"labs/03-statistics/#step-6-calculate-standard-deviation","title":"Step 6: Calculate Standard Deviation","text":"<pre><code># Calculate standard deviation\nstd_expenditure = df['Health_Exp_PerCapita_2022'].std()\n\nprint(f\"\\nStandard deviation of healthcare expenditure:\")\nprint(f\"${std_expenditure:,.2f}\")\n\n# Interpret the standard deviation\nprint(f\"\\nInterpretation:\")\nprint(f\"About 68% of countries spend between ${mean_expenditure - std_expenditure:,.2f} and ${mean_expenditure + std_expenditure:,.2f} per capita\")\nprint(f\"About 95% of countries spend between ${mean_expenditure - 2*std_expenditure:,.2f} and ${mean_expenditure + 2*std_expenditure:,.2f} per capita\")\n</code></pre>"},{"location":"labs/03-statistics/#step-7-summary-statistics-all-at-once","title":"Step 7: Summary Statistics (All at Once)","text":"<pre><code># Get all basic statistics at once\nprint(\"\\nComplete Statistical Summary:\")\nprint(df['Health_Exp_PerCapita_2022'].describe())\n\n# Create a custom summary\nprint(f\"\\n{'='*50}\")\nprint(\"HEALTHCARE EXPENDITURE ANALYSIS SUMMARY\")\nprint(f\"{'='*50}\")\nprint(f\"Lowest spending country:  {df.loc[df['Health_Exp_PerCapita_2022'].idxmin(), 'Country_Name']}\")\nprint(f\"Highest spending country: {df.loc[df['Health_Exp_PerCapita_2022'].idxmax(), 'Country_Name']}\")\nprint(f\"Range: ${min_expenditure:,.2f} - ${max_expenditure:,.2f}\")\nprint(f\"Mean: ${mean_expenditure:,.2f}\")\nprint(f\"Median: ${median_expenditure:,.2f}\")\nprint(f\"Standard Deviation: ${std_expenditure:,.2f}\")\nprint(f\"Total countries analyzed: {len(df)}\")\n</code></pre> <pre><code>Complete Statistical Summary:\ncount      238.000000\nmean      1930.205882\nstd       2458.454731\nmin         39.000000\n25%        270.000000\n50%        930.500000\n75%       2467.500000\nmax      12434.000000\nName: Health_Exp_PerCapita_2022, dtype: float64\n\n==================================================\nHEALTHCARE EXPENDITURE ANALYSIS SUMMARY\n==================================================\nLowest spending country:  South Sudan\nHighest spending country: United States\nRange: $39.00 - $12,434.00\nMean: $1,930.21\nMedian: $930.50\nStandard Deviation: $2,458.45\nTotal countries analyzed: 238\n</code></pre>"},{"location":"labs/03-statistics/#discussion-questions","title":"Discussion Questions","text":"<ol> <li> <p>Which country spends the least on healthcare per capita? How much do they spend?</p> </li> <li> <p>Which country spends the most on healthcare per capita? How much do they spend?</p> </li> <li> <p>What is the difference between the highest and lowest spending countries?</p> </li> <li> <p>Is the mean higher or lower than the median? What does this tell us about the distribution of healthcare spending?</p> </li> <li> <p>How many countries fall within one standard deviation of the mean?</p> </li> <li> <p>If a country spends $2,000 per capita on healthcare, is this above or below average?</p> </li> </ol>"},{"location":"labs/03-statistics/#extension-activities","title":"Extension Activities","text":"<p>For Advanced Students: <pre><code># Find countries within certain ranges\nprint(\"\\nCountries spending more than $5,000 per capita:\")\nhigh_spenders = df[df['Health_Exp_PerCapita_2022'] &gt; 5000]\nprint(high_spenders[['Country_Name', 'Health_Exp_PerCapita_2022']].sort_values('Health_Exp_PerCapita_2022', ascending=False))\n\n# Calculate what percentage of countries spend above the mean\nabove_mean = len(df[df['Health_Exp_PerCapita_2022'] &gt; mean_expenditure])\npercentage_above_mean = (above_mean / len(df)) * 100\nprint(f\"\\n{above_mean} countries ({percentage_above_mean:.1f}%) spend above the global average\")\n</code></pre></p>"},{"location":"labs/03-statistics/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<ul> <li>Understanding the difference between mean and median</li> <li>Learning to find extreme values in datasets</li> <li>Interpreting standard deviation as a measure of variability</li> <li>Using pandas methods for statistical analysis</li> <li>Connecting statistical concepts to real-world data</li> </ul> <p>This lab builds naturally from the previous exploration lab and introduces fundamental statistical analysis that students will use throughout their data science journey.</p>"},{"location":"prompts/","title":"Sample Generative AI Prompts","text":"<p>The following are a list of sample prompts you can use to generate your own Data Science textbook.  Note that these prompts are grouped into three areas:</p> <ol> <li>Level 1 Prompts: Generating a Leaning Graph from a Course Description</li> <li>Level 2 PromptsGenerating an list of chapters and other book-wide content such as glossaries,  FAQs, and book summaries</li> <li>Generating the chapter content and interactive content within a chapter</li> </ol>"},{"location":"prompts/#level-1-prompts","title":"Level 1 Prompts","text":""},{"location":"prompts/#course-description","title":"Course Description","text":"<ul> <li>Course Description</li> </ul>"},{"location":"prompts/#concept-dependencies","title":"Concept Dependencies","text":"<ul> <li>Concept Dependencies</li> </ul>"},{"location":"prompts/#level-2-prompts","title":"Level 2 Prompts","text":"<ul> <li>Chapter Content Prompt</li> <li>FAQs Prompt</li> <li>Glossary Prompt</li> </ul>"},{"location":"prompts/#level-3-prompts","title":"Level 3 Prompts","text":"<ul> <li>MicroSim Prompt</li> </ul>"},{"location":"prompts/chapter-content/","title":"Chapter Content Prompt","text":"<p>See the prompt here</p>"},{"location":"prompts/concept-dependencies/","title":"Concept Dependencies","text":""},{"location":"prompts/concept-dependencies/#prompt","title":"Prompt","text":"<pre><code>That was perfect.  Thank you very much.\nThe next step is to create a dependency graph\nof all the 150 concepts on the list. \nFor each concept, think about other concepts\nthat this concept depends upon for understanding.\n\nFor each of the 150 concepts return a single row in CSV format.\n\nColumn 1 is the ConceptID (the integer 1 to 150)\nColumn 2 is the ConceptLabel\nColumn 3 is the Dependencies in the form of pipe-delimited list of ConceptIDs\n\nMake sure that Foundation Concepts (prerequisites) like knowledge of Python don't have any dependencies.\nMake sure that every concept except Foundation Concepts have at least one dependency.\n</code></pre>"},{"location":"prompts/concept-enumeration/","title":"Concept Enumeration","text":""},{"location":"prompts/concept-enumeration/#prompt","title":"Prompt","text":"<p>``` prompt     I would like to develop a new course called      \"Introduction to Data Science with Python using AI\". </p> <pre><code>I would like you to generate a list of all the core concepts\nthat we would cover in this course and the dependency\nrelationships between these concepts so we could order\nthem and create an learning graph. This course would assume\nthat students have basic Python programming experience. \nThis course would be a class that covers the following topics:\n\n1. What is data science? \n2. Summary of business needs for employees with data science skills. \n3. Review of Python concepts \n4. How generative AI can help you learn Python \n5. Basic Python libraries for handling data such as NumPy \n6. Python statistical libraries \n7. Python libraries for machine learning \n8. Python libraries for working with graph data \n9. Python libraries for visualization with a focus on Plotly \n10. Python libraries for NLP \n11. Python libraries for vector stores \n12. Python libraries for GenAI including LangChain and LlamaIndex\n\nPlease create a numbered list of the 250 most important topics \nthat would be taught in this course. Begin with the prerequisite\nconcepts and then proceed to defining key terms. Then include\nthe core concepts used in Python data analysis.\nFinally, close with some potential final project concepts \nthat students could create. Think carefully about the ordering \nof the concepts from simple to more abstract. For each concept, \nreturn a conceptID followed by short name which would be the\nlabel for the concept in a learning graph (concept dependency).\nFeel free to use short names and abbreviations.\n</code></pre> <p>ChatGPT</p> <p>Thought for 1m 34s</p> <ol> <li>DS Definition - Definition of Data Science</li> <li>DS Importance - Importance of Data Science</li> <li>DS vs DA - Data Science vs. Data Analysis</li> <li>DS Workflow - Data Science Workflow</li> <li>DS Roles - Roles in Data Science</li> <li>DS DataCollection - Data Collection Methods</li> <li>DS DataCleaning - Data Cleaning Processes</li> <li>DS DataExploration - Exploratory Data Analysis</li> <li>DS FeatureEngineering - Feature Engineering</li> <li>DS Modeling - Modeling and Algorithms</li> <li>DS Evaluation - Model Evaluation Techniques</li> <li>DS Deployment - Model Deployment Strategies</li> <li>Business DS Needs - Business Needs for Data Science Skills</li> <li>Business DS Impact - Impact on Decision Making</li> <li>Business DS Examples - Business Applications of Data Science</li> <li>Python DataTypes - Data Types in Python</li> <li>Python DataStructures - Data Structures (List, Dict, Set)</li> <li>Python Control - Control Structures (Loops, Conditionals)</li> <li>Python Functions - Functions and Modules</li> <li>Python OOP - Object-Oriented Programming</li> <li>Python FileHandling - File Handling</li> <li>Python Exceptions - Exception Handling</li> <li>Python Debugging - Debugging Techniques</li> <li>Python LibrariesIntro - Introduction to Python Libraries</li> <li>AI Intro - Introduction to Generative AI</li> <li>AI LearnPython - AI Tools for Learning Python</li> <li>AI CodeAssistants - Using AI Assistants for Coding</li> <li>AI LearningResources - AI-Generated Learning Resources</li> <li>AI Ethics - Ethical Considerations of AI</li> <li>NumPy Intro - Introduction to NumPy</li> <li>NumPy Arrays - NumPy Arrays and Operations</li> <li>NumPy Broadcasting - Broadcasting in NumPy</li> <li>NumPy AdvancedIndexing - Advanced Indexing</li> <li>NumPy MathFunctions - Mathematical Functions</li> <li>Pandas Intro - Introduction to Pandas</li> <li>Pandas DataFrames - DataFrames and Series</li> <li>Pandas IO - Reading and Writing Data</li> <li>Pandas Selection - Data Selection and Filtering</li> <li>Pandas Cleaning - Data Cleaning in Pandas</li> <li>Pandas MissingData - Handling Missing Data</li> <li>Pandas Merging - Merging and Joining DataFrames</li> <li>Pandas Grouping - Data Aggregation and Grouping</li> <li>Pandas Pivot - Pivot Tables</li> <li>Pandas TimeSeries - Time Series Data</li> <li>Stats Intro - Introduction to Statistics</li> <li>Stats Descriptive - Descriptive Statistics</li> <li>Stats Inferential - Inferential Statistics</li> <li>Stats Distributions - Probability Distributions</li> <li>SciPy Intro - SciPy for Statistical Analysis</li> <li>Statsmodels Intro - Statsmodels Library</li> <li>Stats Hypothesis - Hypothesis Testing</li> <li>Stats Regression - Regression Analysis</li> <li>ML Intro - Introduction to Machine Learning</li> <li>ML Supervised - Supervised Learning</li> <li>ML Unsupervised - Unsupervised Learning</li> <li>Sklearn Intro - scikit-learn Library</li> <li>ML Preprocessing - Data Preprocessing</li> <li>ML FeatureSelection - Feature Selection Techniques</li> <li>ML CrossValidation - Cross-Validation Methods</li> <li>ML Classification - Classification Algorithms</li> <li>ML Regression - Regression Algorithms</li> <li>ML Clustering - Clustering Algorithms</li> <li>ML Evaluation - Model Evaluation and Validation</li> <li>NetworkX Intro - NetworkX Library</li> <li>NetworkX Create - Creating Graphs</li> <li>NetworkX Algorithms - Graph Algorithms</li> <li>NetworkX Visualize - Graph Visualization</li> <li>Viz Importance - Importance of Data Visualization</li> <li>Matplotlib Intro - Introduction to Matplotlib</li> <li>Seaborn Intro - Introduction to Seaborn</li> <li>Plotly Intro - Introduction to Plotly</li> <li>Plotly Basic - Basic Plots with Plotly</li> <li>Plotly Interactive - Interactive Visualizations</li> <li>Plotly Dash - Plotly Dash for Web Apps</li> <li>NLP Intro - Introduction to NLP</li> <li>NLP TextPreprocessing - Text Preprocessing Techniques</li> <li>NLP Tokenization - Tokenization Methods</li> <li>NLP WordEmbeddings - Word Embeddings</li> <li>NLTK Intro - NLTK Library</li> <li>Spacy Intro - spaCy Library</li> <li>NLP Sentiment - Sentiment Analysis</li> <li>NLP TextClassify - Text Classification</li> <li>VectorStores Intro - Introduction to Vector Stores</li> <li>Faiss Intro - FAISS Library</li> <li>Annoy Intro - Annoy Library</li> <li>VectorStores Apps - Vector Store Applications</li> <li>GenAI Intro - Introduction to Generative AI</li> <li>LangChain Intro - LangChain Library</li> <li>LangChain Pipelines - Creating Pipelines</li> <li>LangChain COT - Chain-of-thought Prompting</li> <li>LlamaIndex Intro - LlamaIndex Library</li> <li>LlamaIndex Indexing - Indexing Data</li> <li>LlamaIndex Querying - Querying Data</li> <li>Project Ideas - Potential Final Projects Overview</li> <li>Project DataAnalysis - Data Analysis Project</li> <li>Project MLModel - Machine Learning Model Project</li> <li>Project NLP - NLP Application Project</li> <li>Project Visualization - Data Visualization Dashboard</li> <li>Project GraphAnalysis - Graph Analysis Project</li> <li>Project AIChatbot - AI-Powered Chatbot Project</li> <li>Project Planning - Planning a Data Science Project</li> <li>Project Dataset - Choosing Datasets</li> <li>Project Teams - Team Collaboration</li> <li>Project Presentation - Presenting Findings</li> <li>Project Documentation - Project Documentation</li> <li>Project Deployment - Deploying Projects</li> <li>ML DeepLearning - Introduction to Deep Learning</li> <li>TensorFlow Intro - TensorFlow Library</li> <li>PyTorch Intro - PyTorch Library</li> <li>DL NeuralNetworks - Neural Network Fundamentals</li> <li>DL CNNs - Convolutional Neural Networks</li> <li>DL RNNs - Recurrent Neural Networks</li> <li>DL TransferLearning - Transfer Learning</li> <li>DL NLP Transformers - Transformers Architecture</li> <li>DL NLP BERT - BERT Model</li> <li>TimeSeries Intro - Time Series Analysis</li> <li>TimeSeries Decomposition - Time Series Decomposition</li> <li>TimeSeries ARIMA - ARIMA Models</li> <li>TimeSeries Forecasting - Forecasting Techniques</li> <li>Recommender Intro - Recommender Systems</li> <li>Recommender CollabFilter - Collaborative Filtering</li> <li>Recommender ContentBased - Content-Based Filtering</li> <li>Recommender Hybrid - Hybrid Recommenders</li> <li>DataEng Intro - Introduction to Data Engineering</li> <li>DataEng ETL - ETL Processes</li> <li>DataEng DataWarehouses - Data Warehouses</li> <li>DataEng DataLakes - Data Lakes</li> <li>ML Reinforcement - Reinforcement Learning Basics</li> <li>ML GANs - Generative Adversarial Networks</li> <li>ML AutoML - Automated Machine Learning</li> <li>ML Explainability - Model Explainability</li> <li>BigData Intro - Introduction to Big Data</li> <li>PySpark Intro - Introduction to PySpark</li> <li>Cloud Intro - Cloud Computing Basics</li> <li>AWS Intro - AWS Overview</li> <li>Docker Intro - Introduction to Docker</li> <li>Ethics AI - Ethical Considerations in AI</li> <li>Privacy Data - Data Privacy and Security</li> <li>Bias Fairness - Bias and Fairness in ML</li> <li>Git Intro - Introduction to Git</li> <li>GitHub Intro - Using GitHub</li> <li>Viz BestPractices - Visualization Best Practices</li> <li>Dask Intro - Dask for Parallel Computing</li> <li>CaseStudies Intro - Case Studies Overview</li> <li>Communication Skills - Communication Skills</li> <li>CriticalThinking Skills - Critical Thinking</li> <li>Leadership Skills - Leadership in Data Science</li> <li>Final Review - Course Summary and Review</li> <li>Next Steps - Next Steps in Learning</li> <li>Course Evaluation - Course Feedback and Evaluation</li> </ol>"},{"location":"prompts/concept-taxonomy/","title":"Concept Taxonomy","text":"<p>Certainly! Based on the course content you've provided, here is a 10-category taxonomy of the types of concepts in this course:</p> <ol> <li>Foundation Concepts (Prerequisites)</li> <li>Key Terms</li> <li>Python Programming Concepts</li> <li>Python Libraries</li> <li>Data Manipulation and Analysis</li> <li>Statistical Analysis</li> <li>Machine Learning Concepts</li> <li>Data Visualization</li> <li>Natural Language Processing (NLP)</li> <li>Generative AI and Advanced Topics</li> </ol>"},{"location":"prompts/concept-taxonomy/#detailed-taxonomy","title":"Detailed Taxonomy:","text":"<ol> <li> <p>Foundation Concepts (Prerequisites)     Fundamental skills and knowledge required before diving into data science topics, including basic programming concepts and understanding of data types.</p> </li> <li> <p>Key Terms     Essential terminology and definitions used in data science, machine learning, AI, and related fields to build a strong conceptual foundation.</p> </li> <li> <p>Python Programming Concepts     Core Python programming skills necessary for data science, such as control structures, functions, object-oriented programming, file handling, and debugging.</p> </li> <li> <p>Python Libraries     Introduction to important Python libraries used in data science, including NumPy, Pandas, SciPy, Statsmodels, scikit-learn, NetworkX, and more.</p> </li> <li> <p>Data Manipulation and Analysis     Techniques for collecting, cleaning, exploring, and transforming data to prepare it for analysis, including data handling with Pandas and NumPy.</p> </li> <li> <p>Statistical Analysis     Concepts and methods in statistics necessary for analyzing data and making inferences, including descriptive and inferential statistics, probability distributions, and hypothesis testing.</p> </li> <li> <p>Machine Learning Concepts     Understanding of machine learning algorithms, model building, evaluation techniques, and deployment strategies using libraries like scikit-learn.</p> </li> <li> <p>Data Visualization     Tools and techniques for visualizing data to effectively communicate insights, focusing on libraries like Matplotlib, Seaborn, and Plotly.</p> </li> <li> <p>Natural Language Processing (NLP)     Concepts and tools for processing and analyzing textual data, including text preprocessing, tokenization, sentiment analysis, and using libraries like NLTK and spaCy.</p> </li> <li> <p>Generative AI and Advanced Topics     Advanced topics including generative AI, vector stores, deep learning frameworks, and the use of libraries like LangChain and LlamaIndex for building AI applications.</p> </li> </ol> <p>This taxonomy covers the breadth of topics in your course, organizing them into coherent categories that reflect their roles in the learning pathway. Each category groups related concepts together, making it easier to structure the course content and understand the dependencies between topics.</p> <p>o1</p>"},{"location":"prompts/course-description/","title":"Course Description for Introduction to Data Science with Python","text":"<p>Prompt</p> <p>Please generate a detailed course description for a 10-week class on the subject of introduction to data science with Python. The course description should be written in Markdown.  Follow Bloom's 2001 taxonomy.</p> <p>The course description follows an  online textbook about data science using the Python programming language.  The audience is advanced high-school students or freshmen in college.  The focus of the textbook is a series of interactive simulations (MicroSims) that allow the students to interact with data.  We start with simple linear regression and then build increasingly complicated predictive models with Python libraries like NumPy and PyTorch.  The focus is to find the simplest model that combines expandability with prediction fidelity.</p>"},{"location":"prompts/course-description/#response-from-claude-sonnet-4","title":"Response from Claude Sonnet-4","text":"<p>Course Duration: 10 weeks Target Audience: Advanced high school students and college freshmen Prerequisites: Basic algebra and introductory programming experience recommended</p>"},{"location":"prompts/course-description/#course-overview","title":"Course Overview","text":"<p>This introductory course provides students with foundational knowledge and practical skills in data science using Python. Through hands-on experience with interactive simulations (MicroSims) and real-world datasets, students will develop competency in data analysis, visualization, and predictive modeling. The course emphasizes the critical balance between model explainability and predictive accuracy, guiding students to identify the simplest effective solutions to data-driven problems.</p>"},{"location":"prompts/course-description/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this course, students will be able to:</p> <p>Remember (Knowledge) - Recall fundamental data science terminology and concepts - Identify key Python libraries for data science (NumPy, pandas, matplotlib, PyTorch) - Recognize different types of data and measurement scales - List the steps in the data science workflow</p> <p>Understand (Comprehension) - Explain the relationship between independent and dependent variables - Describe how linear regression models make predictions - Interpret basic statistical measures and visualizations - Summarize the trade-offs between model complexity and interpretability</p> <p>Apply (Application) - Implement basic data cleaning and preprocessing techniques - Create visualizations using Python libraries - Build simple linear regression models - Execute standard data science workflows on new datasets</p> <p>Analyze (Analysis) - Examine datasets to identify patterns and relationships - Compare different modeling approaches for the same problem - Distinguish between correlation and causation in data relationships - Evaluate model performance using appropriate metrics</p> <p>Evaluate (Evaluation) - Assess the quality and reliability of data sources - Critique model assumptions and limitations - Judge the appropriateness of different models for specific problems - Validate model performance and identify potential overfitting</p> <p>Create (Synthesis) - Design experiments to test hypotheses using data - Construct predictive models for real-world scenarios - Develop data-driven solutions to complex problems - Generate original insights from exploratory data analysis</p>"},{"location":"prompts/course-description/#weekly-schedule","title":"Weekly Schedule","text":""},{"location":"prompts/course-description/#week-1-foundations-of-data-science","title":"Week 1: Foundations of Data Science","text":"<ul> <li>Introduction to data science and its applications</li> <li>Setting up Python environment and Jupyter notebooks</li> <li>First MicroSim: Exploring sample datasets</li> <li>Basic data types and structures in Python</li> </ul>"},{"location":"prompts/course-description/#week-2-data-exploration-and-visualization","title":"Week 2: Data Exploration and Visualization","text":"<ul> <li>Loading and examining datasets with pandas</li> <li>Creating basic plots with matplotlib</li> <li>MicroSim: Interactive data visualization</li> <li>Identifying patterns in data through visual exploration</li> </ul>"},{"location":"prompts/course-description/#week-3-statistical-foundations","title":"Week 3: Statistical Foundations","text":"<ul> <li>Descriptive statistics and summary measures</li> <li>Understanding distributions and variability</li> <li>MicroSim: Statistical parameter exploration</li> <li>Introduction to probability concepts</li> </ul>"},{"location":"prompts/course-description/#week-4-simple-linear-regression","title":"Week 4: Simple Linear Regression","text":"<ul> <li>Mathematical foundations of linear regression</li> <li>Implementing regression from scratch</li> <li>MicroSim: Interactive regression line fitting</li> <li>Interpreting coefficients and model output</li> </ul>"},{"location":"prompts/course-description/#week-5-model-evaluation-and-validation","title":"Week 5: Model Evaluation and Validation","text":"<ul> <li>Measuring model performance (R\u00b2, MSE, MAE)</li> <li>Training and testing data splits</li> <li>MicroSim: Cross-validation simulation</li> <li>Understanding overfitting and underfitting</li> </ul>"},{"location":"prompts/course-description/#week-6-multiple-linear-regression","title":"Week 6: Multiple Linear Regression","text":"<ul> <li>Extending to multiple predictor variables</li> <li>Feature selection and engineering</li> <li>MicroSim: Multi-dimensional regression explorer</li> <li>Handling categorical variables</li> </ul>"},{"location":"prompts/course-description/#week-7-introduction-to-numpy-and-advanced-computation","title":"Week 7: Introduction to NumPy and Advanced Computation","text":"<ul> <li>NumPy arrays and vectorized operations</li> <li>Matrix operations for regression</li> <li>MicroSim: Linear algebra visualization</li> <li>Computational efficiency in data science</li> </ul>"},{"location":"prompts/course-description/#week-8-non-linear-models-and-regularization","title":"Week 8: Non-linear Models and Regularization","text":"<ul> <li>Polynomial regression and feature transformation</li> <li>Ridge and Lasso regularization</li> <li>MicroSim: Bias-variance trade-off explorer</li> <li>Model selection strategies</li> </ul>"},{"location":"prompts/course-description/#week-9-introduction-to-machine-learning-with-pytorch","title":"Week 9: Introduction to Machine Learning with PyTorch","text":"<ul> <li>Neural networks and deep learning concepts</li> <li>Building simple networks with PyTorch</li> <li>MicroSim: Neural network playground</li> <li>Comparing traditional and deep learning approaches</li> </ul>"},{"location":"prompts/course-description/#week-10-capstone-project-and-model-deployment","title":"Week 10: Capstone Project and Model Deployment","text":"<ul> <li>End-to-end data science project</li> <li>Model interpretation and communication</li> <li>MicroSim: Model comparison dashboard</li> <li>Best practices and ethical considerations</li> </ul>"},{"location":"prompts/course-description/#assessment-methods","title":"Assessment Methods","text":"<p>Formative Assessment (60%) - Weekly MicroSim exercises and reflections (30%) - Homework assignments applying concepts to new datasets (20%) - Peer review activities and collaborative problem-solving (10%)</p> <p>Summative Assessment (40%) - Midterm project: Complete data analysis report (15%) - Final capstone project: Original predictive modeling solution (20%) - Final examination covering theoretical concepts (5%)</p>"},{"location":"prompts/course-description/#required-materials","title":"Required Materials","text":"<ul> <li>Computer with Python 3.8+ installed</li> <li>Access to interactive online textbook with MicroSims</li> <li>Jupyter Notebook environment</li> <li>Required Python packages: pandas, NumPy, matplotlib, scikit-learn, PyTorch</li> </ul>"},{"location":"prompts/course-description/#key-learning-principles","title":"Key Learning Principles","text":"<p>Interactive Learning: Each week features hands-on MicroSims that allow students to manipulate parameters and observe results in real-time, reinforcing theoretical concepts through experiential learning.</p> <p>Scaffolded Complexity: The course progresses systematically from simple linear relationships to complex neural networks, ensuring students build confidence before tackling advanced topics.</p> <p>Explainable AI Focus: Throughout the course, emphasis is placed on understanding and interpreting models rather than simply achieving high accuracy, preparing students for ethical and transparent data science practice.</p> <p>Real-world Applications: All examples and projects use authentic datasets and scenarios, helping students connect academic learning to practical problem-solving.</p>"},{"location":"prompts/course-description/#course-philosophy","title":"Course Philosophy","text":"<p>This course is built on the principle that effective data science requires both technical competence and critical thinking. Students will learn not just how to build predictive models, but when to use them, how to interpret their results, and how to communicate findings to diverse audiences. The integration of interactive simulations ensures that abstract mathematical concepts become concrete and intuitive, while the progression from simple to complex models helps students appreciate the value of parsimony in modeling.</p> <p>By the end of this course, students will have developed both the technical skills and analytical mindset necessary for success in advanced data science coursework or entry-level positions in data-driven fields.</p>"},{"location":"prompts/data-science-language-popularity/","title":"Data Science Popularity","text":"<p>Prompt</p> <p>Please generate a line plot that shows the popularity of different programming languages for use in data science over the last 15 years.  Make sure to include both Python and R.  Document the source of the dataset.  Make time be the horizontal axis and start at 2010.</p>"},{"location":"prompts/data-science-workflow/","title":"Data Science Workflow","text":"<p>Prompt</p> <p>Please generate a new p5.js program for showing a simple linear step-by-step workflow with no feedback.  Use the first horiziontal row in book-gen-workflow.js as your template.</p> <p>Change the steps in the workflow to be the following</p> <ol> <li>Identify Problem</li> <li>Source Data</li> <li>Prepare Data</li> <li>Analyze Data</li> <li>Visualize Data</li> <li>Present Findings</li> </ol> <p>For each of these steps, generate a detailed description of the processes within this step to display in the infobox below the workflow drawing.</p>"},{"location":"prompts/faqs/","title":"FAQs","text":""},{"location":"prompts/faqs/#prompt","title":"Prompt","text":"<pre><code>I am preparing to teach a new college-level course called \"Introduction to Data Science with Python\".  The prerequisites to this course are Beginning Python,  Algebra and simple statistics.  What are the 100 most common questions that will come up in this course?\n\nPlease return the questions and their answer as a in Markdown format. \nPlace the question text in a level-4 header (####) and the response in the body text.\n</code></pre>"},{"location":"prompts/faqs/#chatgpt-o1-preview-response","title":"ChatGPT o1-preview Response","text":""},{"location":"prompts/faqs/#what-is-data-science-and-why-is-it-important","title":"What is data science, and why is it important?","text":"<p>Data science is an interdisciplinary field that combines domain expertise, programming skills, and knowledge of mathematics and statistics to extract meaningful insights from data. It is important because it enables organizations to make informed decisions, predict trends, and solve complex problems by analyzing large datasets.</p>"},{"location":"prompts/faqs/#how-is-python-used-in-data-science","title":"How is Python used in data science?","text":"<p>Python is widely used in data science due to its simplicity and versatility. It offers a vast ecosystem of libraries and frameworks like NumPy, Pandas, Matplotlib, and scikit-learn, which facilitate data manipulation, analysis, visualization, and machine learning tasks.</p>"},{"location":"prompts/faqs/#what-are-the-key-python-libraries-for-data-analysis","title":"What are the key Python libraries for data analysis?","text":"<p>The key Python libraries for data analysis include:</p> <ul> <li>NumPy: For numerical computing and array operations.</li> <li>Pandas: For data manipulation and analysis using data structures like DataFrames.</li> <li>Matplotlib: For creating static, animated, and interactive visualizations.</li> <li>Seaborn: For statistical data visualization built on top of Matplotlib.</li> <li>scikit-learn: For machine learning algorithms and predictive data analysis.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-import-a-csv-file-into-a-pandas-dataframe","title":"How do you import a CSV file into a Pandas DataFrame?","text":"<p>You can import a CSV file using the <code>read_csv()</code> function from Pandas:</p> <pre><code>Copy code\n\n`import pandas as pd\n\ndf = pd.read_csv('file_name.csv')\n`\n</code></pre> <p>Replace <code>'file_name.csv'</code> with the path to your CSV file.</p>"},{"location":"prompts/faqs/#what-is-a-dataframe-in-pandas","title":"What is a DataFrame in Pandas?","text":"<p>A DataFrame is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled axes (rows and columns). It is similar to a spreadsheet or SQL table and is the primary data structure used in Pandas for data manipulation.</p>"},{"location":"prompts/faqs/#how-do-you-handle-missing-data-in-a-dataset","title":"How do you handle missing data in a dataset?","text":"<p>Missing data can be handled by:</p> <ul> <li>Removing missing values: Using <code>dropna()</code> to remove rows or columns with missing values.</li> <li>Imputing missing values: Using <code>fillna()</code> to replace missing values with a specific value, mean, median, or mode.</li> <li>Interpolate missing values: Using <code>interpolate()</code> to estimate missing values based on other data points.</li> </ul>"},{"location":"prompts/faqs/#what-is-the-difference-between-numpy-arrays-and-python-lists","title":"What is the difference between NumPy arrays and Python lists?","text":"<p>NumPy arrays are fixed-size, homogeneous collections of elements (all of the same data type) optimized for numerical computations. Python lists are dynamic, heterogeneous collections that can contain elements of different data types. NumPy arrays offer better performance for mathematical operations.</p>"},{"location":"prompts/faqs/#how-do-you-select-a-subset-of-data-from-a-dataframe","title":"How do you select a subset of data from a DataFrame?","text":"<p>You can select subsets using:</p> <ul> <li> <p>Label-based indexing with <code>.loc</code>:</p> <pre><code>python\nCopy code\n\n`df_subset = df.loc[row_labels, column_labels]\n`\n</code></pre> </li> <li> <p>Integer-based indexing with <code>.iloc</code>:</p> <pre><code>python\nCopy code\n\n`df_subset = df.iloc[row_indices, column_indices]\n`\n</code></pre> </li> </ul>"},{"location":"prompts/faqs/#what-is-data-visualization-and-why-is-it-important","title":"What is data visualization, and why is it important?","text":"<p>Data visualization is the graphical representation of data to communicate information clearly and efficiently. It is important because it helps identify patterns, trends, and outliers in data, making complex data more accessible and understandable.</p>"},{"location":"prompts/faqs/#how-do-you-create-a-simple-line-plot-using-matplotlib","title":"How do you create a simple line plot using Matplotlib?","text":"<pre><code>python\nCopy code\n\n`import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4]\ny = [10, 20, 25, 30]\n\nplt.plot(x, y)\nplt.xlabel('X-axis Label')\nplt.ylabel('Y-axis Label')\nplt.title('Simple Line Plot')\nplt.show()\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-groupby-function-in-pandas","title":"What is the purpose of the <code>groupby()</code> function in Pandas?","text":"<p>The <code>groupby()</code> function is used to split data into groups based on some criteria, perform operations on each group independently, and then combine the results. It is useful for aggregation, transformation, and filtration of data.</p>"},{"location":"prompts/faqs/#how-do-you-merge-two-dataframes-in-pandas","title":"How do you merge two DataFrames in Pandas?","text":"<p>You can merge two DataFrames using the <code>merge()</code> function:</p> <pre><code>python\nCopy code\n\n`merged_df = pd.merge(df1, df2, on='common_column')\n`\n</code></pre> <p>Replace <code>'common_column'</code> with the column name that is common to both DataFrames.</p>"},{"location":"prompts/faqs/#what-is-the-difference-between-merge-and-concat-in-pandas","title":"What is the difference between <code>merge()</code> and <code>concat()</code> in Pandas?","text":"<ul> <li><code>merge()</code>: Combines two DataFrames based on the values of common columns (similar to SQL joins).</li> <li><code>concat()</code>: Concatenates DataFrames either vertically or horizontally, stacking them along an axis.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-calculate-basic-statistical-measures-like-mean-and-median-in-pandas","title":"How do you calculate basic statistical measures like mean and median in Pandas?","text":"<p>You can use built-in functions:</p> <ul> <li> <p>Mean:</p> <pre><code>python\nCopy code\n\n`mean_value = df['column_name'].mean()\n`\n</code></pre> </li> <li> <p>Median:</p> <pre><code>python\nCopy code\n\n`median_value = df['column_name'].median()\n`\n</code></pre> </li> </ul>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-apply-function-in-pandas","title":"What is the purpose of the <code>apply()</code> function in Pandas?","text":"<p>The <code>apply()</code> function allows you to apply a function along an axis of the DataFrame (either rows or columns). It is useful for performing complex operations on DataFrame elements.</p>"},{"location":"prompts/faqs/#how-do-you-create-a-pivot-table-in-pandas","title":"How do you create a pivot table in Pandas?","text":"<p>You can create a pivot table using the <code>pivot_table()</code> function:</p> <pre><code>python\nCopy code\n\n`pivot = pd.pivot_table(df, values='value_column', index='index_column', columns='columns_column', aggfunc='mean')\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-difference-between-supervised-and-unsupervised-learning","title":"What is the difference between supervised and unsupervised learning?","text":"<ul> <li>Supervised Learning: Involves training a model on labeled data, where the target outcome is known. Examples include regression and classification.</li> <li>Unsupervised Learning: Involves finding patterns in unlabeled data without predefined outcomes. Examples include clustering and dimensionality reduction.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-perform-linear-regression-using-scikit-learn","title":"How do you perform linear regression using scikit-learn?","text":"<pre><code>python\nCopy code\n\n`from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-overfitting-in-machine-learning","title":"What is overfitting in machine learning?","text":"<p>Overfitting occurs when a model learns the training data too well, including its noise and outliers, resulting in poor generalization to new, unseen data. It performs well on training data but poorly on test data.</p>"},{"location":"prompts/faqs/#how-can-you-prevent-overfitting","title":"How can you prevent overfitting?","text":"<p>Overfitting can be prevented by:</p> <ul> <li>Cross-validation: Splitting data into training and validation sets.</li> <li>Regularization: Adding penalties for complex models (e.g., Lasso, Ridge).</li> <li>Simplifying the model: Reducing the number of features.</li> <li>Early stopping: Halting training when performance on a validation set starts to degrade.</li> </ul>"},{"location":"prompts/faqs/#what-is-cross-validation","title":"What is cross-validation?","text":"<p>Cross-validation is a technique for assessing how a model will generalize to an independent dataset. It involves partitioning the data into subsets, training the model on some subsets, and validating it on the remaining ones.</p>"},{"location":"prompts/faqs/#how-do-you-evaluate-the-performance-of-a-regression-model","title":"How do you evaluate the performance of a regression model?","text":"<p>Common metrics include:</p> <ul> <li>Mean Absolute Error (MAE)</li> <li>Mean Squared Error (MSE)</li> <li>Root Mean Squared Error (RMSE)</li> <li>R-squared (Coefficient of Determination)</li> </ul>"},{"location":"prompts/faqs/#what-is-the-purpose-of-feature-scaling","title":"What is the purpose of feature scaling?","text":"<p>Feature scaling standardizes the range of independent variables, improving the performance and convergence speed of some machine learning algorithms that are sensitive to the scale of data, such as gradient descent optimization.</p>"},{"location":"prompts/faqs/#how-do-you-perform-feature-scaling-in-python","title":"How do you perform feature scaling in Python?","text":"<p>Using scikit-learn's <code>StandardScaler</code>:</p> <pre><code>python\nCopy code\n\n`from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-one-hot-encoding","title":"What is one-hot encoding?","text":"<p>One-hot encoding is a process of converting categorical variables into a binary (0 or 1) representation. Each category becomes a new column, and a value of 1 indicates the presence of that category.</p>"},{"location":"prompts/faqs/#how-do-you-perform-one-hot-encoding-in-pandas","title":"How do you perform one-hot encoding in Pandas?","text":"<p>Using the <code>get_dummies()</code> function:</p> <pre><code>python\nCopy code\n\n`encoded_df = pd.get_dummies(df, columns=['categorical_column'])\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-a-confusion-matrix","title":"What is a confusion matrix?","text":"<p>A confusion matrix is a table used to evaluate the performance of a classification model. It displays the true positives, true negatives, false positives, and false negatives, providing insight into the types of errors made by the model.</p>"},{"location":"prompts/faqs/#how-do-you-calculate-accuracy-precision-and-recall-from-a-confusion-matrix","title":"How do you calculate accuracy, precision, and recall from a confusion matrix?","text":"<ul> <li>Accuracy: (TP + TN) / (TP + TN + FP + FN)</li> <li>Precision: TP / (TP + FP)</li> <li>Recall: TP / (TP + FN)</li> </ul> <p>Where TP=True Positives, TN=True Negatives, FP=False Positives, FN=False Negatives.</p>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-train_test_split-function","title":"What is the purpose of the <code>train_test_split</code> function?","text":"<p>The <code>train_test_split</code> function splits a dataset into training and testing sets, allowing you to train the model on one subset and evaluate its performance on another to prevent overfitting.</p>"},{"location":"prompts/faqs/#how-do-you-split-data-into-training-and-testing-sets-in-scikit-learn","title":"How do you split data into training and testing sets in scikit-learn?","text":"<pre><code>python\nCopy code\n\n`from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-difference-between-classification-and-regression","title":"What is the difference between classification and regression?","text":"<ul> <li>Classification: Predicts categorical labels or classes.</li> <li>Regression: Predicts continuous numerical values.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-handle-categorical-variables-in-machine-learning-models","title":"How do you handle categorical variables in machine learning models?","text":"<p>Categorical variables can be handled by:</p> <ul> <li>Label Encoding: Assigning a unique integer to each category.</li> <li>One-Hot Encoding: Creating binary columns for each category.</li> </ul>"},{"location":"prompts/faqs/#what-is-k-means-clustering","title":"What is k-means clustering?","text":"<p>K-means clustering is an unsupervised learning algorithm that partitions data into k clusters, where each data point belongs to the cluster with the nearest mean. It aims to minimize the within-cluster sum of squares.</p>"},{"location":"prompts/faqs/#how-do-you-determine-the-optimal-number-of-clusters-in-k-means","title":"How do you determine the optimal number of clusters in k-means?","text":"<p>Common methods include:</p> <ul> <li>Elbow Method: Plotting the explained variance as a function of the number of clusters and looking for an \"elbow\" point.</li> <li>Silhouette Score: Measuring how similar a data point is to its own cluster compared to other clusters.</li> </ul>"},{"location":"prompts/faqs/#what-is-principal-component-analysis-pca","title":"What is principal component analysis (PCA)?","text":"<p>PCA is a dimensionality reduction technique that transforms a large set of variables into a smaller one that still contains most of the information by identifying the principal components (directions of maximum variance).</p>"},{"location":"prompts/faqs/#how-do-you-perform-pca-in-scikit-learn","title":"How do you perform PCA in scikit-learn?","text":"<pre><code>python\nCopy code\n\n`from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(data)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-bias-variance-tradeoff","title":"What is the bias-variance tradeoff?","text":"<p>The bias-variance tradeoff is the balance between a model's ability to generalize to new data (low variance) and its accuracy on training data (low bias). High bias can lead to underfitting, while high variance can lead to overfitting.</p>"},{"location":"prompts/faqs/#what-is-regularization-in-machine-learning","title":"What is regularization in machine learning?","text":"<p>Regularization involves adding a penalty term to the loss function to prevent overfitting by discouraging complex models. Common regularization techniques include Lasso (L1) and Ridge (L2) regression.</p>"},{"location":"prompts/faqs/#how-do-you-implement-ridge-regression-in-scikit-learn","title":"How do you implement Ridge regression in scikit-learn?","text":"<pre><code>python\nCopy code\n\n`from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=1.0)\nmodel.fit(X_train, y_train)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-logistic-regression","title":"What is logistic regression?","text":"<p>Logistic regression is a classification algorithm used to predict binary outcomes (0 or 1) by modeling the probability of a certain class using a logistic function.</p>"},{"location":"prompts/faqs/#how-do-you-evaluate-the-performance-of-a-classification-model","title":"How do you evaluate the performance of a classification model?","text":"<p>Common metrics include:</p> <ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1 Score</li> <li>ROC AUC Score</li> </ul>"},{"location":"prompts/faqs/#what-is-the-receiver-operating-characteristic-roc-curve","title":"What is the Receiver Operating Characteristic (ROC) curve?","text":"<p>The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1 - specificity) at various threshold settings. It illustrates the diagnostic ability of a binary classifier.</p>"},{"location":"prompts/faqs/#how-do-you-handle-imbalanced-datasets","title":"How do you handle imbalanced datasets?","text":"<p>Techniques include:</p> <ul> <li>Resampling Methods: Oversampling the minority class or undersampling the majority class.</li> <li>Synthetic Data Generation: Using methods like SMOTE to generate synthetic examples.</li> <li>Using Appropriate Evaluation Metrics: Focusing on precision, recall, or F1 score instead of accuracy.</li> </ul>"},{"location":"prompts/faqs/#what-is-time-series-analysis","title":"What is time series analysis?","text":"<p>Time series analysis involves analyzing data points collected or recorded at specific time intervals to identify trends, cycles, and seasonal variations for forecasting and other purposes.</p>"},{"location":"prompts/faqs/#how-do-you-deal-with-date-and-time-data-in-pandas","title":"How do you deal with date and time data in Pandas?","text":"<p>Pandas provides the <code>to_datetime()</code> function to convert strings to datetime objects, and you can use datetime properties and methods to manipulate date and time data.</p> <pre><code>python\nCopy code\n\n`df['date_column'] = pd.to_datetime(df['date_column'])\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-autocorrelation-in-time-series-data","title":"What is autocorrelation in time series data?","text":"<p>Autocorrelation is the correlation of a signal with a delayed copy of itself. In time series data, it measures the relationship between a variable's current value and its past values.</p>"},{"location":"prompts/faqs/#how-do-you-perform-forecasting-using-arima-models","title":"How do you perform forecasting using ARIMA models?","text":"<p>Using the <code>statsmodels</code> library:</p> <pre><code>python\nCopy code\n\n`from statsmodels.tsa.arima.model import ARIMA\n\nmodel = ARIMA(time_series_data, order=(p, d, q))\nmodel_fit = model.fit()\nforecast = model_fit.forecast(steps=10)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-natural-language-processing-nlp","title":"What is natural language processing (NLP)?","text":"<p>NLP is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language, enabling machines to understand, interpret, and generate human language.</p>"},{"location":"prompts/faqs/#how-do-you-perform-text-preprocessing-in-nlp","title":"How do you perform text preprocessing in NLP?","text":"<p>Common steps include:</p> <ul> <li>Tokenization: Splitting text into words or sentences.</li> <li>Stop Word Removal: Removing common words that add little meaning.</li> <li>Stemming/Lemmatization: Reducing words to their base or root form.</li> <li>Encoding: Converting text to numerical representation using methods like TF-IDF or word embeddings.</li> </ul>"},{"location":"prompts/faqs/#what-is-tf-idf","title":"What is TF-IDF?","text":"<p>Term Frequency-Inverse Document Frequency (TF-IDF) is a numerical statistic that reflects how important a word is to a document in a collection. It balances the frequency of a word in a document with how common the word is across all documents.</p>"},{"location":"prompts/faqs/#how-do-you-handle-large-datasets-that-dont-fit-into-memory","title":"How do you handle large datasets that don't fit into memory?","text":"<p>Techniques include:</p> <ul> <li>Data Sampling: Working with a subset of the data.</li> <li>Batch Processing: Processing data in chunks.</li> <li>Distributed Computing: Using tools like Apache Spark.</li> <li>Out-of-core Learning: Using algorithms that can learn from data incrementally.</li> </ul>"},{"location":"prompts/faqs/#what-is-a-pipeline-in-scikit-learn","title":"What is a pipeline in scikit-learn?","text":"<p>A pipeline is a sequence of data processing steps assembled into a single object. It ensures that all steps are applied consistently during training and testing, simplifying the workflow.</p> <pre><code>python\nCopy code\n\n`from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('model', LinearRegression())\n])\n`\n</code></pre>"},{"location":"prompts/faqs/#how-do-you-save-and-load-trained-models-in-scikit-learn","title":"How do you save and load trained models in scikit-learn?","text":"<p>Using the <code>joblib</code> library:</p> <pre><code>python\nCopy code\n\n`import joblib\n\n# Save model\njoblib.dump(model, 'model.pkl')\n\n# Load model\nmodel = joblib.load('model.pkl')\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-gradient-descent","title":"What is gradient descent?","text":"<p>Gradient descent is an optimization algorithm used to minimize the cost function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient.</p>"},{"location":"prompts/faqs/#what-is-the-difference-between-batch-stochastic-and-mini-batch-gradient-descent","title":"What is the difference between batch, stochastic, and mini-batch gradient descent?","text":"<ul> <li>Batch Gradient Descent: Uses the entire dataset to compute gradients.</li> <li>Stochastic Gradient Descent (SGD): Uses one sample at a time.</li> <li>Mini-Batch Gradient Descent: Uses a small subset (batch) of the data.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-handle-multicollinearity-in-regression-analysis","title":"How do you handle multicollinearity in regression analysis?","text":"<p>Techniques include:</p> <ul> <li>Removing correlated features.</li> <li>Principal Component Analysis (PCA) to reduce dimensionality.</li> <li>Regularization methods like Ridge regression.</li> </ul>"},{"location":"prompts/faqs/#what-is-the-central-limit-theorem","title":"What is the Central Limit Theorem?","text":"<p>The Central Limit Theorem states that the sampling distribution of the sample means approaches a normal distribution as the sample size becomes large, regardless of the population's distribution.</p>"},{"location":"prompts/faqs/#what-is-hypothesis-testing","title":"What is hypothesis testing?","text":"<p>Hypothesis testing is a statistical method used to decide whether there is enough evidence to reject a null hypothesis in favor of an alternative hypothesis based on sample data.</p>"},{"location":"prompts/faqs/#what-is-p-value","title":"What is p-value?","text":"<p>A p-value is the probability of observing results at least as extreme as those measured when the null hypothesis is true. A low p-value indicates that the observed data is unlikely under the null hypothesis.</p>"},{"location":"prompts/faqs/#how-do-you-perform-a-t-test-in-python","title":"How do you perform a t-test in Python?","text":"<p>Using <code>scipy.stats</code>:</p> <pre><code>python\nCopy code\n\n`from scipy import stats\n\nt_statistic, p_value = stats.ttest_ind(sample1, sample2)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-difference-between-type-i-and-type-ii-errors","title":"What is the difference between Type I and Type II errors?","text":"<ul> <li>Type I Error: Rejecting a true null hypothesis (false positive).</li> <li>Type II Error: Failing to reject a false null hypothesis (false negative).</li> </ul>"},{"location":"prompts/faqs/#what-is-an-anova-test","title":"What is an ANOVA test?","text":"<p>Analysis of Variance (ANOVA) is a statistical method used to compare means across three or more groups to see if at least one mean is different from the others.</p>"},{"location":"prompts/faqs/#how-do-you-perform-an-anova-test-in-python","title":"How do you perform an ANOVA test in Python?","text":"<p>Using <code>scipy.stats</code>:</p> <pre><code>python\nCopy code\n\n`from scipy import stats\n\nf_statistic, p_value = stats.f_oneway(group1, group2, group3)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-bootstrapping-in-statistics","title":"What is bootstrapping in statistics?","text":"<p>Bootstrapping is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It allows estimation of the sampling distribution of almost any statistic.</p>"},{"location":"prompts/faqs/#what-is-the-law-of-large-numbers","title":"What is the law of large numbers?","text":"<p>The law of large numbers states that as the number of trials increases, the sample mean will converge to the expected value (population mean).</p>"},{"location":"prompts/faqs/#what-is-a-probability-distribution","title":"What is a probability distribution?","text":"<p>A probability distribution describes how the values of a random variable are distributed. It defines the probabilities of different outcomes.</p>"},{"location":"prompts/faqs/#what-are-common-probability-distributions-used-in-data-science","title":"What are common probability distributions used in data science?","text":"<ul> <li>Normal Distribution</li> <li>Binomial Distribution</li> <li>Poisson Distribution</li> <li>Exponential Distribution</li> </ul>"},{"location":"prompts/faqs/#how-do-you-generate-random-numbers-following-a-normal-distribution-in-numpy","title":"How do you generate random numbers following a normal distribution in NumPy?","text":"<pre><code>python\nCopy code\n\n`import numpy as np\n\nrandom_numbers = np.random.normal(loc=mean, scale=std_dev, size=num_samples)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-curse-of-dimensionality","title":"What is the curse of dimensionality?","text":"<p>The curse of dimensionality refers to various phenomena that arise when analyzing data in high-dimensional spaces, often leading to challenges like overfitting and increased computational cost.</p>"},{"location":"prompts/faqs/#how-do-you-reduce-dimensionality","title":"How do you reduce dimensionality?","text":"<p>Techniques include:</p> <ul> <li>Feature Selection: Choosing a subset of relevant features.</li> <li>Feature Extraction: Transforming data into a lower-dimensional space (e.g., PCA).</li> </ul>"},{"location":"prompts/faqs/#what-is-the-difference-between-bagging-and-boosting","title":"What is the difference between bagging and boosting?","text":"<ul> <li>Bagging: Combines multiple models (usually of the same type) trained on different subsets of the data to reduce variance.</li> <li>Boosting: Sequentially trains models, where each new model focuses on correcting errors made by previous ones, reducing bias.</li> </ul>"},{"location":"prompts/faqs/#what-is-a-decision-tree","title":"What is a decision tree?","text":"<p>A decision tree is a flowchart-like structure used for classification and regression that splits data into branches based on feature values to make predictions.</p>"},{"location":"prompts/faqs/#how-do-you-prevent-a-decision-tree-from-overfitting","title":"How do you prevent a decision tree from overfitting?","text":"<p>By:</p> <ul> <li>Pruning: Removing branches that have little power in predicting target variables.</li> <li>Setting a maximum depth: Limiting the depth of the tree.</li> <li>Setting a minimum number of samples per leaf.</li> </ul>"},{"location":"prompts/faqs/#what-is-random-forest","title":"What is random forest?","text":"<p>Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees.</p>"},{"location":"prompts/faqs/#how-do-you-implement-a-random-forest-classifier-in-scikit-learn","title":"How do you implement a random forest classifier in scikit-learn?","text":"<pre><code>python\nCopy code\n\n`from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100)\nmodel.fit(X_train, y_train)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-ensemble-learning","title":"What is ensemble learning?","text":"<p>Ensemble learning combines predictions from multiple machine learning algorithms to produce a more accurate prediction than any individual model.</p>"},{"location":"prompts/faqs/#what-is-a-neural-network","title":"What is a neural network?","text":"<p>A neural network is a computational model inspired by the human brain, consisting of layers of interconnected nodes (neurons) that can learn complex patterns through training.</p>"},{"location":"prompts/faqs/#what-is-the-difference-between-deep-learning-and-machine-learning","title":"What is the difference between deep learning and machine learning?","text":"<ul> <li>Machine Learning: Involves algorithms that parse data, learn from it, and make decisions.</li> <li>Deep Learning: A subset of machine learning using neural networks with multiple layers to model complex patterns.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-handle-class-imbalance-in-classification-problems","title":"How do you handle class imbalance in classification problems?","text":"<p>By:</p> <ul> <li>Resampling the dataset: Oversampling the minority class or undersampling the majority class.</li> <li>Using appropriate evaluation metrics: Such as ROC AUC, precision-recall curve.</li> <li>Using algorithms that handle imbalance: Like XGBoost.</li> </ul>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-map-function-in-pandas","title":"What is the purpose of the <code>map()</code> function in Pandas?","text":"<p>The <code>map()</code> function is used to map values of a Series according to an input mapping or function, useful for substituting values or applying a function element-wise.</p>"},{"location":"prompts/faqs/#how-do-you-sort-a-dataframe-in-pandas","title":"How do you sort a DataFrame in Pandas?","text":"<p>Using the <code>sort_values()</code> function:</p> <pre><code>python\nCopy code\n\n`sorted_df = df.sort_values(by='column_name', ascending=True)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-difference-between-apply-and-applymap-in-pandas","title":"What is the difference between <code>apply()</code> and <code>applymap()</code> in Pandas?","text":"<ul> <li><code>apply()</code>: Applies a function along an axis of the DataFrame (rows or columns).</li> <li><code>applymap()</code>: Applies a function element-wise to the entire DataFrame.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-remove-duplicates-from-a-dataframe","title":"How do you remove duplicates from a DataFrame?","text":"<p>Using the <code>drop_duplicates()</code> function:</p> <pre><code>python\nCopy code\n\n`df_unique = df.drop_duplicates()\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-an-outlier-and-how-do-you-detect-them","title":"What is an outlier, and how do you detect them?","text":"<p>An outlier is a data point significantly different from others. Detection methods include:</p> <ul> <li>Statistical methods: Using Z-scores or IQR.</li> <li>Visualization: Box plots or scatter plots.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-handle-outliers-in-data","title":"How do you handle outliers in data?","text":"<p>By:</p> <ul> <li>Removing them: If they are errors.</li> <li>Transforming data: Using log or square root transformations.</li> <li>Using robust algorithms: That are less sensitive to outliers.</li> </ul>"},{"location":"prompts/faqs/#what-is-data-normalization","title":"What is data normalization?","text":"<p>Data normalization scales numerical data into a specific range, typically [0,1], ensuring that each feature contributes equally to the analysis.</p>"},{"location":"prompts/faqs/#how-do-you-perform-data-normalization-in-scikit-learn","title":"How do you perform data normalization in scikit-learn?","text":"<p>Using <code>MinMaxScaler</code>:</p> <pre><code>python\nCopy code\n\n`from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_data = scaler.fit_transform(data)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-a-heatmap-and-when-do-you-use-it","title":"What is a heatmap, and when do you use it?","text":"<p>A heatmap is a graphical representation of data where individual values are represented as colors. It is used to visualize correlation matrices or to display patterns in data.</p>"},{"location":"prompts/faqs/#how-do-you-create-a-heatmap-in-seaborn","title":"How do you create a heatmap in Seaborn?","text":"<pre><code>python\nCopy code\n\n`import seaborn as sns\n\nsns.heatmap(data, annot=True)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-a-pairplot-in-seaborn","title":"What is a pairplot in Seaborn?","text":"<p>A pairplot creates a grid of Axes such that each variable in the data is shared across the y-axes across a single row and the x-axes across a single column, visualizing pairwise relationships.</p> <pre><code>python\nCopy code\n\n`sns.pairplot(df)\n`\n</code></pre>"},{"location":"prompts/faqs/#how-do-you-interpret-a-correlation-coefficient","title":"How do you interpret a correlation coefficient?","text":"<p>A correlation coefficient measures the strength and direction of a linear relationship between two variables. Values range from -1 to 1:</p> <ul> <li>-1: Perfect negative correlation.</li> <li>0: No correlation.</li> <li>1: Perfect positive correlation.</li> </ul>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-describe-function-in-pandas","title":"What is the purpose of the <code>describe()</code> function in Pandas?","text":"<p>The <code>describe()</code> function generates descriptive statistics, including count, mean, standard deviation, min, max, and quartile values for numerical columns.</p>"},{"location":"prompts/faqs/#how-do-you-handle-datetime-features-for-machine-learning-models","title":"How do you handle date/time features for machine learning models?","text":"<p>By extracting meaningful components:</p> <ul> <li>Year, Month, Day</li> <li>Weekday</li> <li>Hour, Minute, Second</li> <li>Time since a specific date</li> </ul>"},{"location":"prompts/faqs/#what-is-the-difference-between-loc-and-iloc-in-pandas","title":"What is the difference between <code>.loc</code> and <code>.iloc</code> in Pandas?","text":"<ul> <li><code>.loc</code>: Label-based indexing to select data by row and column labels.</li> <li><code>.iloc</code>: Integer-based indexing to select data by row and column positions.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-rename-columns-in-a-dataframe","title":"How do you rename columns in a DataFrame?","text":"<p>Using the <code>rename()</code> function:</p> <pre><code>python\nCopy code\n\n`df.rename(columns={'old_name': 'new_name'}, inplace=True)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-astype-function-in-pandas","title":"What is the purpose of the <code>astype()</code> function in Pandas?","text":"<p>The <code>astype()</code> function is used to change the data type of a Series or DataFrame columns.</p> <pre><code>python\nCopy code\n\n`df['column_name'] = df['column_name'].astype('float')\n`\n</code></pre>"},{"location":"prompts/faqs/#how-do-you-detect-missing-values-in-a-dataframe","title":"How do you detect missing values in a DataFrame?","text":"<p>Using <code>isnull()</code> or <code>isna()</code> functions:</p> <pre><code>python\nCopy code\n\n`missing_values = df.isnull().sum()\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-an-ensemble-method-in-machine-learning","title":"What is an ensemble method in machine learning?","text":"<p>An ensemble method combines predictions from multiple machine learning models to improve performance over a single model. Examples include Random Forest, Gradient Boosting.</p>"},{"location":"prompts/faqs/#how-do-you-implement-gradient-boosting-in-scikit-learn","title":"How do you implement Gradient Boosting in scikit-learn?","text":"<pre><code>python\nCopy code\n\n`from sklearn.ensemble import GradientBoostingClassifier\n\nmodel = GradientBoostingClassifier()\nmodel.fit(X_train, y_train)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-xgboost","title":"What is XGBoost?","text":"<p>XGBoost (Extreme Gradient Boosting) is an optimized gradient boosting library designed to be highly efficient, flexible, and portable, widely used for its performance and speed.</p>"},{"location":"prompts/faqs/#how-do-you-install-and-use-xgboost-in-python","title":"How do you install and use XGBoost in Python?","text":"<p>Install using pip:</p> <pre><code>bash\nCopy code\n\n`pip install xgboost\n`\n</code></pre> <p>Use in code:</p> <pre><code>python\nCopy code\n\n`import xgboost as xgb\n\nmodel = xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-cross-entropy-loss","title":"What is cross-entropy loss?","text":"<p>Cross-entropy loss measures the performance of a classification model whose output is a probability between 0 and 1. It increases as the predicted probability diverges from the actual label.</p>"},{"location":"prompts/faqs/#how-do-you-calculate-the-learning-rate-in-gradient-descent","title":"How do you calculate the learning rate in gradient descent?","text":"<p>The learning rate is a hyperparameter that you set manually. It determines the step size at each iteration while moving toward a minimum of a loss function.</p>"},{"location":"prompts/faqs/#what-is-the-difference-between-epochs-batches-and-iterations","title":"What is the difference between epochs, batches, and iterations?","text":"<ul> <li>Epoch: One complete pass through the entire training dataset.</li> <li>Batch: A subset of the training data used in one iteration.</li> <li>Iteration: One update of the model's parameters.</li> </ul>"},{"location":"prompts/faqs/#how-do-you-perform-hyperparameter-tuning","title":"How do you perform hyperparameter tuning?","text":"<p>By:</p> <ul> <li>Grid Search: Exhaustively searching through a specified subset of hyperparameters.</li> <li>Random Search: Randomly sampling hyperparameter combinations.</li> <li>Bayesian Optimization: Using probabilistic models to select hyperparameters.</li> </ul>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-pipeline-module-in-scikit-learn","title":"What is the purpose of the <code>pipeline</code> module in scikit-learn?","text":"<p>It allows you to chain preprocessing steps and estimators in a sequential manner, ensuring consistent application of transformations during training and testing.</p>"},{"location":"prompts/faqs/#how-do-you-evaluate-a-clustering-algorithm","title":"How do you evaluate a clustering algorithm?","text":"<p>Using metrics like:</p> <ul> <li>Silhouette Score</li> <li>Calinski-Harabasz Index</li> <li>Davies-Bouldin Index</li> </ul>"},{"location":"prompts/faqs/#what-is-a-dummy-variable-trap","title":"What is a dummy variable trap?","text":"<p>The dummy variable trap occurs when multicollinearity is introduced in a regression model due to the inclusion of dummy variables that are linearly dependent. It can be avoided by dropping one dummy variable.</p>"},{"location":"prompts/faqs/#how-do-you-create-a-correlation-matrix-in-pandas","title":"How do you create a correlation matrix in Pandas?","text":"<pre><code>python\nCopy code\n\n`corr_matrix = df.corr()\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-an-roc-curve-and-how-do-you-plot-it","title":"What is an ROC curve, and how do you plot it?","text":"<p>An ROC (Receiver Operating Characteristic) curve plots the true positive rate against the false positive rate at various threshold settings. You can plot it using scikit-learn:</p> <pre><code>python\nCopy code\n\n`from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_scores)\nplt.plot(fpr, tpr)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-a-type-i-error","title":"What is a type I error?","text":"<p>A type I error occurs when the null hypothesis is true, but we incorrectly reject it (false positive).</p>"},{"location":"prompts/faqs/#what-is-a-type-ii-error","title":"What is a type II error?","text":"<p>A type II error occurs when the null hypothesis is false, but we fail to reject it (false negative).</p>"},{"location":"prompts/faqs/#how-do-you-calculate-the-p-value-in-a-hypothesis-test","title":"How do you calculate the p-value in a hypothesis test?","text":"<p>Using statistical tests from libraries like <code>scipy.stats</code>, which return the p-value as part of the output.</p>"},{"location":"prompts/faqs/#what-is-the-difference-between-parametric-and-non-parametric-tests","title":"What is the difference between parametric and non-parametric tests?","text":"<ul> <li>Parametric Tests: Assume underlying statistical distributions (e.g., t-test).</li> <li>Non-Parametric Tests: Do not assume any specific distribution (e.g., Mann-Whitney U test).</li> </ul>"},{"location":"prompts/faqs/#how-do-you-perform-a-chi-squared-test-in-python","title":"How do you perform a chi-squared test in Python?","text":"<p>Using <code>scipy.stats</code>:</p> <pre><code>python\nCopy code\n\n`from scipy.stats import chi2_contingency\n\nchi2, p, dof, expected = chi2_contingency(observed_values)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-purpose-of-the-seaborn-library","title":"What is the purpose of the <code>seaborn</code> library?","text":"<p>Seaborn is a Python data visualization library based on Matplotlib that provides a high-level interface for drawing attractive statistical graphics.</p>"},{"location":"prompts/faqs/#how-do-you-create-a-box-plot-in-seaborn","title":"How do you create a box plot in Seaborn?","text":"<pre><code>python\nCopy code\n\n`import seaborn as sns\n\nsns.boxplot(x='categorical_column', y='numerical_column', data=df)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-a-violin-plot","title":"What is a violin plot?","text":"<p>A violin plot combines a box plot and a kernel density plot to provide a richer depiction of the data distribution.</p>"},{"location":"prompts/faqs/#how-do-you-handle-multivariate-time-series-data","title":"How do you handle multivariate time series data?","text":"<p>By:</p> <ul> <li>Using models designed for multivariate data: Like VAR (Vector Autoregression).</li> <li>Feature engineering: Creating lag features for each variable.</li> </ul>"},{"location":"prompts/faqs/#what-is-an-ab-test","title":"What is an A/B test?","text":"<p>An A/B test is an experiment comparing two variants (A and B) to determine which one performs better regarding a specific metric.</p>"},{"location":"prompts/faqs/#how-do-you-analyze-ab-test-results","title":"How do you analyze A/B test results?","text":"<p>By:</p> <ul> <li>Calculating the difference in metrics between groups.</li> <li>Performing statistical tests: Like t-tests or chi-squared tests.</li> <li>Checking for statistical significance: Using p-values and confidence intervals.</li> </ul>"},{"location":"prompts/faqs/#what-is-the-bonferroni-correction","title":"What is the Bonferroni correction?","text":"<p>A method to adjust p-values when multiple comparisons are made to reduce the chances of obtaining false-positive results (Type I errors).</p>"},{"location":"prompts/faqs/#what-is-survivorship-bias","title":"What is survivorship bias?","text":"<p>Survivorship bias occurs when analyses are conducted only on surviving subjects, leading to skewed results due to the overlooking of those that did not survive or were not included.</p>"},{"location":"prompts/faqs/#what-is-data-leakage","title":"What is data leakage?","text":"<p>Data leakage occurs when information from outside the training dataset is used to create the model, leading to overly optimistic performance estimates that won't generalize to new data.</p>"},{"location":"prompts/faqs/#how-do-you-prevent-data-leakage","title":"How do you prevent data leakage?","text":"<p>By:</p> <ul> <li>Separating training and testing data properly.</li> <li>Performing data preprocessing steps within cross-validation.</li> <li>Avoiding using future data in model training.</li> </ul>"},{"location":"prompts/faqs/#what-is-a-hash-table","title":"What is a hash table?","text":"<p>A hash table is a data structure that implements an associative array, mapping keys to values using a hash function to compute an index into an array of buckets.</p>"},{"location":"prompts/faqs/#what-is-memoization","title":"What is memoization?","text":"<p>Memoization is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again.</p>"},{"location":"prompts/faqs/#how-do-you-reverse-a-linked-list","title":"How do you reverse a linked list?","text":"<p>By iterating through the list and reversing the pointers of each node to point to the previous node.</p>"},{"location":"prompts/faqs/#what-is-the-time-complexity-of-quicksort","title":"What is the time complexity of quicksort?","text":"<p>The average time complexity is O(n log n), while the worst-case is O(n^2).</p>"},{"location":"prompts/faqs/#what-is-a-generator-in-python","title":"What is a generator in Python?","text":"<p>A generator is a special type of function that returns an iterator object which can iterate over a sequence of values. It uses the <code>yield</code> keyword.</p> <pre><code>python\nCopy code\n\n`def my_generator():\n    yield value\n`\n</code></pre>"},{"location":"prompts/faqs/#how-do-you-handle-exceptions-in-python","title":"How do you handle exceptions in Python?","text":"<p>Using try-except blocks:</p> <pre><code>python\nCopy code\n\n`try:\n    # Code that may raise an exception\nexcept ExceptionType as e:\n    # Code to handle the exception\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-a-decorator-in-python","title":"What is a decorator in Python?","text":"<p>A decorator is a function that modifies the behavior of another function or method. It allows for the addition of functionality to existing code in a modular way.</p> <pre><code>python\nCopy code\n\n`def decorator_function(func):\n    def wrapper():\n        # Code before function call\n        func()\n        # Code after function call\n    return wrapper\n`\n</code></pre>"},{"location":"prompts/faqs/#how-do-you-read-and-write-json-files-in-python","title":"How do you read and write JSON files in Python?","text":"<p>Using the <code>json</code> module:</p> <pre><code>python\nCopy code\n\n`import json\n\n# Read JSON\nwith open('file.json', 'r') as f:\n    data = json.load(f)\n\n# Write JSON\nwith open('file.json', 'w') as f:\n    json.dump(data, f)\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-multithreading-and-how-do-you-implement-it-in-python","title":"What is multithreading, and how do you implement it in Python?","text":"<p>Multithreading allows concurrent execution of threads (lightweight processes) to improve performance. In Python, you can use the <code>threading</code> module:</p> <pre><code>python\nCopy code\n\n`import threading\n\ndef function_to_run():\n    pass\n\nthread = threading.Thread(target=function_to_run)\nthread.start()\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-the-global-interpreter-lock-gil-in-python","title":"What is the Global Interpreter Lock (GIL) in Python?","text":"<p>The GIL is a mutex that protects access to Python objects, preventing multiple native threads from executing Python bytecodes at once. It simplifies memory management but can limit performance in CPU-bound multi-threaded programs.</p>"},{"location":"prompts/faqs/#how-do-you-handle-file-operations-in-python","title":"How do you handle file operations in Python?","text":"<p>Using <code>open()</code>:</p> <pre><code>python\nCopy code\n\n`with open('file.txt', 'r') as file:\n    content = file.read()\n`\n</code></pre>"},{"location":"prompts/faqs/#what-are-lambda-functions-in-python","title":"What are lambda functions in Python?","text":"<p>Lambda functions are anonymous functions defined using the <code>lambda</code> keyword, useful for short, simple functions.</p> <pre><code>python\nCopy code\n\n`add = lambda x, y: x + y\n`\n</code></pre>"},{"location":"prompts/faqs/#how-do-you-work-with-databases-in-python","title":"How do you work with databases in Python?","text":"<p>By using database connectors and ORMs like:</p> <ul> <li>SQLite: Using <code>sqlite3</code> module.</li> <li>MySQL: Using <code>mysql-connector-python</code>.</li> <li>ORMs: Using libraries like SQLAlchemy.</li> </ul>"},{"location":"prompts/faqs/#what-is-the-purpose-of-virtual-environments-in-python","title":"What is the purpose of virtual environments in Python?","text":"<p>Virtual environments allow you to create isolated Python environments with specific packages and dependencies, preventing conflicts between projects.</p> <pre><code>bash\nCopy code\n\n`python -m venv myenv\n`\n</code></pre>"},{"location":"prompts/faqs/#how-do-you-install-packages-in-python","title":"How do you install packages in Python?","text":"<p>Using <code>pip</code>:</p> <pre><code>bash\nCopy code\n\n`pip install package_name\n`\n</code></pre>"},{"location":"prompts/faqs/#what-are-the-common-data-types-in-python","title":"What are the common data types in Python?","text":"<ul> <li>Numeric Types: int, float, complex</li> <li>Sequence Types: list, tuple, range</li> <li>Text Type: str</li> <li>Mapping Type: dict</li> <li>Set Types: set, frozenset</li> <li>Boolean Type: bool</li> </ul>"},{"location":"prompts/faqs/#how-do-you-create-a-class-in-python","title":"How do you create a class in Python?","text":"<pre><code>python\nCopy code\n\n`class MyClass:\n    def __init__(self, attribute):\n        self.attribute = attribute\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-inheritance-in-python","title":"What is inheritance in Python?","text":"<p>Inheritance allows a class (child) to inherit attributes and methods from another class (parent), promoting code reusability.</p> <pre><code>python\nCopy code\n\n`class ChildClass(ParentClass):\n    pass\n`\n</code></pre>"},{"location":"prompts/faqs/#what-is-polymorphism-in-python","title":"What is polymorphism in Python?","text":"<p>Polymorphism allows methods to have the same name but behave differently in different classes. It enables methods to be used interchangeably.</p> <p>o1</p>"},{"location":"prompts/generate-microsims/","title":"Generate List of MicroSims for Data Science","text":"<p>Prompt</p> <p>You are in expert at creating great instructional designs using interactive simulations.</p> <p>Please create a list of the 100 most difficult concepts to learn a course called \"Introduction to Data Science with Python\" and suggest a detailed list of MicroSims that could be used to explain these concepts to students.</p> <p>MicroSims are interactive in-browser simulations and animations that allow students to click on the screen and learn data science concepts.  They are often written in JavaScript libraries like p5.js.  MicroSims have input controls like buttons and sliders that students can click.  We can add logging tools to these controls to see what events the student clicked on.</p> <p>An example of a data-science MicroSim is a \"least square\" MicroSim that allows the student to change the slop and intercept which will minimize the area of squares on a graph. https://dmccreary.github.io/microsims/sims/least-squares/main.html</p> <p>For each MicroSim generate:</p> <ol> <li>The Name of the MicroSim in Level 2 Markdown Header</li> <li>A short description of the MicroSim in level 3 markdown</li> <li>The learning goals of the MicroSim in level 3 markdown</li> <li>A list of the input controls that the student could change in a numbered list</li> </ol> <p>Focus on good instructional design and step-by-step learning from simple to complex.  Begin with simple MicroSims and move on to more complex MicroSims. </p>"},{"location":"prompts/generate-microsims/#results-in-chatgpt-using-gpt-5","title":"Results in ChatGPT using GPT-5","text":""},{"location":"prompts/glossary/","title":"Glossary Generation","text":""},{"location":"prompts/glossary/#prompt","title":"Prompt","text":"<p>Prompt</p> <p>Please generate an glossary of terms for the 250 most frequently used terms used in an introductory course  in introduction to data science with Python. Make sure to include the names of Python libraries used in data science. The target audience for this glossary is college freshmen. Each term should have a term name in a level-4 markdown (####) and the definition placed in the body text. Do not use the term in the definition of the term. The definition should be precise, concise and distinct.</p> <p>If appropriate, create an Example: of how that term is used in the Introduction to Data Science with Python course.  Do not place a newline after the Example: Return the glossary of terms in alphabetical order.</p> <p>A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"prompts/glossary/#accuracy","title":"Accuracy","text":"<p>A metric used to evaluate classification models, representing the proportion of correct predictions over the total number of predictions.</p> <p>Example: In a spam email classifier, if the model correctly identifies 90 out of 100 emails, the accuracy is 90%.</p>"},{"location":"prompts/glossary/#algorithm","title":"Algorithm","text":"<p>A step-by-step procedure or set of rules designed to perform a specific task or solve a problem.</p> <p>Example: Implementing the k-means clustering algorithm to group similar data points in an unsupervised learning task.</p>"},{"location":"prompts/glossary/#anaconda","title":"Anaconda","text":"<p>A free and open-source distribution of Python and R programming languages for scientific computing and data science.</p> <p>Example: Using Anaconda to manage Python packages and environments for data analysis projects in the course.</p>"},{"location":"prompts/glossary/#analytics","title":"Analytics","text":"<p>The examining data sets to draw conclusions about the information they contain, often using specialized software and statistical techniques.</p> <p>Example: Performing customer behavior analytics using Pandas and Matplotlib to improve marketing strategies.</p> <p>```</p>"},{"location":"prompts/glossary/#chatgpt-o1-preview-response","title":"ChatGPT o1-preview Response","text":""},{"location":"prompts/glossary/#accuracy_1","title":"Accuracy","text":"<p>A metric used to evaluate classification models, representing the proportion of correct predictions over the total number of predictions.</p> <p>Example: In a spam email classifier, if the model correctly identifies 90 out of 100 emails, the accuracy is 90%.</p>"},{"location":"prompts/glossary/#algorithm_1","title":"Algorithm","text":"<p>A step-by-step procedure or set of rules designed to perform a specific task or solve a problem.</p> <p>Example: Implementing the k-means clustering algorithm to group similar data points in an unsupervised learning task.</p>"},{"location":"prompts/glossary/#anaconda_1","title":"Anaconda","text":"<p>A free and open-source distribution of Python and R programming languages for scientific computing and data science.</p> <p>Example: Using Anaconda to manage Python packages and environments for data analysis projects in the course.</p>"},{"location":"prompts/glossary/#analytics_1","title":"Analytics","text":"<p>The examining data sets to draw conclusions about the information they contain, often using specialized software and statistical techniques.</p> <p>Example: Performing customer behavior analytics using Pandas and Matplotlib to improve marketing strategies.</p>"},{"location":"prompts/glossary/#api-application-programming-interface","title":"API (Application Programming Interface)","text":"<p>An API is a set of protocols and tools that allow different software applications to communicate with each other.</p> <p>Example: Utilizing the Twitter API to collect real-time tweets for sentiment analysis in Python.</p>"},{"location":"prompts/glossary/#array","title":"Array","text":"<p>An array is a data structure that stores a collection of items at contiguous memory locations, allowing for efficient indexing.</p> <p>Example: Using NumPy arrays to perform vectorized operations for faster numerical computations.</p>"},{"location":"prompts/glossary/#artificial-intelligence-ai","title":"Artificial Intelligence (AI)","text":"<p>AI is the simulation of human intelligence processes by machines, especially computer systems, enabling them to perform tasks that typically require human intelligence.</p> <p>Example: Exploring AI concepts by implementing machine learning models that can recognize images or understand natural language.</p>"},{"location":"prompts/glossary/#attribute","title":"Attribute","text":"<p>An attribute refers to a variable or feature in a dataset that represents a characteristic of the data points.</p> <p>Example: In a dataset of cars, attributes might include horsepower, weight, and fuel efficiency.</p>"},{"location":"prompts/glossary/#auc-area-under-the-curve","title":"AUC (Area Under the Curve)","text":"<p>AUC is a performance metric for classification models, representing the area under the Receiver Operating Characteristic (ROC) curve.</p> <p>Example: Comparing models by evaluating their AUC scores to determine which has better classification performance.</p>"},{"location":"prompts/glossary/#bagging","title":"Bagging","text":"<p>Bagging, short for Bootstrap Aggregating, is an ensemble learning technique that improves model stability and accuracy by combining predictions from multiple models trained on random subsets of the data.</p> <p>Example: Implementing bagging with decision trees to reduce variance and prevent overfitting in the course project.</p>"},{"location":"prompts/glossary/#bar-chart","title":"Bar Chart","text":"<p>A bar chart is a graphical representation of data using rectangular bars to show the frequency or value of different categories.</p> <p>Example: Creating a bar chart with Matplotlib to visualize the count of different species in an ecological dataset.</p>"},{"location":"prompts/glossary/#bias","title":"Bias","text":"<p>Bias refers to the error introduced by approximating a real-world problem, which may be complex, by a much simpler model.</p> <p>Example: Recognizing high bias in a linear model that underfits the data during regression analysis.</p>"},{"location":"prompts/glossary/#bias-variance-tradeoff","title":"Bias-Variance Tradeoff","text":"<p>The bias-variance tradeoff is the balance between a model's ability to generalize to new data (variance) and its accuracy on the training data (bias).</p> <p>Example: Adjusting the complexity of a model to find the optimal point where both bias and variance are minimized.</p>"},{"location":"prompts/glossary/#big-data","title":"Big Data","text":"<p>Big Data refers to datasets that are too large or complex for traditional data-processing software to handle efficiently.</p> <p>Example: Discussing how tools like Hadoop or Spark can process big data in the context of data science.</p>"},{"location":"prompts/glossary/#box-plot","title":"Box Plot","text":"<p>A box plot is a graphical representation of data that displays the distribution's quartiles and averages, highlighting the median and outliers.</p> <p>Example: Using Seaborn to create box plots for visualizing the distribution of test scores across different classrooms.</p>"},{"location":"prompts/glossary/#bootstrapping","title":"Bootstrapping","text":"<p>Bootstrapping is a statistical resampling technique that involves repeatedly drawing samples from a dataset with replacement to estimate a population parameter.</p> <p>Example: Applying bootstrapping methods to estimate confidence intervals for a sample mean in a data analysis assignment.</p>"},{"location":"prompts/glossary/#classification","title":"Classification","text":"<p>Classification is a supervised learning task where the goal is to predict discrete labels or categories for given input data.</p> <p>Example: Building a logistic regression model to classify emails as spam or not spam.</p>"},{"location":"prompts/glossary/#clustering","title":"Clustering","text":"<p>Clustering is an unsupervised learning technique that groups similar data points together based on their features.</p> <p>Example: Using k-means clustering to segment customers into different groups based on purchasing behavior.</p>"},{"location":"prompts/glossary/#confusion-matrix","title":"Confusion Matrix","text":"<p>A confusion matrix is a table used to evaluate the performance of a classification model by comparing predicted and actual labels.</p> <p>Example: Analyzing a confusion matrix to calculate precision and recall for a disease diagnosis model.</p>"},{"location":"prompts/glossary/#correlation","title":"Correlation","text":"<p>Correlation measures the statistical relationship between two variables, indicating how one may predict the other.</p> <p>Example: Calculating the correlation coefficient between hours studied and exam scores to determine their relationship.</p>"},{"location":"prompts/glossary/#cross-validation","title":"Cross-Validation","text":"<p>Cross-validation is a technique for assessing how a predictive model will perform on an independent dataset by partitioning the data into complementary subsets for training and validation.</p> <p>Example: Using k-fold cross-validation to evaluate the generalization performance of a machine learning model.</p>"},{"location":"prompts/glossary/#csv-comma-separated-values","title":"CSV (Comma-Separated Values)","text":"<p>CSV is a file format that uses commas to separate values, commonly used for storing tabular data.</p> <p>Example: Importing a CSV file into a Pandas DataFrame to begin data analysis.</p>"},{"location":"prompts/glossary/#dataframe","title":"DataFrame","text":"<p>A DataFrame is a two-dimensional labeled data structure in Pandas, similar to a spreadsheet or SQL table.</p> <p>Example: Manipulating data stored in a DataFrame to clean and prepare it for analysis.</p>"},{"location":"prompts/glossary/#data-mining","title":"Data Mining","text":"<p>Data mining is the process of discovering patterns and knowledge from large amounts of data.</p> <p>Example: Extracting useful information from a large customer database to identify purchasing trends.</p>"},{"location":"prompts/glossary/#data-science","title":"Data Science","text":"<p>Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract insights from structured and unstructured data.</p> <p>Example: Applying data science techniques to analyze social media data for sentiment analysis.</p>"},{"location":"prompts/glossary/#data-visualization","title":"Data Visualization","text":"<p>Data visualization is the graphical representation of data to help people understand complex data easily.</p> <p>Example: Creating interactive dashboards using Matplotlib or Seaborn to present findings.</p>"},{"location":"prompts/glossary/#decision-tree","title":"Decision Tree","text":"<p>A decision tree is a flowchart-like structure used for making decisions or predictions based on input features.</p> <p>Example: Building a decision tree classifier to predict whether a loan application should be approved.</p>"},{"location":"prompts/glossary/#deep-learning","title":"Deep Learning","text":"<p>Deep learning is a subset of machine learning involving neural networks with multiple layers that can learn representations from data.</p> <p>Example: Exploring deep learning concepts by creating a neural network for image recognition tasks.</p>"},{"location":"prompts/glossary/#dimensionality-reduction","title":"Dimensionality Reduction","text":"<p>Dimensionality reduction involves reducing the number of input variables in a dataset while retaining as much information as possible.</p> <p>Example: Using Principal Component Analysis (PCA) to reduce features before training a model.</p>"},{"location":"prompts/glossary/#distribution","title":"Distribution","text":"<p>A distribution describes how values of a variable are spread or dispersed.</p> <p>Example: Plotting the normal distribution of test scores to analyze class performance.</p>"},{"location":"prompts/glossary/#dummy-variable","title":"Dummy Variable","text":"<p>A dummy variable is a binary variable created to include categorical data in regression models.</p> <p>Example: Converting categorical variables like 'Gender' into dummy variables for a regression analysis.</p>"},{"location":"prompts/glossary/#encoding","title":"Encoding","text":"<p>Encoding transforms data into a different format using a specific scheme.</p> <p>Example: Applying one-hot encoding to convert categorical variables into numerical format for machine learning models.</p>"},{"location":"prompts/glossary/#ensemble-learning","title":"Ensemble Learning","text":"<p>Ensemble learning combines predictions from multiple machine learning models to improve overall performance.</p> <p>Example: Using a random forest, which is an ensemble of decision trees, to enhance prediction accuracy.</p>"},{"location":"prompts/glossary/#exploratory-data-analysis-eda","title":"Exploratory Data Analysis (EDA)","text":"<p>EDA is an approach to analyzing data sets to summarize their main characteristics, often using visual methods.</p> <p>Example: Performing EDA to detect anomalies and patterns before building predictive models.</p>"},{"location":"prompts/glossary/#feature-engineering","title":"Feature Engineering","text":"<p>Feature engineering involves creating new input features from existing ones to improve model performance.</p> <p>Example: Combining 'Date of Birth' and 'Current Date' to create a new feature 'Age' for a predictive model.</p>"},{"location":"prompts/glossary/#feature-scaling","title":"Feature Scaling","text":"<p>Feature scaling adjusts the range of features in the data to ensure they contribute equally to the model.</p> <p>Example: Applying standardization to features before using gradient descent algorithms.</p>"},{"location":"prompts/glossary/#feature-selection","title":"Feature Selection","text":"<p>Feature selection is the process of selecting a subset of relevant features for model construction.</p> <p>Example: Using correlation analysis to remove redundant features that do not improve the model.</p>"},{"location":"prompts/glossary/#function","title":"Function","text":"<p>In programming, a function is a block of organized, reusable code that performs a single action.</p> <p>Example: Defining a Python function to calculate the mean of a list of numbers in data analysis.</p>"},{"location":"prompts/glossary/#f1-score","title":"F1 Score","text":"<p>The F1 score is the harmonic mean of precision and recall, used as a measure of a test's accuracy.</p> <p>Example: Evaluating a classification model with imbalanced classes using the F1 score.</p>"},{"location":"prompts/glossary/#gradient-boosting","title":"Gradient Boosting","text":"<p>Gradient Boosting is an ensemble technique that builds models sequentially, each correcting the errors of the previous one.</p> <p>Example: Implementing Gradient Boosting Machines (GBM) to improve prediction accuracy on complex datasets.</p>"},{"location":"prompts/glossary/#gradient-descent","title":"Gradient Descent","text":"<p>Gradient descent is an optimization algorithm used to minimize the cost function in machine learning models.</p> <p>Example: Using gradient descent to find the optimal weights in a linear regression model.</p>"},{"location":"prompts/glossary/#grid-search","title":"Grid Search","text":"<p>Grid search is a hyperparameter optimization technique that exhaustively searches through a specified subset of hyperparameters.</p> <p>Example: Applying grid search to find the best combination of parameters for a support vector machine classifier.</p>"},{"location":"prompts/glossary/#histogram","title":"Histogram","text":"<p>A histogram is a graphical representation showing the distribution of numerical data by depicting the number of data points that fall within specified ranges.</p> <p>Example: Creating a histogram to visualize the frequency distribution of ages in a dataset.</p>"},{"location":"prompts/glossary/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<p>Hyperparameter tuning involves adjusting the parameters that govern the training process of a model to improve performance.</p> <p>Example: Tuning the number of trees and depth in a random forest model to achieve better accuracy.</p>"},{"location":"prompts/glossary/#hypothesis-testing","title":"Hypothesis Testing","text":"<p>Hypothesis testing is a statistical method used to make decisions about the properties of a population based on sample data.</p> <p>Example: Conducting a t-test to determine if there is a significant difference between two groups' means.</p>"},{"location":"prompts/glossary/#imputation","title":"Imputation","text":"<p>Imputation is the process of replacing missing data with substituted values.</p> <p>Example: Filling missing values in a dataset with the mean or median of the column.</p>"},{"location":"prompts/glossary/#inferential-statistics","title":"Inferential Statistics","text":"<p>Inferential statistics use a random sample of data taken from a population to describe and make inferences about the population.</p> <p>Example: Estimating the average height of all students in a university by sampling a subset.</p>"},{"location":"prompts/glossary/#interpolation","title":"Interpolation","text":"<p>Interpolation is a method of estimating unknown values that fall between known data points.</p> <p>Example: Using interpolation to estimate missing temperature readings in a time series dataset.</p>"},{"location":"prompts/glossary/#json-javascript-object-notation","title":"JSON (JavaScript Object Notation)","text":"<p>JSON is a lightweight data-interchange format that is easy for humans to read and write and for machines to parse and generate.</p> <p>Example: Reading data from a JSON file into a Pandas DataFrame for analysis.</p>"},{"location":"prompts/glossary/#jupyter-notebook","title":"Jupyter Notebook","text":"<p>Jupyter Notebook is an open-source web application that allows you to create and share documents containing live code, equations, visualizations, and narrative text.</p> <p>Example: Using Jupyter Notebook to write Python code and document the data analysis process.</p>"},{"location":"prompts/glossary/#k-means-clustering","title":"k-means Clustering","text":"<p>k-means clustering is an unsupervised learning algorithm that partitions data into k distinct clusters based on feature similarity.</p> <p>Example: Segmenting customers into groups based on purchasing behavior using k-means clustering.</p>"},{"location":"prompts/glossary/#k-nearest-neighbors-knn","title":"K-Nearest Neighbors (KNN)","text":"<p>KNN is a simple, supervised machine learning algorithm that classifies new cases based on the majority class of their k nearest neighbors.</p> <p>Example: Implementing KNN to predict whether a patient has a certain disease based on symptoms.</p>"},{"location":"prompts/glossary/#label-encoding","title":"Label Encoding","text":"<p>Label encoding converts categorical text data into numerical values by assigning a unique integer to each category.</p> <p>Example: Transforming the 'Color' feature into numerical labels before model training.</p>"},{"location":"prompts/glossary/#learning-rate","title":"Learning Rate","text":"<p>The learning rate is a hyperparameter that controls how much we adjust the model weights with respect to the loss gradient.</p> <p>Example: Setting an appropriate learning rate in gradient descent to ensure the model converges.</p>"},{"location":"prompts/glossary/#linear-regression","title":"Linear Regression","text":"<p>Linear regression is a supervised learning algorithm that models the relationship between a dependent variable and one or more independent variables.</p> <p>Example: Predicting house prices based on features like size and location using linear regression.</p>"},{"location":"prompts/glossary/#logistic-regression","title":"Logistic Regression","text":"<p>Logistic regression is a classification algorithm used to predict the probability of a categorical dependent variable.</p> <p>Example: Using logistic regression to determine the likelihood of a customer churning.</p>"},{"location":"prompts/glossary/#machine-learning","title":"Machine Learning","text":"<p>Machine learning is a subset of AI that focuses on building systems that learn from and make decisions based on data.</p> <p>Example: Implementing various machine learning algorithms to solve classification and regression problems in the course.</p>"},{"location":"prompts/glossary/#matplotlib","title":"Matplotlib","text":"<p>Matplotlib is a Python library used for creating static, animated, and interactive visualizations.</p> <p>Example: Plotting data trends using Matplotlib to support data analysis conclusions.</p>"},{"location":"prompts/glossary/#missing-data","title":"Missing Data","text":"<p>Missing data occurs when no value is stored for a variable in an observation, which can impact data analysis.</p> <p>Example: Identifying and handling missing data in a dataset before model training.</p>"},{"location":"prompts/glossary/#model-selection","title":"Model Selection","text":"<p>Model selection involves choosing the best model from a set of candidates based on their predictive performance.</p> <p>Example: Comparing different algorithms like decision trees and logistic regression to select the best model for a classification task.</p>"},{"location":"prompts/glossary/#multicollinearity","title":"Multicollinearity","text":"<p>Multicollinearity occurs when independent variables in a regression model are highly correlated, which can affect the model's stability.</p> <p>Example: Detecting multicollinearity using the Variance Inflation Factor (VIF) and addressing it in the dataset.</p>"},{"location":"prompts/glossary/#natural-language-processing-nlp","title":"Natural Language Processing (NLP)","text":"<p>NLP is a field of AI that gives computers the ability to understand, interpret, and generate human language.</p> <p>Example: Analyzing text data for sentiment analysis using NLP techniques.</p>"},{"location":"prompts/glossary/#neural-network","title":"Neural Network","text":"<p>A neural network is a series of algorithms that mimic the operations of a human brain to recognize patterns and solve complex problems.</p> <p>Example: Building a simple neural network to classify images of handwritten digits.</p>"},{"location":"prompts/glossary/#normal-distribution","title":"Normal Distribution","text":"<p>The normal distribution is a continuous probability distribution characterized by a symmetrical, bell-shaped curve.</p> <p>Example: Assuming normal distribution of residuals in linear regression models.</p>"},{"location":"prompts/glossary/#normalization","title":"Normalization","text":"<p>Normalization scales data to fit within a specific range, often between 0 and 1, to ensure all features contribute equally.</p> <p>Example: Applying Min-Max normalization to features before training a neural network.</p>"},{"location":"prompts/glossary/#numpy","title":"NumPy","text":"<p>NumPy is a Python library used for working with arrays and providing functions for mathematical operations on large, multi-dimensional arrays and matrices.</p> <p>Example: Using NumPy arrays for efficient numerical computations in data science projects.</p>"},{"location":"prompts/glossary/#one-hot-encoding","title":"One-Hot Encoding","text":"<p>One-hot encoding converts categorical variables into a binary matrix representation.</p> <p>Example: Transforming the 'Country' feature into multiple binary columns representing each country.</p>"},{"location":"prompts/glossary/#optimization","title":"Optimization","text":"<p>Optimization involves adjusting the inputs or parameters of a model to minimize or maximize some objective function.</p> <p>Example: Optimizing the weights in a neural network to reduce the loss function during training.</p>"},{"location":"prompts/glossary/#outlier","title":"Outlier","text":"<p>An outlier is a data point that differs significantly from other observations, potentially indicating variability in measurement or experimental errors.</p> <p>Example: Identifying outliers in a dataset using box plots and deciding whether to remove or transform them.</p>"},{"location":"prompts/glossary/#overfitting","title":"Overfitting","text":"<p>Overfitting occurs when a model learns the training data too well, capturing noise and details that negatively impact its performance on new data.</p> <p>Example: Preventing overfitting by using regularization techniques and cross-validation.</p>"},{"location":"prompts/glossary/#pandas","title":"Pandas","text":"<p>Pandas is a Python library providing high-performance, easy-to-use data structures and data analysis tools.</p> <p>Example: Using Pandas DataFrames to manipulate and analyze tabular data in the course.</p>"},{"location":"prompts/glossary/#parameter","title":"Parameter","text":"<p>A parameter is a configuration variable that is internal to the model and estimated from data.</p> <p>Example: The coefficients in a linear regression model are parameters learned during training.</p>"},{"location":"prompts/glossary/#pca-principal-component-analysis","title":"PCA (Principal Component Analysis)","text":"<p>PCA is a dimensionality reduction technique that transforms data into a new coordinate system, reducing the number of variables while retaining most information.</p> <p>Example: Applying PCA to reduce the dimensionality of a dataset before clustering.</p>"},{"location":"prompts/glossary/#pipeline","title":"Pipeline","text":"<p>A pipeline is a sequence of data processing components or steps, where the output of one component is the input to the next.</p> <p>Example: Creating a scikit-learn pipeline to standardize data and train a model in a single workflow.</p>"},{"location":"prompts/glossary/#precision","title":"Precision","text":"<p>Precision is a metric that measures the proportion of true positives among all positive predictions.</p> <p>Example: Calculating precision to evaluate a model where false positives are costly, such as in fraud detection.</p>"},{"location":"prompts/glossary/#predictive-modeling","title":"Predictive Modeling","text":"<p>Predictive modeling uses statistics and data to predict outcomes with data models.</p> <p>Example: Building a predictive model to forecast sales based on historical data.</p>"},{"location":"prompts/glossary/#probability-distribution","title":"Probability Distribution","text":"<p>A probability distribution describes how the values of a random variable are distributed.</p> <p>Example: Using the normal distribution to model the heights of individuals in a population.</p>"},{"location":"prompts/glossary/#python","title":"Python","text":"<p>Python is a high-level, interpreted programming language known for its readability and versatility in data science.</p> <p>Example: Writing Python scripts to automate data cleaning and analysis tasks.</p>"},{"location":"prompts/glossary/#random-forest","title":"Random Forest","text":"<p>Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes for classification tasks.</p> <p>Example: Implementing a random forest classifier to improve accuracy over a single decision tree.</p>"},{"location":"prompts/glossary/#regression","title":"Regression","text":"<p>Regression is a set of statistical processes for estimating the relationships among variables.</p> <p>Example: Performing linear regression to understand how the price of a house varies with its size.</p>"},{"location":"prompts/glossary/#regularization","title":"Regularization","text":"<p>Regularization adds a penalty to the loss function to prevent overfitting by discouraging complex models.</p> <p>Example: Applying Lasso regularization to reduce overfitting in a regression model.</p>"},{"location":"prompts/glossary/#recall","title":"Recall","text":"<p>Recall is a metric that measures the proportion of actual positives correctly identified.</p> <p>Example: Evaluating recall in a medical diagnosis model where missing a positive case is critical.</p>"},{"location":"prompts/glossary/#roc-curve-receiver-operating-characteristic-curve","title":"ROC Curve (Receiver Operating Characteristic Curve)","text":"<p>An ROC curve is a graphical plot illustrating the diagnostic ability of a binary classifier as its discrimination threshold is varied.</p> <p>Example: Plotting the ROC curve to select the optimal threshold for a classification model.</p>"},{"location":"prompts/glossary/#root-mean-squared-error-rmse","title":"Root Mean Squared Error (RMSE)","text":"<p>RMSE is a metric used to measure the difference between values predicted by a model and the actual values.</p> <p>Example: Using RMSE to assess the performance of a regression model predicting housing prices.</p>"},{"location":"prompts/glossary/#sampling","title":"Sampling","text":"<p>Sampling involves selecting a subset of data from a larger dataset to estimate characteristics of the whole population.</p> <p>Example: Drawing a random sample from a large dataset to make computations more manageable.</p>"},{"location":"prompts/glossary/#scikit-learn","title":"Scikit-learn","text":"<p>Scikit-learn is a Python library for machine learning that provides simple and efficient tools for data analysis and modeling.</p> <p>Example: Using scikit-learn to implement machine learning algorithms like SVMs and random forests.</p>"},{"location":"prompts/glossary/#seaborn","title":"Seaborn","text":"<p>Seaborn is a Python data visualization library based on Matplotlib that provides a high-level interface for drawing attractive statistical graphics.</p> <p>Example: Creating complex visualizations like heatmaps and violin plots using Seaborn.</p>"},{"location":"prompts/glossary/#smote-synthetic-minority-over-sampling-technique","title":"SMOTE (Synthetic Minority Over-sampling Technique)","text":"<p>SMOTE is a technique used to address class imbalance by generating synthetic samples of the minority class.</p> <p>Example: Applying SMOTE to balance the dataset before training a classifier on imbalanced data.</p>"},{"location":"prompts/glossary/#standard-deviation","title":"Standard Deviation","text":"<p>Standard deviation measures the amount of variation or dispersion in a set of values.</p> <p>Example: Calculating the standard deviation to understand the spread of exam scores in a class.</p>"},{"location":"prompts/glossary/#standardscaler","title":"StandardScaler","text":"<p>StandardScaler is a scikit-learn tool that standardizes features by removing the mean and scaling to unit variance.</p> <p>Example: Using StandardScaler to preprocess data before feeding it into a machine learning algorithm.</p>"},{"location":"prompts/glossary/#statistical-significance","title":"Statistical Significance","text":"<p>Statistical significance indicates that the result of a test is unlikely to have occurred by chance alone.</p> <p>Example: Interpreting p-values to determine if the difference between two groups is statistically significant.</p>"},{"location":"prompts/glossary/#supervised-learning","title":"Supervised Learning","text":"<p>Supervised learning is a type of machine learning where models are trained using labeled data.</p> <p>Example: Training a supervised learning model to predict house prices based on historical data.</p>"},{"location":"prompts/glossary/#time-series","title":"Time Series","text":"<p>Time series data is a sequence of data points collected or recorded at time intervals.</p> <p>Example: Analyzing stock prices over time to forecast future market trends.</p>"},{"location":"prompts/glossary/#tokenization","title":"Tokenization","text":"<p>Tokenization is the process of breaking text into smaller units called tokens, often words or phrases.</p> <p>Example: Tokenizing text data for input into a natural language processing model.</p>"},{"location":"prompts/glossary/#training-set","title":"Training Set","text":"<p>A training set is a subset of the dataset used to train machine learning models.</p> <p>Example: Splitting data into training and test sets to build and evaluate a model.</p>"},{"location":"prompts/glossary/#t-test","title":"T-test","text":"<p>A t-test is a statistical test used to compare the means of two groups.</p> <p>Example: Performing a t-test to determine if there is a significant difference in test scores between two classes.</p>"},{"location":"prompts/glossary/#underfitting","title":"Underfitting","text":"<p>Underfitting occurs when a model is too simple and fails to capture the underlying pattern of the data.</p> <p>Example: Addressing underfitting by increasing the complexity of the model or adding more features.</p>"},{"location":"prompts/glossary/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>Unsupervised learning involves training models on data without labeled responses, aiming to find hidden patterns.</p> <p>Example: Using unsupervised learning techniques like clustering to segment customers.</p>"},{"location":"prompts/glossary/#validation-set","title":"Validation Set","text":"<p>A validation set is a subset of the dataset used to tune hyperparameters and prevent overfitting during model training.</p> <p>Example: Using a validation set to adjust the learning rate and number of layers in a neural network.</p>"},{"location":"prompts/glossary/#variance","title":"Variance","text":"<p>Variance measures how far a set of numbers is spread out from their average value.</p> <p>Example: Calculating the variance to understand the variability in a dataset.</p>"},{"location":"prompts/glossary/#visualization","title":"Visualization","text":"<p>Visualization refers to the graphical representation of information and data.</p> <p>Example: Creating line charts and scatter plots to visualize trends and relationships in the data.</p>"},{"location":"prompts/glossary/#weight","title":"Weight","text":"<p>In machine learning models, weights are parameters that are learned during training to map input features to outputs.</p> <p>Example: Adjusting weights in a neural network during training to minimize the loss function.</p>"},{"location":"prompts/glossary/#z-score","title":"Z-score","text":"<p>A z-score indicates how many standard deviations an element is from the mean.</p> <p>Example: Calculating z-scores to identify outliers in a dataset.</p>"},{"location":"prompts/glossary/#xgboost","title":"XGBoost","text":"<p>XGBoost is an optimized distributed gradient boosting library designed to be highly efficient and flexible.</p> <p>Example: Implementing XGBoost to improve model performance on a classification task.</p>"},{"location":"prompts/glossary/#confusion-matrix_1","title":"Confusion Matrix","text":"<p>A confusion matrix is a table used to describe the performance of a classification model.</p> <p>Example: Using a confusion matrix to calculate precision, recall, and F1 score for a classifier.</p>"},{"location":"prompts/glossary/#hyperparameter","title":"Hyperparameter","text":"<p>A hyperparameter is a configuration that is external to the model and whose value cannot be estimated from data.</p> <p>Example: Setting the number of neighbors in a KNN algorithm as a hyperparameter to tune.</p>"},{"location":"prompts/glossary/#kernel","title":"Kernel","text":"<p>In machine learning, a kernel is a function used in algorithms like SVM to transform data into a higher-dimensional space.</p> <p>Example: Choosing a radial basis function (RBF) kernel for an SVM to handle non-linear data.</p>"},{"location":"prompts/glossary/#lasso-regression","title":"Lasso Regression","text":"<p>Lasso regression is a type of linear regression that uses L1 regularization to reduce overfitting and perform feature selection.</p> <p>Example: Applying lasso regression to identify the most important features in a dataset.</p>"},{"location":"prompts/glossary/#mean-absolute-error-mae","title":"Mean Absolute Error (MAE)","text":"<p>MAE is a measure of errors between paired observations expressing the same phenomenon.</p> <p>Example: Evaluating a regression model by calculating the MAE between predicted and actual values.</p>"},{"location":"prompts/glossary/#overfitting_1","title":"Overfitting","text":"<p>Overfitting occurs when a model learns the training data too well, capturing noise and details that negatively impact performance on new data.</p> <p>Example: Observing overfitting in a model that performs well on training data but poorly on test data.</p>"},{"location":"prompts/glossary/#pearson-correlation-coefficient","title":"Pearson Correlation Coefficient","text":"<p>The Pearson correlation coefficient measures the linear correlation between two variables.</p> <p>Example: Calculating the Pearson coefficient to assess the strength of the relationship between two features.</p>"},{"location":"prompts/glossary/#r-squared-coefficient-of-determination","title":"R-Squared (Coefficient of Determination)","text":"<p>R-squared is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by independent variables.</p> <p>Example: Interpreting an R-squared value of 0.85 to mean that 85% of the variance in the dependent variable is predictable.</p>"},{"location":"prompts/glossary/#sampling-bias","title":"Sampling Bias","text":"<p>Sampling bias occurs when some members of a population are systematically more likely to be selected in a sample than others.</p> <p>Example: Ensuring random sampling in data collection to avoid sampling bias.</p>"},{"location":"prompts/glossary/#tokenization_1","title":"Tokenization","text":"<p>Tokenization is the process of splitting text into individual units (tokens), such as words or phrases.</p> <p>Example: Tokenizing customer reviews to prepare text data for sentiment analysis.</p>"},{"location":"prompts/glossary/#univariate-analysis","title":"Univariate Analysis","text":"<p>Univariate analysis examines each variable individually to summarize and find patterns.</p> <p>Example: Performing univariate analysis on the 'Age' feature to understand its distribution.</p>"},{"location":"prompts/glossary/#variance-inflation-factor-vif","title":"Variance Inflation Factor (VIF)","text":"<p>VIF quantifies the severity of multicollinearity in regression analysis.</p> <p>Example: Calculating VIF to detect multicollinearity and decide whether to remove correlated features.</p>"},{"location":"prompts/glossary/#white-noise","title":"White Noise","text":"<p>White noise refers to a time series of random data points that have a constant mean and variance.</p> <p>Example: Checking residuals for white noise to validate the assumptions of a time series model.</p>"},{"location":"prompts/glossary/#cross-entropy-loss","title":"Cross-Entropy Loss","text":"<p>Cross-entropy loss measures the performance of a classification model whose output is a probability between 0 and 1.</p> <p>Example: Using cross-entropy loss as the loss function in a logistic regression model.</p>"},{"location":"prompts/glossary/#epoch","title":"Epoch","text":"<p>An epoch refers to one complete pass through the entire training dataset.</p> <p>Example: Training a neural network for 10 epochs to optimize the weights.</p>"},{"location":"prompts/glossary/#fitting","title":"Fitting","text":"<p>Fitting a model involves adjusting its parameters to best match the data.</p> <p>Example: Fitting a linear regression model to the training data by minimizing the cost function.</p>"},{"location":"prompts/glossary/#hyperplane","title":"Hyperplane","text":"<p>A hyperplane is a flat affine subspace of one dimension less than its ambient space, used in SVMs to separate classes.</p> <p>Example: Understanding how an SVM finds the optimal hyperplane to classify data points.</p>"},{"location":"prompts/glossary/#iteration","title":"Iteration","text":"<p>An iteration refers to one update of the model's parameters during training.</p> <p>Example: Observing loss reduction after each iteration in gradient descent optimization.</p>"},{"location":"prompts/glossary/#learning-curve","title":"Learning Curve","text":"<p>A learning curve plots the model's performance on the training and validation sets over time or as the training set size increases.</p> <p>Example: Analyzing the learning curve to diagnose if a model is overfitting or underfitting.</p>"},{"location":"prompts/glossary/#loss-function","title":"Loss Function","text":"<p>A loss function measures how well a machine learning model performs, guiding the optimization process.</p> <p>Example: Using Mean Squared Error (MSE) as the loss function in a regression model.</p>"},{"location":"prompts/glossary/#mini-batch-gradient-descent","title":"Mini-Batch Gradient Descent","text":"<p>Mini-batch gradient descent is an optimization algorithm that updates the model parameters using small batches of data.</p> <p>Example: Accelerating training by using mini-batches instead of the entire dataset in each iteration.</p>"},{"location":"prompts/glossary/#multivariate-analysis","title":"Multivariate Analysis","text":"<p>Multivariate analysis examines the relationship between multiple variables simultaneously.</p> <p>Example: Performing multivariate regression to understand how multiple features affect the target variable.</p>"},{"location":"prompts/glossary/#natural-language-processing-nlp_1","title":"Natural Language Processing (NLP)","text":"<p>NLP focuses on the interaction between computers and human language.</p> <p>Example: Using NLP techniques to analyze customer feedback and extract key themes.</p>"},{"location":"prompts/glossary/#optimization-algorithm","title":"Optimization Algorithm","text":"<p>An optimization algorithm adjusts the parameters of a model to minimize the loss function.</p> <p>Example: Choosing Adam optimizer for faster convergence in training a neural network.</p>"},{"location":"prompts/glossary/#precision-recall-curve","title":"Precision-Recall Curve","text":"<p>A precision-recall curve plots the trade-off between precision and recall for different threshold settings.</p> <p>Example: Using the precision-recall curve to select the threshold that balances precision and recall.</p>"},{"location":"prompts/glossary/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>Reinforcement learning is a type of machine learning where an agent learns to make decisions by performing actions and receiving rewards.</p> <p>Example: Discussing reinforcement learning concepts as an advanced topic in the course.</p>"},{"location":"prompts/glossary/#stratified-sampling","title":"Stratified Sampling","text":"<p>Stratified sampling involves dividing the population into subgroups and sampling from each to ensure representation.</p> <p>Example: Using stratified sampling to maintain the class distribution in training and test sets.</p>"},{"location":"prompts/glossary/#support-vector-machine-svm","title":"Support Vector Machine (SVM)","text":"<p>SVM is a supervised learning algorithm that finds the hyperplane that best separates classes.</p> <p>Example: Implementing an SVM classifier for a binary classification problem in the course.</p>"},{"location":"prompts/glossary/#synthetic-data","title":"Synthetic Data","text":"<p>Synthetic data is artificially generated data that mimics the properties of real data.</p> <p>Example: Generating synthetic data to augment the dataset and improve model training.</p>"},{"location":"prompts/glossary/#training-loss","title":"Training Loss","text":"<p>Training loss measures the error on the training dataset during model training.</p> <p>Example: Monitoring training loss to assess how well the model is learning from the training data.</p>"},{"location":"prompts/glossary/#type-i-error","title":"Type I Error","text":"<p>A Type I error occurs when the null hypothesis is true but is incorrectly rejected.</p> <p>Example: Understanding Type I errors when interpreting p-values in hypothesis testing.</p>"},{"location":"prompts/glossary/#type-ii-error","title":"Type II Error","text":"<p>A Type II error occurs when the null hypothesis is false but erroneously fails to be rejected.</p> <p>Example: Recognizing the implications of Type II errors in statistical testing.</p>"},{"location":"prompts/glossary/#validation-loss","title":"Validation Loss","text":"<p>Validation loss measures the error on the validation dataset, used to tune model hyperparameters.</p> <p>Example: Observing validation loss to detect overfitting during model training.</p>"},{"location":"prompts/glossary/#weight-initialization","title":"Weight Initialization","text":"<p>Weight initialization is the process of setting the initial values of the weights before training a neural network.</p> <p>Example: Using random initialization methods to start training a deep learning model.</p>"},{"location":"prompts/glossary/#word-embedding","title":"Word Embedding","text":"<p>Word embedding is a representation of text where words with similar meaning have similar vector representations.</p> <p>Example: Implementing word embeddings like Word2Vec in NLP tasks.</p>"},{"location":"prompts/glossary/#xgboost_1","title":"XGBoost","text":"<p>XGBoost is an optimized gradient boosting library designed for performance and speed.</p> <p>Example: Using XGBoost to improve model accuracy in classification problems.</p>"},{"location":"prompts/glossary/#z-score-normalization","title":"Z-score Normalization","text":"<p>Z-score normalization scales data based on mean and standard deviation.</p> <p>Example: Applying z-score normalization to standardize features before training a model.</p> <p>o1</p>"},{"location":"prompts/library-comparison-prompt/","title":"Comparison of Matplotlib and Plotly for GenAI-Created Plots and Animations","text":""},{"location":"prompts/library-comparison-prompt/#prompt","title":"Prompt","text":"<pre><code>Compare the Python libraries matplotlib with plotly.\nWhat are the pros and cons for GenAI created plots and animations?\n\nWhen choosing between **Matplotlib** and **Plotly** for creating\nplots and animations with generative AI, here are their pros and cons?\n</code></pre>"},{"location":"prompts/library-comparison-prompt/#chatgpt-response","title":"ChatGPT Response","text":""},{"location":"prompts/library-comparison-prompt/#matplotlib","title":"Matplotlib","text":"<p>Matplotlib is a versatile and widely-used Python library for creating static, animated, and interactive visualizations.</p>"},{"location":"prompts/library-comparison-prompt/#pros","title":"Pros","text":"<ol> <li>Simplicity and Customization:</li> <li>Great for generating static, publication-quality plots with fine-grained control.</li> <li> <p>Straightforward API for generating standard visualizations like line plots, bar charts, and scatter plots.</p> </li> <li> <p>Broad Ecosystem Support:</p> </li> <li>Integrates well with NumPy, pandas, and other scientific libraries.</li> <li> <p>Supported by many GenAI frameworks for generating data visualizations.</p> </li> <li> <p>Animations:</p> </li> <li>Provides tools for creating animations (e.g., <code>FuncAnimation</code>).</li> <li> <p>Ideal for embedding animations in applications or saving them as GIFs or videos.</p> </li> <li> <p>Customization:</p> </li> <li>Allows deep customization of every aspect of the plot.</li> <li> <p>Perfect for generating AI-tailored visualizations that require specific formats or aesthetics.</p> </li> <li> <p>Lightweight and Efficient:</p> </li> <li>Better for lightweight tasks where interactivity is not required.</li> </ol>"},{"location":"prompts/library-comparison-prompt/#cons","title":"Cons","text":"<ol> <li>Steep Learning Curve:</li> <li>Customizing plots can become verbose and complicated, especially for advanced layouts.</li> <li> <p>Syntax can feel tedious for beginners or for generating multiple visualizations programmatically.</p> </li> <li> <p>Limited Interactivity:</p> </li> <li>Interactivity is minimal compared to modern libraries like Plotly.</li> <li> <p>Interactive plots require third-party tools (e.g., <code>mpld3</code>) and are often less intuitive.</p> </li> <li> <p>Outdated Animations:</p> </li> <li>Animations are not as smooth or interactive as those created by Plotly.</li> </ol>"},{"location":"prompts/library-comparison-prompt/#plotly","title":"Plotly","text":"<p>Plotly is a modern library for creating highly interactive and dynamic visualizations.</p>"},{"location":"prompts/library-comparison-prompt/#pros_1","title":"Pros","text":"<ol> <li>Interactivity:</li> <li>All visualizations are interactive by default (e.g., zooming, panning, tooltips).</li> <li> <p>Excellent for dashboards, presentations, and GenAI-generated insights.</p> </li> <li> <p>Ease of Use:</p> </li> <li>Simple syntax for creating complex plots, suitable for AI-generated visualizations.</li> <li> <p>Works seamlessly with data from pandas, NumPy, and other libraries.</p> </li> <li> <p>Browser-Based Rendering:</p> </li> <li>Plots render in web browsers using JavaScript, making them highly portable and shareable.</li> <li> <p>Supports embedding in Jupyter Notebooks, web apps, and standalone HTML files.</p> </li> <li> <p>Built-in Animations:</p> </li> <li>Easy to create smooth, interactive animations with native support.</li> <li> <p>Ideal for demonstrating dynamic AI models or processes.</p> </li> <li> <p>Wide Range of Charts:</p> </li> <li>Includes advanced visualizations like 3D plots, heatmaps, choropleth maps, and Sankey diagrams.</li> <li>Perfect for showing complex GenAI outputs in an intuitive way.</li> </ol>"},{"location":"prompts/library-comparison-prompt/#cons_1","title":"Cons","text":"<ol> <li>Heavier and Slower:</li> <li>More resource-intensive due to JavaScript-based interactivity.</li> <li> <p>Can slow down with large datasets or complex visualizations.</p> </li> <li> <p>Limited Fine-Grained Control:</p> </li> <li>While customizable, it lacks the deep control over plot details that Matplotlib offers.</li> <li> <p>Certain niche visualizations might be harder to implement.</p> </li> <li> <p>Dependency on JavaScript:</p> </li> <li> <p>Requires JavaScript runtime for rendering, which might not be ideal for all environments.</p> </li> <li> <p>Animation Complexity:</p> </li> <li>While animations are smoother, creating complex animations programmatically can be less intuitive than with Matplotlib.</li> </ol>"},{"location":"prompts/library-comparison-prompt/#which-to-choose-for-genai","title":"Which to Choose for GenAI?","text":"<ol> <li>Static Plots:</li> <li>Use Matplotlib for quick, customizable, high-quality static plots.</li> <li> <p>Example: Generating high-resolution images for reports or papers.</p> </li> <li> <p>Interactive and Animated Plots:</p> </li> <li>Use Plotly for dynamic and interactive plots.</li> <li> <p>Example: Interactive GenAI dashboards or showcasing dynamic AI model predictions.</p> </li> <li> <p>Collaborative and Web-Based Use:</p> </li> <li> <p>Use Plotly if your plots need to be shared on the web or included in interactive applications.</p> </li> <li> <p>Complex Animations:</p> </li> <li>Use Matplotlib for complex, programmatically controlled animations.</li> <li>Use Plotly for simple, interactive animations with smooth transitions.</li> </ol>"},{"location":"prompts/library-comparison-prompt/#conclusion","title":"Conclusion","text":"<p>Both libraries are valuable for different contexts: - Matplotlib shines in fine-grained control and efficient static or programmatic visualizations. - Plotly is the go-to for interactivity, browser-based plots, and user-friendly animations.</p> <p>For GenAI, combining both libraries strategically (e.g., static plots with Matplotlib and interactive plots with Plotly) can provide the best of both worlds.</p>"},{"location":"prompts/microsim/","title":"Generating a MicroSim Prompt","text":"<p>Prompt</p> <p>Please generate a p5.js Javascript file that assumes that the canvas is placed in a <code>&lt;main&gt;</code> HTML element. Follow the rules from the file width-adaptive-microsim-rules.md. The title of the MicroSim is [TITLE]. The purpose of the MicroSim is [PURPOSE]. The description of the MicroSim is [DESCRIPTION]. The input controls are [CONTROLS].</p>"},{"location":"prompts/quiz/","title":"Data Science Quiz","text":""},{"location":"prompts/quiz/#sample-prompt","title":"Sample Prompt","text":"<pre><code>I am preparing a review quiz for a freshman course called \"Introduction to Data Science with Python\".\nFor the concept of the NumPy Python library, create a four-answer\nmultiple choice question\nabout what it is primarily used for in Data Science.  Create three\nplausible destructor answers that are not correct but have a\nsimilar form to the correct answer.  Use the following format:\n\n#### What is the primary purpose of the NumPy?\n\nA. Bla Bla Bla\nB. Bla Bla Bla\nC. Bla Bla Bla\nD. Bla Bla Bla\n\n??? note \"Show Answer\"\n\n    The correct answer is **LETTER**.  Explanation of answer text.\n</code></pre>"},{"location":"prompts/quiz/#response","title":"Response","text":""},{"location":"prompts/quiz/#what-is-the-primary-purpose-of-numpy","title":"What is the primary purpose of NumPy?","text":"<p>A. Data visualization and creating complex plots for reports B. Machine learning model training and hyperparameter tuning C. Performing numerical computations and handling multi-dimensional arrays D. Creating interactive web-based dashboards for data exploration</p> Show Answer <p>The correct answer is C. NumPy is primarily used for numerical computations, including working with multi-dimensional arrays and matrices, and providing mathematical functions to perform operations on these arrays efficiently.</p>"},{"location":"sims/","title":"List of MicroSims for Data Science","text":"<p>Learning Graph</p>"},{"location":"sims/bell-curve/","title":"Bell Curve Emergence","text":""},{"location":"sims/bell-curve/#sample-iframe","title":"Sample iframe","text":"<p>You can include the following in your HTML to use this MicroSim</p> <pre><code>&lt;iframe src=\"DOC_ROOT/docs/sims/MICROSIM_NAME/main.html\" height=\"500px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim Edit this MicroSim</p> <p>Topics: Normal distribution, Central Limit Theorem (CLT), sampling distribution of the mean, law of large numbers, z\u2011scores</p> <p>Description: Students watch a true bell curve emerge in real time by repeatedly sampling from a non\u2011normal base distribution (choose Uniform, Skewed, Exponential, or Bernoulli). Each iteration draws <code>n</code> observations, computes their sample mean, and drops a small dot into a running histogram of sample means. As more means accumulate and/or as <code>n</code> increases, the histogram approaches a normal (Gaussian) curve. Overlay a theoretical normal with mean <code>\u03bc</code> (of the base distribution) and standard deviation <code>\u03c3/\u221an</code> to make the convergence explicit. Optional shading shows central probability regions (e.g., \u00b11\u03c3, \u00b12\u03c3).</p> <p>Input Controls (in controls region):</p> <ol> <li> <p>Base Distribution (dropdown: Uniform[0,1], Skewed (Beta), Exponential(\u03bb), Bernoulli(p))</p> </li> <li> <p>Sample Size (n) (slider: 1 \u2192 100, default 10)</p> </li> <li> <p>Samples per Tick (slider: 1 \u2192 200, default 50) --- controls animation speed</p> </li> <li> <p>Bins (slider: 10 \u2192 80, default 51)</p> </li> <li> <p>Show Theoretical Normal (checkbox)</p> </li> <li> <p>Shade \u00b1\u03c3, \u00b12\u03c3 (checkbox)</p> </li> <li> <p>Start/Pause (button)</p> </li> <li> <p>Reset (button)</p> </li> </ol> <p>On\u2011Canvas Readouts:</p> <ul> <li> <p>Base <code>\u03bc</code>, <code>\u03c3</code>; current <code>n</code>; theoretical sampling SD <code>\u03c3/\u221an</code></p> </li> <li> <p>Running count of sample means collected</p> </li> <li> <p>Optional z\u2011score under cursor (hover on histogram to show area left of x)</p> </li> </ul> <p>Learning Objectives:</p> <ul> <li> <p>See why the sampling distribution of the mean approaches normality regardless of the base distribution.</p> </li> <li> <p>Connect sample size to the spread of the sampling distribution (<code>\u03c3/\u221an</code>).</p> </li> <li> <p>Interpret bell curve parameters visually and relate to empirical rules (68--95--99.7%).</p> </li> <li> <p>Distinguish between a population distribution (often non\u2011normal) and the sampling distribution of the mean (approximately normal for large <code>n</code>).</p> </li> </ul> <p>Difficulty: Intermediate</p> <p>Implementation Notes (p5.js, responsive width per standard rules):</p> <ul> <li> <p>Two\u2011column layout: left = controls + small \"base distribution preview\"; right = main histogram of sample means.</p> </li> <li> <p>Maintain an array <code>means[]</code>; on each tick, generate <code>k = Samples per Tick</code> sample means by drawing <code>n</code> IID values from the chosen base distribution, pushing their averages.</p> </li> <li> <p>Histogram x\u2011axis spans a sensible range around the base mean (e.g., <code>\u03bc \u00b1 4\u03c3</code>); update bin counts incrementally for performance.</p> </li> <li> <p>When \"Show Theoretical Normal\" is checked, draw <code>N(\u03bc, \u03c3\u00b2/n)</code> scaled to histogram area.</p> </li> <li> <p>For shading, fill under the curve between <code>\u03bc\u00b1\u03c3</code> and <code>\u03bc\u00b12\u03c3</code>.</p> </li> <li> <p>Accessibility: <code>describe(description, p5.LABEL)</code> with a clear string like:     \"Sampling distribution simulator that shows a bell curve emerging from sample means drawn from a chosen non\u2011normal population.\"</p> </li> </ul> <p>Nice Extras (optional):</p> <ul> <li> <p>Toggle between \"Sample Means\" vs \"Sample Sums\" (sums also go normal as <code>n</code> grows).</p> </li> <li> <p>Snapshot button to freeze and annotate the current histogram with mean/SD labels.</p> </li> <li> <p>A tiny QQ\u2011plot inset comparing sample means to a perfect normal line.</p> </li> </ul>"},{"location":"sims/book-gen-workflow/","title":"Book Build Workflow","text":"<p>Use these templates to create a MicroSim that can be added to any website with just a single <code>iframe</code> HTML element.</p> <p>You can include this interactive infographic MicroSim in your textbook by adding the following HTML statement to your website:</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/intelligent-textbooks/sims/book-gen-workflow/main.html\" height=\"610px\" scrolling=\"no\" style=\"overflow: hidden;\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the Circle Radius MicroSim</p> <p>Edit this MicroSim</p>"},{"location":"sims/data-science-workflow/","title":"MicroSim Template","text":""},{"location":"sims/data-science-workflow/#sample-iframe","title":"Sample iframe","text":"<p>You can include the following in your HTML to use this MicroSim</p> <pre><code>&lt;iframe src=\"/data-science-course/docs/data-science-workflow/main.html\" height=\"300px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the Data Science Workflow MicroSim Edit the Data Science Workflow MicroSim</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/microsims/sims/spectrum-analyzer/main.html\" height=\"400\"  scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/data-science-workflow/#about-this-microsim","title":"About this MicroSim","text":"<p>This MicroSim teaches us how to specify the drawing of a static filled circle.</p>"},{"location":"sims/data-science-workflow/#sample-prompt","title":"Sample Prompt","text":"<p>Prompt</p> <p>Create a single file p5.js sketch.   Draw a green circle on a 600x400 canvas with a radius of 200.</p>"},{"location":"sims/data-science-workflow/#sample-response","title":"Sample Response","text":"<pre><code>// canvas regions setup\n// let canvasWidth = 750;\nlet drawHeight = 400;\nlet controlHeight = 50;\nlet canvasHeight = drawHeight + controlHeight;\nlet aspectRatio = 1.91; // Open Graph standard\nlet canvasWidth = canvasHeight * aspectRatio;\nlet radius = 200;\n\nfunction setup() {\n  const canvas = createCanvas(canvasWidth, canvasHeight);\n  var mainElement = document.querySelector('main');\n  canvas.parent(mainElement);\n}\n\nfunction draw() {\n  // background of drawing region\n  fill('aliceblue');\n  rect(0, 0, canvasWidth, drawHeight);\n\n  // background of controls\n  fill('whitegray');\n  rect(0, drawHeight, canvasWidth, controlHeight);\n  circle(canvasWidth/2, canvasHeight/2, radius);\n}\n</code></pre>"},{"location":"sims/data-science-workflow/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/data-science-workflow/#grade-level-subject-and-topic","title":"Grade Level, Subject and Topic","text":"<p>9th grade geometry. Circle and radius.</p>"},{"location":"sims/data-science-workflow/#activities","title":"Activities","text":""},{"location":"sims/data-science-workflow/#fill-color","title":"Fill Color","text":"<p>Change the color in the prompt.  You can specify any one of the 140 named colors.</p>"},{"location":"sims/data-science-workflow/#border-weight","title":"Border Weight","text":"<p>Change the prompt to include a black border of width 10.</p>"},{"location":"sims/data-science-workflow/#border-color","title":"Border Color","text":"<p>Change the prompt to make the border purple.</p>"},{"location":"sims/data-science-workflow/#change-the-radius","title":"Change the Radius","text":"<p>Change the prompt to make the circle smaller or larger by changing the radius from 10 to 200.</p>"},{"location":"sims/data-science-workflow/#change-the-location","title":"Change the Location","text":"<p>Change the prompt to move the circle to the left or right.</p>"},{"location":"sims/data-science-workflow/#references","title":"References","text":"<ul> <li>Processing Wiki on Positioning Your Canvas</li> </ul>"},{"location":"sims/ds-prog-lang/","title":"Data Science Programming Language Popularity","text":""},{"location":"sims/ds-prog-lang/#sample-iframe","title":"Sample iframe","text":"<p>You can include the following in your HTML to use this MicroSim</p> <pre><code>&lt;iframe src=\"/data-science-course/docs/sims/da-prog-lang/main.html\" height=\"590px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim Edit this MicroSim</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/microsims/sims/spectrum-analyzer/main.html\" height=\"400\"  scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/ds-prog-lang/#about-this-microsim","title":"About this MicroSim","text":"<p>This chart was created using Claude Sonnet 4 using the following prompt:</p> <p>Prompt</p> <p>Please generate a line plot that shows the popularity of different programming languages for use in data science over the last 15 years.  Make sure to include both Python and R.  Document the source of the dataset.  Make time be the horizontal axis and start at 2010.</p> <p>Claude Sonnet 4 Transcript</p> <p>Claude Public Artifact</p>"},{"location":"sims/ds-prog-lang/#claude-transcript","title":"Claude Transcript","text":"<p>I'll create a line plot showing the popularity of programming languages in data science from 2010 to 2025. Since this requires current data about programming language trends, let me search for reliable sources first.Now let me search for more specific historical data and datasets about programming language trends:Let me fetch some specific data from the Stack Overflow surveys to get actual numbers:Let me search for more historical data about programming language trends:Now I have enough information to create a comprehensive visualization. Let me create a line plot showing programming language popularity trends from 2010-2025, using the data I've gathered from multiple sources.## Programming Language Popularity in Data Science (2010-2025)</p> <p>I've created a comprehensive line plot showing the popularity trends of major programming languages used in data science from 2010 to 2025. The visualization clearly shows time on the horizontal axis starting from 2010, as requested.</p> <p>Key Findings:</p> <p>Python's Dominance: Python has seen explosive growth, reaching approximately 90% usage among data science professionals by 2025, with a 7 percentage point increase from 2024 to 2025 alone. Python achieved a 25.35% share in the TIOBE index by May 2025, the highest rating for any language since Java in 2001.</p> <p>R's Steady Position: R's usage has declined to around 38% in 2025, but remains dominant in research, with more than 60% of papers using regression analysis in 2024-2025 utilizing R.</p> <p>SQL's Continued Relevance: SQL maintains its critical role, utilized by about 53% of data science professionals for data management and querying tasks.</p>"},{"location":"sims/ds-prog-lang/#data-sources","title":"Data Sources","text":"<p>The chart is based on comprehensive data from multiple authoritative sources:</p> <ul> <li>TIOBE Programming Community Index: Monthly rankings based on search engine results from 25 major search engines including Google, Bing, Yahoo, and Wikipedia</li> <li>Stack Overflow Developer Surveys: Annual surveys with 49,000+ to 90,000+ developers from 177 countries, providing insights into actual usage patterns</li> <li>Industry Analysis: Reports from DataCamp, upGrad, and other data science education platforms tracking industry trends</li> <li>Academic Sources: Research from Stanford University and Nature Data Science publications</li> </ul> <p>The visualization demonstrates Python's rise from a niche language to the dominant force in data science, driven by its versatility in AI, machine learning, and automation, while other languages like R and SQL maintain their specialized roles in the data science ecosystem.</p>"},{"location":"sims/ds-prog-lang/#data-source-links","title":"Data Source Links","text":"<ol> <li> <p>Top Programming Language Trends in Data Science: 2025 Insights - June 12, 2025 - upGrad - Analysis of Python, R, and SQL trends in data science, comparing use cases and future programming shifts</p> </li> <li> <p>The Popularity of Data Science Languages: Python and R (April 2023 Update) - April 11, 2023 - Medium - Examination of Python and R rankings in TIOBE, PYPL, and Stack Overflow indices</p> </li> <li> <p>The Popularity of Data Science Languages: Python and R (October 2023 Update) - November 2, 2023 - Medium - Analysis of Python and R trends with Stack Overflow survey insights</p> </li> <li> <p>Popularity Ranking of Programming Languages - January 24, 2025 - Towards Data Science - Comprehensive analysis of programming language trends using Stack Overflow data</p> </li> <li> <p>The Popularity of Data Science Languages: Python and R (March 2024 Update) - November 29, 2024 - Medium - Latest trends showing Python's continued dominance and R's specialized role</p> </li> <li> <p>Top 12 Programming Languages for Data Scientists in 2025 - July 25, 2024 - DataCamp - Comprehensive guide to programming languages for data science with pros and cons analysis</p> </li> <li> <p>Python vs. R vs. SQL: 2025 Data Science Programming Language Trends - April 26, 2025 - Analytics Insight - Comparison of the three dominant data science languages and their use cases</p> </li> <li> <p>The Most Popular Programming Languages in 2025 - February 18, 2025 - Career in STEM - Analysis of programming language popularity with market share percentages</p> </li> <li> <p>Don't Miss Out: 12 Data Science Programming Languages 2025! - July 10, 2025 - upGrad - Overview of essential data science programming languages and their applications</p> </li> <li> <p>Stack Overflow Developer Survey 2025 - 2025 - Stack Overflow - Annual survey of 49,000+ developers from 177 countries on technology usage and trends</p> </li> <li> <p>2025 Stack Overflow Developer Survey Technology Section - 2025 - Stack Overflow - Detailed breakdown of programming language usage and popularity trends</p> </li> <li> <p>TIOBE Programming Index News May 2025 - May 13, 2025 - TechRepublic - Analysis of Python reaching highest TIOBE rating in programming language history</p> </li> <li> <p>Python popularity climbs to highest ever \u2013 Tiobe - May 9, 2025 - InfoWorld - Report on Python achieving 25.35% share in TIOBE index</p> </li> <li> <p>TIOBE Index for August 2025 - August 2025 - TechRepublic - Latest programming language rankings showing Python's continued dominance</p> </li> <li> <p>TIOBE Index - Ongoing - TIOBE Software - Monthly programming language popularity index based on search engine results from 25 major platforms</p> </li> </ol> <p>Note that these links were accessed in the past and the links may longer work.</p>"},{"location":"sims/ds-prog-lang/#link-verification","title":"Link Verification","text":"<p>Prompt</p> <p>Verify that these links all work.</p> <ol> <li>Top Programming Language Trends in Data Science: 2025 Insights - June 12, 2025 - upGrad - \u2705 WORKING - Analysis of Python, R, and SQL trends in data science, comparing use cases and future programming shifts</li> <li>The Popularity of Data Science Languages: Python and R (April 2023 Update) - April 11, 2023 - Medium - \u274c NOT ACCESSIBLE - Examination of Python and R rankings in TIOBE, PYPL, and Stack Overflow indices</li> <li>The Popularity of Data Science Languages: Python and R (October 2023 Update) - November 2, 2023 - Medium - \u2705 WORKING - Analysis of Python and R trends with Stack Overflow survey insights</li> <li>Popularity Ranking of Programming Languages - January 24, 2025 - Towards Data Science - \u2705 WORKING - Comprehensive analysis of programming language trends using Stack Overflow data</li> <li>The Popularity of Data Science Languages: Python and R (March 2024 Update) - November 29, 2024 - Medium - \u2705 WORKING - Latest trends showing Python's continued dominance and R's specialized role</li> <li>Top 12 Programming Languages for Data Scientists in 2025 - July 25, 2024 - DataCamp - \u274c NOT ACCESSIBLE - Comprehensive guide to programming languages for data science with pros and cons analysis</li> <li>Python vs. R vs. SQL: 2025 Data Science Programming Language Trends - April 26, 2025 - Analytics Insight - \u2705 WORKING - Comparison of the three dominant data science languages and their use cases</li> <li>The Most Popular Programming Languages in 2025 - February 18, 2025 - Career in STEM - Referenced but not directly verified</li> <li>Don't Miss Out: 12 Data Science Programming Languages 2025! - July 10, 2025 - upGrad - Referenced but not directly verified</li> <li>Stack Overflow Developer Survey 2025 - 2025 - Stack Overflow - \u2705 WORKING - Annual survey of 49,000+ developers from 177 countries on technology usage and trends</li> <li>2025 Stack Overflow Developer Survey Technology Section - 2025 - Stack Overflow - \u2705 WORKING - Detailed breakdown of programming language usage and popularity trends</li> <li>TIOBE Programming Index News May 2025 - May 13, 2025 - TechRepublic - Referenced in search results</li> <li>Python popularity climbs to highest ever -- Tiobe - May 9, 2025 - InfoWorld - Referenced in search results</li> <li>TIOBE Index for August 2025 - August 2025 - TechRepublic - Referenced in search results</li> <li>TIOBE Index - Ongoing - TIOBE Software - Monthly programming language popularity index based on search engine results from 25 major platforms</li> </ol> <p>Summary: Out of the primary sources, 5 out of 7 verified links are working (71% success rate). The non-accessible links appear to be Medium articles that may have access restrictions or have been moved. The core data sources from Stack Overflow, major tech publications, and educational platforms are functioning properly and provide reliable data for the visualization.</p>"},{"location":"sims/four-types-of-data/","title":"Four Types of Data Science Data","text":""},{"location":"sims/four-types-of-data/#sample-iframe","title":"Sample iframe","text":"<p>You can include the following in your HTML to use this MicroSim</p> <pre><code>&lt;iframe src=\"/data-science-course/docs/sims/four-types-of-data/main.html\" height=\"600\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim Edit this MicroSim</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/microsims/sims/spectrum-analyzer/main.html\" height=\"400\"  scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/four-types-of-data/#about-this-microsim","title":"About this MicroSim","text":"<p>This MicroSim teaches us how to specify the drawing of a static filled circle.</p>"},{"location":"sims/four-types-of-data/#sample-prompt","title":"Sample Prompt","text":"<p>Prompt</p> <p>Create a single file p5.js sketch.   Draw a green circle on a 600x400 canvas with a radius of 200.</p>"},{"location":"sims/four-types-of-data/#sample-response","title":"Sample Response","text":"<pre><code>// canvas regions setup\n// let canvasWidth = 750;\nlet drawHeight = 400;\nlet controlHeight = 50;\nlet canvasHeight = drawHeight + controlHeight;\nlet aspectRatio = 1.91; // Open Graph standard\nlet canvasWidth = canvasHeight * aspectRatio;\nlet radius = 200;\n\nfunction setup() {\n  const canvas = createCanvas(canvasWidth, canvasHeight);\n  var mainElement = document.querySelector('main');\n  canvas.parent(mainElement);\n}\n\nfunction draw() {\n  // background of drawing region\n  fill('aliceblue');\n  rect(0, 0, canvasWidth, drawHeight);\n\n  // background of controls\n  fill('whitegray');\n  rect(0, drawHeight, canvasWidth, controlHeight);\n  circle(canvasWidth/2, canvasHeight/2, radius);\n}\n</code></pre>"},{"location":"sims/four-types-of-data/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/four-types-of-data/#grade-level-subject-and-topic","title":"Grade Level, Subject and Topic","text":"<p>9th grade geometry. Circle and radius.</p>"},{"location":"sims/four-types-of-data/#activities","title":"Activities","text":""},{"location":"sims/four-types-of-data/#fill-color","title":"Fill Color","text":"<p>Change the color in the prompt.  You can specify any one of the 140 named colors.</p>"},{"location":"sims/four-types-of-data/#border-weight","title":"Border Weight","text":"<p>Change the prompt to include a black border of width 10.</p>"},{"location":"sims/four-types-of-data/#border-color","title":"Border Color","text":"<p>Change the prompt to make the border purple.</p>"},{"location":"sims/four-types-of-data/#change-the-radius","title":"Change the Radius","text":"<p>Change the prompt to make the circle smaller or larger by changing the radius from 10 to 200.</p>"},{"location":"sims/four-types-of-data/#change-the-location","title":"Change the Location","text":"<p>Change the prompt to move the circle to the left or right.</p>"},{"location":"sims/four-types-of-data/#references","title":"References","text":"<ul> <li>Processing Wiki on Positioning Your Canvas</li> </ul>"},{"location":"sims/learning-graph/","title":"View Learning Graph","text":"<p>Run Learning Graph MicroSim</p>"},{"location":"sims/least-squares/","title":"Least Squares MicroSim","text":"<p>Run the Least Squares MicroSim in Fullscreen Edit the Least Squares MicroSim in the p5.js editor</p>"},{"location":"sims/least-squares/#lesson-plan-for-high-school-algebra","title":"Lesson Plan for High School Algebra","text":"<p>Linear Functions: Understanding Slope and Intercept</p> <p>Duration: 50 minutes</p> <p>Grade Level: 9-10</p> <p>Subject: Algebra 1</p>"},{"location":"sims/least-squares/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this lesson, students will be able to:</p> <ul> <li>Define slope as a rate of change</li> <li>Explain the meaning of y-intercept in a linear function</li> <li>Identify how changes in slope and intercept affect the graph of a line</li> <li>Use an interactive visualization to explore linear functions</li> <li>Solve real-world problems involving slope and intercept</li> </ul>"},{"location":"sims/least-squares/#materials-needed","title":"Materials Needed","text":"<ul> <li>Interactive Slope-Intercept Visualization (p5.js application)</li> <li>Student devices (computers, tablets, or smartphones)</li> <li>Guided worksheet (printed or digital)</li> <li>Whiteboard/projector</li> </ul>"},{"location":"sims/least-squares/#prerequisite-knowledge","title":"Prerequisite Knowledge","text":"<ul> <li>Basic understanding of coordinate plane</li> <li>Ability to plot points on a graph</li> <li>Familiarity with the equation y = mx + b</li> </ul>"},{"location":"sims/least-squares/#lesson-outline","title":"Lesson Outline","text":""},{"location":"sims/least-squares/#1-introduction-5-minutes","title":"1. Introduction (5 minutes)","text":"<ul> <li>Begin with a real-world scenario: \"If you earn $15 per hour at your job, how would you calculate your total earnings?\"</li> <li>Discuss how the relationship between hours worked and money earned forms a linear relationship</li> <li>Introduce the lesson focus: understanding how slope and intercept affect linear functions</li> </ul>"},{"location":"sims/least-squares/#2-review-of-key-concepts-10-minutes","title":"2. Review of Key Concepts (10 minutes)","text":"<ul> <li>Review the slope-intercept form of a line: y = mx + b</li> <li>Define slope (m) as the rate of change (rise/run)</li> <li>Define y-intercept (b) as the point where the line crosses the y-axis (0,b)</li> <li>Demonstrate examples on the board with different values for m and b</li> </ul>"},{"location":"sims/least-squares/#3-interactive-exploration-15-minutes","title":"3. Interactive Exploration (15 minutes)","text":"<ul> <li>Introduce the Slope-Intercept Visualization tool</li> <li>Demonstrate how to use the sliders to change slope and intercept values</li> <li>Explain the visual elements:<ul> <li>Green points represent actual data points</li> <li>Purple points show where the line would predict those values</li> <li>Colored squares show the \"error\" or difference between actual and predicted points</li> </ul> </li> <li>Guided exploration:<ol> <li>What happens when the slope increases? Decreases? Becomes negative?</li> <li>What happens when the y-intercept changes?</li> <li>Can you find values that minimize the differences between actual and predicted points?</li> </ol> </li> </ul>"},{"location":"sims/least-squares/#4-pair-work-10-minutes","title":"4. Pair Work (10 minutes)","text":"<ul> <li>Students work in pairs using the visualization tool</li> <li>Challenge: Find the linear function that best fits the green data points</li> <li>Each pair should record their \"best fit\" values for slope and intercept</li> <li>Discuss strategy: How can you tell when you've found a good fit?</li> </ul>"},{"location":"sims/least-squares/#5-connection-to-real-world-applications-5-minutes","title":"5. Connection to Real-World Applications (5 minutes)","text":"<p>Discuss how the slope-intercept model applies to:</p> <ul> <li>Economics: price vs. quantity relationships</li> <li>Physics: distance vs. time in constant velocity</li> <li>Business: fixed costs (y-intercept) and variable costs (slope)</li> </ul> <p>Show how the colored squares relate to \"error\" in predictions</p>"},{"location":"sims/least-squares/#6-closure-and-assessment-5-minutes","title":"6. Closure and Assessment (5 minutes)","text":"<ul> <li>Quick check for understanding:<ul> <li>\"If a line has a slope of 2 and a y-intercept of -3, what is its equation?\"</li> <li>\"If a line has a negative slope, what does that tell us about the relationship?\"</li> </ul> </li> <li>Exit ticket: Students write one insight they gained from using the visualization</li> </ul>"},{"location":"sims/least-squares/#extension-activities","title":"Extension Activities","text":"<ul> <li>Challenge students to create their own set of points and find the best-fitting line</li> <li>Introduce the concept of \"least squares regression\" as a mathematical way to find the best fit</li> <li>Connect to data science concepts: predictions, error measurements, and model accuracy</li> </ul>"},{"location":"sims/least-squares/#differentiation","title":"Differentiation","text":"<ul> <li>Support: Provide a step-by-step guide for using the visualization tool</li> <li>Extension: Ask advanced students to modify the code to add new features or data points</li> </ul>"},{"location":"sims/least-squares/#assessment","title":"Assessment","text":"<ul> <li>Formative: Observation during interactive exploration and pair work</li> <li>Summative: Exit ticket responses and follow-up homework assignment</li> </ul>"},{"location":"sims/least-squares/#homework","title":"Homework","text":"<ul> <li>Complete practice problems involving writing equations in slope-intercept form</li> <li>Find a real-world example where a linear relationship exists and identify what the slope and intercept represent in that context</li> </ul>"},{"location":"sims/least-squares/#follow-up-lesson-ideas","title":"Follow-Up Lesson Ideas","text":"<ul> <li>Comparing linear vs. non-linear relationships</li> <li>Introduction to systems of linear equations</li> <li>Linear regression with larger datasets</li> </ul>"},{"location":"sims/least-squares/#lesson-plan-focusing-on-prediction-of-future-events","title":"Lesson Plan focusing on Prediction of Future Events","text":""},{"location":"sims/least-squares/#learning-objectives_1","title":"Learning Objectives","text":"<p>By the end of this lesson, students will be able to: - Define slope as a rate of change - Explain the meaning of y-intercept in a linear function - Identify how changes in slope and intercept affect the graph of a line - Use an interactive visualization to explore linear functions - Use a linear model to make predictions for new x-values - Evaluate the reliability of predictions using a linear model - Solve real-world problems involving slope and intercept</p>"},{"location":"sims/least-squares/#materials-needed_1","title":"Materials Needed","text":"<ul> <li>Interactive Slope-Intercept Visualization (p5.js application)</li> <li>Student devices (computers, tablets, or smartphones)</li> <li>Guided worksheet (printed or digital)</li> <li>Whiteboard/projector</li> </ul>"},{"location":"sims/least-squares/#prerequisite-knowledge_1","title":"Prerequisite Knowledge","text":"<ul> <li>Basic understanding of coordinate plane</li> <li>Ability to plot points on a graph</li> <li>Familiarity with the equation y = mx + b</li> </ul>"},{"location":"sims/least-squares/#lesson-outline_1","title":"Lesson Outline","text":""},{"location":"sims/least-squares/#1-introduction-5-minutes_1","title":"1. Introduction (5 minutes)","text":"<ul> <li>Begin with a real-world scenario: \"If you earn $15 per hour at your job, how would you calculate your total earnings?\"</li> <li>Discuss how the relationship between hours worked and money earned forms a linear relationship</li> <li>Introduce the lesson focus: understanding how slope and intercept affect linear functions</li> </ul>"},{"location":"sims/least-squares/#2-review-of-key-concepts-10-minutes_1","title":"2. Review of Key Concepts (10 minutes)","text":"<ul> <li>Review the slope-intercept form of a line: y = mx + b</li> <li>Define slope (m) as the rate of change (rise/run)</li> <li>Define y-intercept (b) as the point where the line crosses the y-axis (0,b)</li> <li>Demonstrate examples on the board with different values for m and b</li> </ul>"},{"location":"sims/least-squares/#3-interactive-exploration-15-minutes_1","title":"3. Interactive Exploration (15 minutes)","text":"<ul> <li>Introduce the Slope-Intercept Visualization tool</li> <li>Demonstrate how to use the sliders to change slope and intercept values</li> <li>Explain the visual elements:</li> <li>Green points represent actual data points</li> <li>Purple points show where the line would predict those values</li> <li>Colored squares show the \"error\" or difference between actual and predicted points</li> <li>Guided exploration:</li> <li>What happens when the slope increases? Decreases? Becomes negative?</li> <li>What happens when the y-intercept changes?</li> <li>Can you find values that minimize the differences between actual and predicted points?</li> </ul>"},{"location":"sims/least-squares/#4-pair-work-10-minutes_1","title":"4. Pair Work (10 minutes)","text":"<ul> <li>Students work in pairs using the visualization tool</li> <li>Challenge: Find the linear function that best fits the green data points</li> <li>Each pair should record their \"best fit\" values for slope and intercept</li> <li>Discuss strategy: How can you tell when you've found a good fit?</li> </ul>"},{"location":"sims/least-squares/#5-prediction-and-real-world-applications-10-minutes","title":"5. Prediction and Real-World Applications (10 minutes)","text":"<ul> <li>Discuss how the slope-intercept model applies to:</li> <li>Economics: price vs. quantity relationships</li> <li>Physics: distance vs. time in constant velocity</li> <li>Business: fixed costs (y-intercept) and variable costs (slope)</li> <li>Show how the colored squares relate to \"error\" in predictions</li> <li>Prediction activity:</li> <li>Given our current \"best fit\" line with slope m and intercept b, what would be the predicted y-value for:<ol> <li>x = 250 (a value within our current data range)</li> <li>x = 600 (a value outside our current data range)</li> </ol> </li> <li>Discuss the concept of interpolation vs. extrapolation</li> <li>Question: \"How confident are we in these predictions and why?\"</li> <li>Question: \"What factors might affect the accuracy of our predictions?\"</li> </ul>"},{"location":"sims/least-squares/#6-closure-and-assessment-5-minutes_1","title":"6. Closure and Assessment (5 minutes)","text":"<ul> <li>Quick check for understanding: </li> <li>\"If a line has a slope of 2 and a y-intercept of -3, what is its equation?\"</li> <li>\"If a line has a negative slope, what does that tell us about the relationship?\"</li> <li>\"Using the equation y = 0.5x + 25, predict the y-value when x = 120\"</li> <li>\"How would you use our linear model to predict a new value not shown on the graph?\"</li> <li>Exit ticket: Students write one insight they gained about using linear models for prediction</li> </ul>"},{"location":"sims/least-squares/#extension-activities_1","title":"Extension Activities","text":"<ul> <li>Challenge students to create their own set of points and find the best-fitting line</li> <li>Introduce the concept of \"least squares regression\" as a mathematical way to find the best fit</li> <li>Connect to data science concepts: predictions, error measurements, and model accuracy</li> </ul>"},{"location":"sims/least-squares/#differentiation_1","title":"Differentiation","text":"<ul> <li>Support: Provide a step-by-step guide for using the visualization tool</li> <li>Extension: Ask advanced students to modify the code to add new features or data points</li> </ul>"},{"location":"sims/least-squares/#assessment_1","title":"Assessment","text":"<ul> <li>Formative: Observation during interactive exploration and pair work</li> <li>Summative: Exit ticket responses and follow-up homework assignment</li> </ul>"},{"location":"sims/least-squares/#homework_1","title":"Homework","text":"<ul> <li>Complete practice problems involving writing equations in slope-intercept form</li> <li>Find a real-world example where a linear relationship exists and identify what the slope and intercept represent in that context</li> <li>Prediction challenge: Given the linear model y = 1.5x + 10:</li> <li>Predict values for x = 50, x = 100, and x = 150</li> <li>If you measured y = 85, what would be the corresponding x value?</li> <li>Create a real-world scenario where this model might be useful, and explain what the slope and intercept represent</li> <li>Explain a situation where this model might break down or become unreliable for predictions</li> </ul>"},{"location":"sims/least-squares/#follow-up-lesson-ideas_1","title":"Follow-Up Lesson Ideas","text":"<ul> <li>Comparing linear vs. non-linear relationships</li> <li>Introduction to systems of linear equations</li> <li>Linear regression with larger datasets</li> </ul>"},{"location":"sims/microsim-lists/","title":"List of Data Science MicroSims Lists","text":"<p>What would be the most useful MicroSims in a Data Science course?</p> <p>We can ask our generative AI tools what concepts are the most difficult to understand in Data Science that could be explained by a MicroSim.</p> <p>Here are the top 10 microsims for reviewing basic statistics: - 10 Stats Review MicroSims</p> <p>Here are the top 100 data science microsims: - 100 Data Science MicroSims</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/","title":"10 Basic Statistics Review MicroSims","text":"<p>Here\u2019s a scaffolded set of Ten Basic Statistics MicroSims designed for students entering your data science course without a strong statistics background. I\u2019ve ordered them from simplest to more complex, drawing from the MicroSim styles already in your library.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#1-exploring-data-points","title":"1. Exploring Data Points","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description","title":"Description","text":"<p>Students click to add or remove points on a 2D scatter plot, instantly seeing the effect on the dataset.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals","title":"Learning Goals","text":"<ul> <li>Recognize individual data points as observations.</li> <li>Understand how points are represented in x\u2013y coordinates.</li> <li>See how changes in points affect the shape of a dataset.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls","title":"Input Controls","text":"<ol> <li>Add Point (click on canvas)</li> <li>Remove Point (click existing point)</li> <li>Clear All Points (button)</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#2-histogram-builder","title":"2. Histogram Builder","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_1","title":"Description","text":"<p>Students adjust bin sizes to see how histograms change, revealing over-smoothing or excessive detail.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_1","title":"Learning Goals","text":"<ul> <li>Understand bins and frequency counts.</li> <li>Relate bin size to detail retention in data.</li> <li>Connect histograms to raw data.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_1","title":"Input Controls","text":"<ol> <li>Bin Size Slider</li> <li>Dataset Selector (normal, uniform, skewed)</li> <li>Toggle Grid Lines (checkbox)</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#3-mean-and-median-explorer","title":"3. Mean and Median Explorer","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_2","title":"Description","text":"<p>Drag points along a number line to see how the mean and median respond differently to changes.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_2","title":"Learning Goals","text":"<ul> <li>Differentiate mean vs. median.</li> <li>Understand how outliers affect each measure.</li> <li>See why median is more robust.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_2","title":"Input Controls","text":"<ol> <li>Drag Points (mouse)</li> <li>Add Outlier (button)</li> <li>Reset Points (button)</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#4-distribution-shape-explorer","title":"4. Distribution Shape Explorer","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_3","title":"Description","text":"<p>Morph between uniform, normal, skewed, and bimodal distributions and see parameter changes in real time.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_3","title":"Learning Goals","text":"<ul> <li>Identify common distribution shapes.</li> <li>Understand skewness and kurtosis.</li> <li>Connect distribution properties to data characteristics.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_3","title":"Input Controls","text":"<ol> <li>Distribution Type Selector</li> <li>Skewness Slider</li> <li>Kurtosis Slider</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#5-correlation-playground","title":"5. Correlation Playground","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_4","title":"Description","text":"<p>Students drag clusters of points to change correlation and watch the correlation coefficient update.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_4","title":"Learning Goals","text":"<ul> <li>Visualize correlation strength and direction.</li> <li>Understand positive, negative, and zero correlation.</li> <li>See the impact of noise on correlation.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_4","title":"Input Controls","text":"<ol> <li>Drag Cluster (mouse)</li> <li>Add Noise (slider)</li> <li>Show Best Fit Line (toggle)</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#6-least-squares-line-fitter","title":"6. Least Squares Line Fitter","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_5","title":"Description","text":"<p>Adjust slope and intercept to minimize squared residuals with visual feedback.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_5","title":"Learning Goals","text":"<ul> <li>Understand slope, intercept, and residuals.</li> <li>Experience manual fitting before automation.</li> <li>Build intuition for regression.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_5","title":"Input Controls","text":"<ol> <li>Slope Slider</li> <li>Intercept Slider</li> <li>Toggle Residual Squares (checkbox)</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#7-r2-intuition-builder","title":"7. R\u00b2 Intuition Builder","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_6","title":"Description","text":"<p>Manipulate data spread around a regression line and see how R\u00b2 changes.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_6","title":"Learning Goals","text":"<ul> <li>Understand what R\u00b2 measures.</li> <li>Relate R\u00b2 to model fit.</li> <li>Recognize limits of R\u00b2 as a single metric.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_6","title":"Input Controls","text":"<ol> <li>Noise Level Slider</li> <li>Number of Points Slider</li> <li>Reset Dataset (button)</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#8-sampling-bias-demonstrator","title":"8. Sampling Bias Demonstrator","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_7","title":"Description","text":"<p>Draw samples from representative or biased datasets to see effects on mean/median estimates.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_7","title":"Learning Goals","text":"<ul> <li>Recognize sampling bias.</li> <li>Connect bias to flawed conclusions.</li> <li>Practice identifying representative samples.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_7","title":"Input Controls","text":"<ol> <li>Sampling Method Selector (random, biased)</li> <li>Sample Size Slider</li> <li>Reset Data (button)</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#9-hypothesis-testing-visualizer","title":"9. Hypothesis Testing Visualizer","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_8","title":"Description","text":"<p>Adjust sample statistics to see how p-values change under different population means.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_8","title":"Learning Goals","text":"<ul> <li>Understand null and alternative hypotheses.</li> <li>Interpret p-values visually.</li> <li>See the effect of sample size on significance.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_8","title":"Input Controls","text":"<ol> <li>Population Mean Slider</li> <li>Sample Mean Slider</li> <li>Sample Size Slider</li> </ol>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#10-confidence-interval-explorer","title":"10. Confidence Interval Explorer","text":""},{"location":"sims/microsim-lists/10-stats-review-microsims/#description_9","title":"Description","text":"<p>Show multiple sample means with confidence intervals to explore coverage probability.</p>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#learning-goals_9","title":"Learning Goals","text":"<ul> <li>Understand confidence intervals conceptually.</li> <li>Connect sample size to interval width.</li> <li>Interpret intervals in the context of repeated sampling.</li> </ul>"},{"location":"sims/microsim-lists/10-stats-review-microsims/#input-controls_9","title":"Input Controls","text":"<ol> <li>Confidence Level Slider</li> <li>Sample Size Slider</li> <li>Number of Samples Slider</li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/","title":"List of 100 Top MicroSims","text":"<p>This is a list of the 100 most important MicroSims for a Data Science course according to GPT-5. Each MicroSim is described in a level-2 header with the description, learning goals and input controls in level 3 headers.  We will have agents generate these MicroSims one at a time.</p> <p>Note that if students don't have a strong statistics background, they should review them.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#1-exploring-data-points","title":"1. Exploring Data Points","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description","title":"Description","text":"<p>Students click to add or remove points on a 2D scatter plot, instantly seeing the effect on the overall distribution.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals","title":"Learning Goals","text":"<ul> <li> <p>Recognize individual observations in a dataset</p> </li> <li> <p>Understand x--y coordinate representation</p> </li> <li> <p>See how adding/removing points changes data shape</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls","title":"Input Controls","text":"<ol> <li> <p>Add Point (click on canvas)</p> </li> <li> <p>Remove Point (click existing point)</p> </li> <li> <p>Clear All Points (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#2-histogram-builder","title":"2. Histogram Builder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_1","title":"Description","text":"<p>Students adjust bin sizes to see how histograms change, revealing over-smoothing and under-smoothing effects.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_1","title":"Learning Goals","text":"<ul> <li> <p>Understand bins and frequencies</p> </li> <li> <p>Relate bin size to data detail retention</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_1","title":"Input Controls","text":"<ol> <li> <p>Bin Size Slider</p> </li> <li> <p>Dataset Selector (dropdown: normal, uniform, skewed)</p> </li> <li> <p>Toggle Grid Lines (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#3-mean-and-median-explorer","title":"3. Mean and Median Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_2","title":"Description","text":"<p>Drag points along a number line to see how mean and median shift differently.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_2","title":"Learning Goals","text":"<ul> <li> <p>Differentiate mean vs. median</p> </li> <li> <p>Observe robustness of median to outliers</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_2","title":"Input Controls","text":"<ol> <li> <p>Drag Points (mouse)</p> </li> <li> <p>Add Outlier (button)</p> </li> <li> <p>Reset Points (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#4-correlation-playground","title":"4. Correlation Playground","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_3","title":"Description","text":"<p>Students drag clusters of points to adjust correlation, watching the correlation coefficient update in real-time.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_3","title":"Learning Goals","text":"<ul> <li> <p>Visualize correlation strength and direction</p> </li> <li> <p>Understand positive, negative, and zero correlation</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_3","title":"Input Controls","text":"<ol> <li> <p>Drag Cluster (mouse)</p> </li> <li> <p>Add Noise (slider)</p> </li> <li> <p>Show Best Fit Line (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#5-least-squares-line-fitter","title":"5. Least Squares Line Fitter","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_4","title":"Description","text":"<p>Adjust slope and intercept manually to minimize sum of squared errors, with real-time residual visualization.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_4","title":"Learning Goals","text":"<ul> <li> <p>Understand slope, intercept, and residuals</p> </li> <li> <p>Experience trial-and-error fitting</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_4","title":"Input Controls","text":"<ol> <li> <p>Slope Slider</p> </li> <li> <p>Intercept Slider</p> </li> <li> <p>Toggle Residual Squares (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#6-r2-intuition-builder","title":"6. R\u00b2 Intuition Builder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_5","title":"Description","text":"<p>Manipulate data spread around a fitted line to see how R\u00b2 changes.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_5","title":"Learning Goals","text":"<ul> <li> <p>Understand coefficient of determination</p> </li> <li> <p>Relate R\u00b2 to model fit quality</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_5","title":"Input Controls","text":"<ol> <li> <p>Noise Level Slider</p> </li> <li> <p>Number of Points Slider</p> </li> <li> <p>Reset Dataset (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#7-train-test-split-visualizer","title":"7. Train-Test Split Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_6","title":"Description","text":"<p>Randomly split a dataset and see how train/test points differ in model performance.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_6","title":"Learning Goals","text":"<ul> <li> <p>Understand importance of splitting data</p> </li> <li> <p>See overfitting risk when test set is too small</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_6","title":"Input Controls","text":"<ol> <li> <p>Train/Test Ratio Slider</p> </li> <li> <p>Resample Dataset (button)</p> </li> <li> <p>Model Complexity Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#8-cross-validation-simulator","title":"8. Cross-Validation Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_7","title":"Description","text":"<p>Animate k-fold cross-validation, showing shifting train/test subsets and aggregated scores.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_7","title":"Learning Goals","text":"<ul> <li> <p>Understand cross-validation mechanics</p> </li> <li> <p>See benefits over single train-test split</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_7","title":"Input Controls","text":"<ol> <li> <p>Number of Folds Slider</p> </li> <li> <p>Dataset Size Slider</p> </li> <li> <p>Play/Pause Animation (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#9-overfitting-vs-underfitting-explorer","title":"9. Overfitting vs. Underfitting Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_8","title":"Description","text":"<p>Adjust polynomial degree to see bias--variance trade-off on train vs. test errors.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_8","title":"Learning Goals","text":"<ul> <li> <p>Recognize overfitting and underfitting patterns</p> </li> <li> <p>Connect complexity to generalization</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_8","title":"Input Controls","text":"<ol> <li> <p>Polynomial Degree Slider</p> </li> <li> <p>Noise Level Slider</p> </li> <li> <p>Toggle Error Curves (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#10-2multiple-regression-plane","title":"10. $2Multiple Regression Plane","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_9","title":"Description","text":"<p>Manipulate two independent variables in 3D space to see a regression plane fit to data.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_9","title":"Learning Goals","text":"<ul> <li> <p>Visualize multivariate linear regression</p> </li> <li> <p>See plane adjustment with variable changes</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_9","title":"Input Controls","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#1-rotate-view-mouse-drag","title":"1.  Rotate View (mouse drag)","text":"<ol> <li> <p>Noise Level Slider</p> </li> <li> <p>Add/Remove Points (click)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#11-residuals-heatmap-viewer","title":"11. Residuals Heatmap Viewer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_10","title":"Description","text":"<p>Color-code residuals on a scatter plot to identify patterns and non-linearity.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_10","title":"Learning Goals","text":"<ul> <li> <p>Understand residual analysis</p> </li> <li> <p>Detect systematic errors in model predictions</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_10","title":"Input Controls","text":"<ol> <li> <p>Model Complexity Slider</p> </li> <li> <p>Toggle Residual Colors</p> </li> <li> <p>Noise Level Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#12-distribution-shape-explorer","title":"12. Distribution Shape Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_11","title":"Description","text":"<p>Morph between uniform, normal, skewed, and bimodal distributions.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_11","title":"Learning Goals","text":"<ul> <li> <p>Identify common data distributions</p> </li> <li> <p>Understand skewness and kurtosis visually</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_11","title":"Input Controls","text":"<ol> <li> <p>Distribution Type Selector</p> </li> <li> <p>Skewness Slider</p> </li> <li> <p>Kurtosis Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#13-box-plot-anatomy","title":"13. Box Plot Anatomy","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_12","title":"Description","text":"<p>Interactively adjust dataset values to see quartiles, whiskers, and outliers update in real time.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_12","title":"Learning Goals","text":"<ul> <li> <p>Interpret box plot components</p> </li> <li> <p>Relate box plot features to dataset properties</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_12","title":"Input Controls","text":"<ol> <li> <p>Drag Data Points</p> </li> <li> <p>Add Outlier (button)</p> </li> <li> <p>Reset Data (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#14-central-limit-theorem-animator","title":"14. Central Limit Theorem Animator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_13","title":"Description","text":"<p>Sample repeatedly from various population distributions and watch sampling distribution approach normality.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_13","title":"Learning Goals","text":"<ul> <li> <p>Visualize the CLT in action</p> </li> <li> <p>Understand why normality emerges</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_13","title":"Input Controls","text":"<ol> <li> <p>Population Distribution Selector</p> </li> <li> <p>Sample Size Slider</p> </li> <li> <p>Number of Samples Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#15-sampling-bias-demonstrator","title":"15. Sampling Bias Demonstrator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_14","title":"Description","text":"<p>Draw samples from skewed or representative datasets to see effect on mean/median estimates.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_14","title":"Learning Goals","text":"<ul> <li> <p>Recognize sampling bias</p> </li> <li> <p>Relate bias to poor generalization</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_14","title":"Input Controls","text":"<ol> <li> <p>Sampling Method Selector (random, biased)</p> </li> <li> <p>Sample Size Slider</p> </li> <li> <p>Reset Data (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#16-hypothesis-testing-visualizer","title":"16. Hypothesis Testing Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_15","title":"Description","text":"<p>Adjust population mean and see how p-values change for given sample statistics.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_15","title":"Learning Goals","text":"<ul> <li> <p>Understand null/alternative hypotheses</p> </li> <li> <p>Interpret p-values visually</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_15","title":"Input Controls","text":"<ol> <li> <p>Population Mean Slider</p> </li> <li> <p>Sample Mean Slider</p> </li> <li> <p>Sample Size Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#17-confidence-interval-explorer","title":"17. Confidence Interval Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_16","title":"Description","text":"<p>Show multiple sample means with confidence intervals and see coverage percentage.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_16","title":"Learning Goals","text":"<ul> <li> <p>Understand confidence interval interpretation</p> </li> <li> <p>See how sample size affects interval width</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_16","title":"Input Controls","text":"<ol> <li> <p>Confidence Level Slider</p> </li> <li> <p>Sample Size Slider</p> </li> <li> <p>Number of Samples Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#18-t-test-simulator","title":"18. t-Test Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_17","title":"Description","text":"<p>Compare means of two groups with adjustable overlap and see t-statistic and p-value.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_17","title":"Learning Goals","text":"<ul> <li> <p>Perform and interpret t-tests</p> </li> <li> <p>Relate group separation to statistical significance</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_17","title":"Input Controls","text":"<ol> <li> <p>Mean Difference Slider</p> </li> <li> <p>Sample Size Slider</p> </li> <li> <p>Variance Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#19-correlation-vs-causation-scenario-builder","title":"19. Correlation vs. Causation Scenario Builder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_18","title":"Description","text":"<p>Toggle between linked and independent variables with visual storytelling elements.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_18","title":"Learning Goals","text":"<ul> <li> <p>Distinguish correlation from causation</p> </li> <li> <p>Recognize spurious correlations</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_18","title":"Input Controls","text":"<ol> <li> <p>Relationship Type Selector</p> </li> <li> <p>Add Confounder Variable (button)</p> </li> <li> <p>Noise Level Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#20-data-cleaning-sandbox","title":"20. Data Cleaning Sandbox","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_19","title":"Description","text":"<p>Interactively identify and fix missing values, duplicates, and inconsistencies in a small dataset.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_19","title":"Learning Goals","text":"<ul> <li> <p>Practice data cleaning operations</p> </li> <li> <p>Recognize data quality issues</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_19","title":"Input Controls","text":"<ol> <li> <p>Highlight Missing Values (checkbox)</p> </li> <li> <p>Fill Missing Values Method Selector</p> </li> <li> <p>Remove Duplicates (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#21-missing-data-imputation-lab","title":"21. Missing Data Imputation Lab","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_20","title":"Description","text":"<p>Students choose different strategies to fill in missing values and compare how summaries change.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_20","title":"Learning Goals","text":"<ul> <li> <p>Explore mean, median, mode, and model-based imputation</p> </li> <li> <p>See effects of imputation on dataset statistics</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_20","title":"Input Controls","text":"<ol> <li> <p>Imputation Method Selector</p> </li> <li> <p>Preview Changes (toggle)</p> </li> <li> <p>Apply Changes (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#22-one-hot-encoding-demonstrator","title":"22. One-Hot Encoding Demonstrator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_21","title":"Description","text":"<p>Convert categorical variables into binary columns and see the dataset shape change.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_21","title":"Learning Goals","text":"<ul> <li> <p>Understand one-hot encoding</p> </li> <li> <p>Recognize dataset expansion with categorical variables</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_21","title":"Input Controls","text":"<ol> <li> <p>Category Count Slider</p> </li> <li> <p>Toggle Encoding (checkbox)</p> </li> <li> <p>Reset Categories (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#23-feature-scaling-visualizer","title":"23. Feature Scaling Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_22","title":"Description","text":"<p>Scale features using min-max, standardization, or robust scaling, and compare results.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_22","title":"Learning Goals","text":"<ul> <li> <p>Understand scaling methods</p> </li> <li> <p>Recognize scaling's impact on model training</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_22","title":"Input Controls","text":"<ol> <li> <p>Scaling Method Selector</p> </li> <li> <p>Dataset Selector</p> </li> <li> <p>Apply Scaling (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#24-scatter-plot-matrix-explorer","title":"24. Scatter Plot Matrix Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_23","title":"Description","text":"<p>Select variables to display in an interactive scatter plot matrix.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_23","title":"Learning Goals","text":"<ul> <li> <p>Visualize pairwise relationships</p> </li> <li> <p>Identify potential multicollinearity</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_23","title":"Input Controls","text":"<ol> <li> <p>Variable Selector (multi-select)</p> </li> <li> <p>Highlight Correlated Pairs (toggle)</p> </li> <li> <p>Reset Matrix (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#25-multicollinearity-detector","title":"25. Multicollinearity Detector","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_24","title":"Description","text":"<p>Add or remove features and see the correlation heatmap update in real time.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_24","title":"Learning Goals","text":"<ul> <li> <p>Recognize multicollinearity</p> </li> <li> <p>Learn its impact on regression models</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_24","title":"Input Controls","text":"<ol> <li> <p>Add Feature (dropdown)</p> </li> <li> <p>Remove Feature (click)</p> </li> <li> <p>Threshold Slider for correlation warning</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#26-gradient-descent-animation","title":"26. Gradient Descent Animation","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_25","title":"Description","text":"<p>Visualize gradient descent steps on a 3D loss surface.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_25","title":"Learning Goals","text":"<ul> <li> <p>Understand optimization paths</p> </li> <li> <p>See effects of learning rate changes</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_25","title":"Input Controls","text":"<ol> <li> <p>Learning Rate Slider</p> </li> <li> <p>Start Position Selector</p> </li> <li> <p>Play/Pause Steps (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#27-loss-function-comparator","title":"27. Loss Function Comparator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_26","title":"Description","text":"<p>Compare MSE, MAE, and Huber loss on the same dataset.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_26","title":"Learning Goals","text":"<ul> <li> <p>Understand different loss functions</p> </li> <li> <p>Recognize how they respond to outliers</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_26","title":"Input Controls","text":"<ol> <li> <p>Loss Function Selector</p> </li> <li> <p>Add Outlier (button)</p> </li> <li> <p>Reset Data (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#28-logistic-regression-probability-curve","title":"28. Logistic Regression Probability Curve","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_27","title":"Description","text":"<p>Adjust slope and intercept to see how the logistic curve shifts and steepens.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_27","title":"Learning Goals","text":"<ul> <li> <p>Understand logistic regression shape</p> </li> <li> <p>Relate slope to classification threshold sharpness</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_27","title":"Input Controls","text":"<ol> <li> <p>Slope Slider</p> </li> <li> <p>Intercept Slider</p> </li> <li> <p>Show Decision Boundary (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#29-confusion-matrix-builder","title":"29. Confusion Matrix Builder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_28","title":"Description","text":"<p>Manually adjust predictions to see confusion matrix cells update and metrics recalculate.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_28","title":"Learning Goals","text":"<ul> <li> <p>Interpret precision, recall, F1-score</p> </li> <li> <p>See trade-offs in prediction thresholds</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_28","title":"Input Controls","text":"<ol> <li> <p>Threshold Slider</p> </li> <li> <p>Toggle Misclassification Highlight (checkbox)</p> </li> <li> <p>Reset Predictions (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#30-roc-curve-interactive-plotter","title":"30. ROC Curve Interactive Plotter","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_29","title":"Description","text":"<p>Drag threshold point along the curve to see corresponding confusion matrix metrics.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_29","title":"Learning Goals","text":"<ul> <li> <p>Understand ROC curves</p> </li> <li> <p>Relate AUC to model performance</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_29","title":"Input Controls","text":"<ol> <li> <p>Move Threshold Point (mouse drag)</p> </li> <li> <p>Toggle AUC Display (checkbox)</p> </li> <li> <p>Dataset Selector</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#31-precision-recall-trade-off-tool","title":"31. Precision-Recall Trade-off Tool","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_30","title":"Description","text":"<p>Visualize precision and recall lines as threshold changes, highlighting the F1-score peak.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_30","title":"Learning Goals","text":"<ul> <li> <p>Recognize trade-offs between precision and recall</p> </li> <li> <p>Identify optimal balance point</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_30","title":"Input Controls","text":"<ol> <li> <p>Threshold Slider</p> </li> <li> <p>Show F1 Peak (toggle)</p> </li> <li> <p>Reset Chart (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#32-decision-tree-split-explorer","title":"32. Decision Tree Split Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_31","title":"Description","text":"<p>Select split features and thresholds to see how data partitions change.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_31","title":"Learning Goals","text":"<ul> <li> <p>Understand feature-based splitting</p> </li> <li> <p>Recognize overfitting in deep trees</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_31","title":"Input Controls","text":"<ol> <li> <p>Feature Selector</p> </li> <li> <p>Threshold Slider</p> </li> <li> <p>Add Split (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#33-random-forest-voting-visualizer","title":"33. Random Forest Voting Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_32","title":"Description","text":"<p>Show predictions from individual trees and how majority vote determines the final prediction.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_32","title":"Learning Goals","text":"<ul> <li> <p>Understand ensemble voting</p> </li> <li> <p>See stability from multiple models</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_32","title":"Input Controls","text":"<ol> <li> <p>Number of Trees Slider</p> </li> <li> <p>Tree Depth Slider</p> </li> <li> <p>Noise Level Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#34-bagging-vs-boosting-simulator","title":"34. Bagging vs. Boosting Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_33","title":"Description","text":"<p>Switch between bagging and boosting to compare error reduction over iterations.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_33","title":"Learning Goals","text":"<ul> <li> <p>Contrast two ensemble methods</p> </li> <li> <p>Understand impact on bias and variance</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_33","title":"Input Controls","text":"<ol> <li> <p>Method Selector</p> </li> <li> <p>Number of Estimators Slider</p> </li> <li> <p>Learning Rate Slider (for boosting)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#35-k-means-clustering-playground","title":"35. k-Means Clustering Playground","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_34","title":"Description","text":"<p>Move cluster centers and see point assignments change instantly.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_34","title":"Learning Goals","text":"<ul> <li> <p>Understand k-means mechanics</p> </li> <li> <p>Recognize sensitivity to initialization</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_34","title":"Input Controls","text":"<ol> <li> <p>Number of Clusters Slider</p> </li> <li> <p>Drag Cluster Centers</p> </li> <li> <p>Reset Clusters (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#36-elbow-method-visualizer","title":"36. Elbow Method Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_35","title":"Description","text":"<p>Generate k-means cost curve to find optimal k.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_35","title":"Learning Goals","text":"<ul> <li> <p>Apply elbow method for cluster selection</p> </li> <li> <p>Interpret inertia curve</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_35","title":"Input Controls","text":"<ol> <li> <p>Max k Slider</p> </li> <li> <p>Dataset Selector</p> </li> <li> <p>Recalculate Curve (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#37-hierarchical-clustering-dendrogram","title":"37. Hierarchical Clustering Dendrogram","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_36","title":"Description","text":"<p>Cut dendrogram at different heights to form clusters.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_36","title":"Learning Goals","text":"<ul> <li> <p>Interpret dendrograms</p> </li> <li> <p>Relate cut height to cluster count</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_36","title":"Input Controls","text":"<ol> <li> <p>Cut Height Slider</p> </li> <li> <p>Dataset Selector</p> </li> <li> <p>Toggle Leaf Labels (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#38-pca-variance-explorer","title":"38. PCA Variance Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_37","title":"Description","text":"<p>Adjust number of principal components and see variance explained update.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_37","title":"Learning Goals","text":"<ul> <li> <p>Understand dimensionality reduction</p> </li> <li> <p>Relate components to variance retention</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_37","title":"Input Controls","text":"<ol> <li> <p>Number of Components Slider</p> </li> <li> <p>Dataset Selector</p> </li> <li> <p>Show Projection (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#39-pca-projection-visualizer","title":"39. PCA Projection Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_38","title":"Description","text":"<p>Project high-dimensional data into 2D and explore structure.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_38","title":"Learning Goals","text":"<ul> <li> <p>Visualize principal component projections</p> </li> <li> <p>Detect patterns in reduced space</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_38","title":"Input Controls","text":"<ol> <li> <p>Rotate Projection (mouse drag)</p> </li> <li> <p>Highlight Class Labels (toggle)</p> </li> <li> <p>Reset View (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#40-feature-importance-bar-chart","title":"40. Feature Importance Bar Chart","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_39","title":"Description","text":"<p>Interactively remove features and see model accuracy update.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_39","title":"Learning Goals","text":"<ul> <li> <p>Rank feature contributions</p> </li> <li> <p>Recognize redundancy in predictors</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_39","title":"Input Controls","text":"<ol> <li> <p>Remove Feature (click bar)</p> </li> <li> <p>Recalculate Accuracy (button)</p> </li> <li> <p>Reset Features (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#41-time-series-trend-explorer","title":"41. Time Series Trend Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_40","title":"Description","text":"<p>Students add or remove long-term upward or downward trends to see their effect on time series plots.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_40","title":"Learning Goals","text":"<ul> <li> <p>Recognize trends in time series data</p> </li> <li> <p>Separate trend from noise visually</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_40","title":"Input Controls","text":"<ol> <li> <p>Trend Slope Slider</p> </li> <li> <p>Noise Level Slider</p> </li> <li> <p>Reset Series (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#42-seasonality-animator","title":"42. Seasonality Animator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_41","title":"Description","text":"<p>Add seasonal patterns to time series and adjust amplitude/frequency.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_41","title":"Learning Goals","text":"<ul> <li> <p>Understand seasonality components</p> </li> <li> <p>Differentiate seasonal effects from trends</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_41","title":"Input Controls","text":"<ol> <li> <p>Amplitude Slider</p> </li> <li> <p>Frequency Slider</p> </li> <li> <p>Toggle Seasonal Component (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#43-autocorrelation-plot-builder","title":"43. Autocorrelation Plot Builder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_42","title":"Description","text":"<p>Interactively generate autocorrelation plots for different time series patterns.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_42","title":"Learning Goals","text":"<ul> <li> <p>Recognize autocorrelation signatures</p> </li> <li> <p>Link patterns to time lags</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_42","title":"Input Controls","text":"<ol> <li> <p>Pattern Selector (trend, seasonal, white noise)</p> </li> <li> <p>Series Length Slider</p> </li> <li> <p>Recalculate Plot (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#44-moving-average-filter","title":"44. Moving Average Filter","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_43","title":"Description","text":"<p>Smooth noisy time series using different window sizes.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_43","title":"Learning Goals","text":"<ul> <li> <p>Apply moving average smoothing</p> </li> <li> <p>Understand trade-off between smoothing and responsiveness</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_43","title":"Input Controls","text":"<ol> <li> <p>Window Size Slider</p> </li> <li> <p>Toggle Original Series (checkbox)</p> </li> <li> <p>Reset Filter (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#45-exponential-smoothing-explorer","title":"45. Exponential Smoothing Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_44","title":"Description","text":"<p>Adjust smoothing factor to see effect on responsiveness to new data.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_44","title":"Learning Goals","text":"<ul> <li> <p>Understand exponential smoothing</p> </li> <li> <p>Compare to simple moving average</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_44","title":"Input Controls","text":"<ol> <li> <p>Smoothing Factor Slider (0--1)</p> </li> <li> <p>Toggle Forecast Values (checkbox)</p> </li> <li> <p>Reset Data (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#46-arima-model-simulator","title":"46. ARIMA Model Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_45","title":"Description","text":"<p>Experiment with AR, I, and MA parameters to fit simple time series.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_45","title":"Learning Goals","text":"<ul> <li> <p>Recognize ARIMA components</p> </li> <li> <p>See parameter effects on forecast shape</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_45","title":"Input Controls","text":"<ol> <li> <p>AR Order Slider</p> </li> <li> <p>I Order Slider</p> </li> <li> <p>MA Order Slider</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#47-train-test-split-for-time-series","title":"47. Train-Test Split for Time Series","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_46","title":"Description","text":"<p>Split data chronologically and compare forecasting performance.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_46","title":"Learning Goals","text":"<ul> <li> <p>Understand why random splits don't work in time series</p> </li> <li> <p>Practice chronological evaluation</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_46","title":"Input Controls","text":"<ol> <li> <p>Split Point Slider</p> </li> <li> <p>Model Selector</p> </li> <li> <p>Show Forecast Horizon (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#48-outlier-impact-on-time-series","title":"48. Outlier Impact on Time Series","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_47","title":"Description","text":"<p>Insert outliers into time series and see how forecasts change.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_47","title":"Learning Goals","text":"<ul> <li> <p>Recognize sensitivity to anomalies</p> </li> <li> <p>Understand need for preprocessing</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_47","title":"Input Controls","text":"<ol> <li> <p>Insert Outlier (click point)</p> </li> <li> <p>Outlier Magnitude Slider</p> </li> <li> <p>Remove Outliers (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#49-tf-idf-text-weighting-tool","title":"49. TF-IDF Text Weighting Tool","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_48","title":"Description","text":"<p>Type or paste text and see term frequencies and TF-IDF scores update live.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_48","title":"Learning Goals","text":"<ul> <li> <p>Understand term frequency weighting</p> </li> <li> <p>Recognize the role of inverse document frequency</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_48","title":"Input Controls","text":"<ol> <li> <p>Text Input Box</p> </li> <li> <p>Toggle Stopword Removal (checkbox)</p> </li> <li> <p>Recalculate Scores (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#50-tokenization-visualizer","title":"50. Tokenization Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_49","title":"Description","text":"<p>See text split into tokens using different tokenization rules.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_49","title":"Learning Goals","text":"<ul> <li> <p>Understand tokenization</p> </li> <li> <p>Compare word vs. subword methods</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_49","title":"Input Controls","text":"<ol> <li> <p>Text Input Box</p> </li> <li> <p>Tokenizer Type Selector</p> </li> <li> <p>Show Token IDs (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#51-word-embedding-explorer","title":"51. Word Embedding Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_50","title":"Description","text":"<p>Plot word embeddings in 2D space and explore semantic similarity.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_50","title":"Learning Goals","text":"<ul> <li> <p>Understand word vector representations</p> </li> <li> <p>See clusters of related words</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_50","title":"Input Controls","text":"<ol> <li> <p>Select Word to Highlight (dropdown)</p> </li> <li> <p>Show Similar Words (toggle)</p> </li> <li> <p>Reset Embeddings (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#52-sentiment-classification-threshold-tool","title":"52. Sentiment Classification Threshold Tool","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_51","title":"Description","text":"<p>Adjust sentiment score threshold to see how classifications change.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_51","title":"Learning Goals","text":"<ul> <li> <p>Understand sentiment score distributions</p> </li> <li> <p>See trade-offs in precision and recall for sentiment tasks</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_51","title":"Input Controls","text":"<ol> <li> <p>Threshold Slider</p> </li> <li> <p>Show Confusion Matrix (checkbox)</p> </li> <li> <p>Dataset Selector</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#53-bag-of-words-vs-embeddings","title":"53. Bag-of-Words vs. Embeddings","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_52","title":"Description","text":"<p>Switch between BoW and embedding-based representations to compare classification accuracy.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_52","title":"Learning Goals","text":"<ul> <li> <p>Contrast sparse vs. dense text features</p> </li> <li> <p>Recognize embedding advantages</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_52","title":"Input Controls","text":"<ol> <li> <p>Representation Selector</p> </li> <li> <p>Dataset Selector</p> </li> <li> <p>Recalculate Accuracy (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#54-neural-network-layer-visualizer","title":"54. Neural Network Layer Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_53","title":"Description","text":"<p>Show how inputs propagate through fully connected layers with activation functions.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_53","title":"Learning Goals","text":"<ul> <li> <p>Understand forward propagation</p> </li> <li> <p>Visualize activation transformations</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_53","title":"Input Controls","text":"<ol> <li> <p>Number of Layers Slider</p> </li> <li> <p>Activation Function Selector</p> </li> <li> <p>Reset Network (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#55-activation-function-explorer","title":"55. Activation Function Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_54","title":"Description","text":"<p>Compare sigmoid, ReLU, and tanh shapes and outputs for input ranges.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_54","title":"Learning Goals","text":"<ul> <li> <p>Recognize activation function behaviors</p> </li> <li> <p>See saturation and dead neuron effects</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_54","title":"Input Controls","text":"<ol> <li> <p>Function Selector</p> </li> <li> <p>Input Range Slider</p> </li> <li> <p>Toggle Derivative Curve (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#56-weight-initialization-impact","title":"56. Weight Initialization Impact","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_55","title":"Description","text":"<p>Initialize neural network weights differently and observe training convergence.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_55","title":"Learning Goals","text":"<ul> <li> <p>Understand initialization strategies</p> </li> <li> <p>See effect on loss curve and accuracy</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_55","title":"Input Controls","text":"<ol> <li> <p>Initialization Method Selector</p> </li> <li> <p>Learning Rate Slider</p> </li> <li> <p>Reset Training (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#57-learning-rate-finder","title":"57. Learning Rate Finder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_56","title":"Description","text":"<p>Gradually increase learning rate to see where loss diverges or minimizes fastest.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_56","title":"Learning Goals","text":"<ul> <li> <p>Tune learning rate</p> </li> <li> <p>Recognize underfitting and instability from wrong rates</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_56","title":"Input Controls","text":"<ol> <li> <p>Start Rate Slider</p> </li> <li> <p>End Rate Slider</p> </li> <li> <p>Run LR Finder (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#58-convolution-filter-visualizer","title":"58. Convolution Filter Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_57","title":"Description","text":"<p>Apply filters to images and see resulting feature maps.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_57","title":"Learning Goals","text":"<ul> <li> <p>Understand convolution in CNNs</p> </li> <li> <p>Recognize edge and texture detection</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_57","title":"Input Controls","text":"<ol> <li> <p>Filter Type Selector</p> </li> <li> <p>Kernel Size Slider</p> </li> <li> <p>Toggle Original Image (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#59-pooling-layer-explorer","title":"59. Pooling Layer Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_58","title":"Description","text":"<p>Compare max pooling and average pooling effects on feature maps.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_58","title":"Learning Goals","text":"<ul> <li> <p>Understand pooling</p> </li> <li> <p>See dimensionality reduction effects</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_58","title":"Input Controls","text":"<ol> <li> <p>Pooling Type Selector</p> </li> <li> <p>Pool Size Slider</p> </li> <li> <p>Toggle Feature Map Overlay (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#60-overfitting-in-deep-networks","title":"60. Overfitting in Deep Networks","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_59","title":"Description","text":"<p>Increase network capacity and watch training vs. validation loss diverge.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_59","title":"Learning Goals","text":"<ul> <li> <p>Recognize overfitting in neural nets</p> </li> <li> <p>See regularization benefits</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_59","title":"Input Controls","text":"<ol> <li> <p>Number of Neurons Slider</p> </li> <li> <p>Dropout Rate Slider</p> </li> <li> <p>Toggle Validation Curve (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#61-l1-vs-l2-regularization-visualizer","title":"61. L1 vs. L2 Regularization Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_60","title":"Description","text":"<p>Toggle between L1 and L2 regularization and see coefficient shrinkage effects.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_60","title":"Learning Goals","text":"<ul> <li> <p>Understand Lasso vs. Ridge regression</p> </li> <li> <p>See how regularization affects weights</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_60","title":"Input Controls","text":"<ol> <li> <p>Regularization Type Selector</p> </li> <li> <p>Penalty Strength Slider</p> </li> <li> <p>Reset Coefficients (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#62-dropout-effect-simulator","title":"62. Dropout Effect Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_61","title":"Description","text":"<p>Adjust dropout rates and watch neuron activations disappear during training.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_61","title":"Learning Goals","text":"<ul> <li> <p>Understand dropout regularization</p> </li> <li> <p>Recognize its role in preventing overfitting</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_61","title":"Input Controls","text":"<ol> <li> <p>Dropout Rate Slider</p> </li> <li> <p>Toggle Training/Inference View (checkbox)</p> </li> <li> <p>Reset Network (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#63-early-stopping-demonstrator","title":"63. Early Stopping Demonstrator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_62","title":"Description","text":"<p>Visualize training and validation loss to determine optimal stop point.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_62","title":"Learning Goals","text":"<ul> <li> <p>Understand early stopping criteria</p> </li> <li> <p>Avoid overtraining a model</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_62","title":"Input Controls","text":"<ol> <li> <p>Patience Slider</p> </li> <li> <p>Max Epochs Slider</p> </li> <li> <p>Toggle Loss Curves (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#64-shap-value-explorer","title":"64. SHAP Value Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_63","title":"Description","text":"<p>Show feature contributions to individual predictions using SHAP values.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_63","title":"Learning Goals","text":"<ul> <li> <p>Interpret model predictions</p> </li> <li> <p>Recognize key contributing features</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_63","title":"Input Controls","text":"<ol> <li> <p>Select Data Point (dropdown)</p> </li> <li> <p>Show Positive/Negative Contributions (toggle)</p> </li> <li> <p>Reset View (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#65-partial-dependence-plot-tool","title":"65. Partial Dependence Plot Tool","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_64","title":"Description","text":"<p>Adjust a single feature and see average prediction change while holding others constant.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_64","title":"Learning Goals","text":"<ul> <li> <p>Interpret partial dependence</p> </li> <li> <p>Detect feature impact trends</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_64","title":"Input Controls","text":"<ol> <li> <p>Feature Selector</p> </li> <li> <p>Value Slider</p> </li> <li> <p>Toggle Confidence Interval (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#66-counterfactual-example-generator","title":"66. Counterfactual Example Generator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_65","title":"Description","text":"<p>Change features to flip a prediction outcome.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_65","title":"Learning Goals","text":"<ul> <li> <p>Understand counterfactual reasoning</p> </li> <li> <p>Identify decision boundaries</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_65","title":"Input Controls","text":"<ol> <li> <p>Feature Sliders</p> </li> <li> <p>Toggle Prediction Probability (checkbox)</p> </li> <li> <p>Reset Features (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#67-bias-detection-dashboard","title":"67. Bias Detection Dashboard","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_66","title":"Description","text":"<p>Compare model accuracy across demographic subgroups.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_66","title":"Learning Goals","text":"<ul> <li> <p>Detect model bias</p> </li> <li> <p>Understand fairness metrics</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_66","title":"Input Controls","text":"<ol> <li> <p>Group Selector</p> </li> <li> <p>Metric Selector</p> </li> <li> <p>Show Disparity Alert (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#68-fairness-metric-comparator","title":"68. Fairness Metric Comparator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_67","title":"Description","text":"<p>Compare demographic parity, equalized odds, and other fairness metrics.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_67","title":"Learning Goals","text":"<ul> <li> <p>Interpret multiple fairness definitions</p> </li> <li> <p>Recognize trade-offs between them</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_67","title":"Input Controls","text":"<ol> <li> <p>Metric Selector</p> </li> <li> <p>Group Selector</p> </li> <li> <p>Highlight Best Metric (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#69-adversarial-example-creator","title":"69. Adversarial Example Creator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_68","title":"Description","text":"<p>Add small perturbations to input data and see if predictions change.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_68","title":"Learning Goals","text":"<ul> <li> <p>Understand adversarial vulnerability</p> </li> <li> <p>Recognize security risks in ML</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_68","title":"Input Controls","text":"<ol> <li> <p>Perturbation Magnitude Slider</p> </li> <li> <p>Noise Pattern Selector</p> </li> <li> <p>Reset Data (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#70-model-drift-monitor","title":"70. Model Drift Monitor","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_69","title":"Description","text":"<p>Compare live data predictions to historical model performance.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_69","title":"Learning Goals","text":"<ul> <li> <p>Detect concept and data drift</p> </li> <li> <p>Understand retraining triggers</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_69","title":"Input Controls","text":"<ol> <li> <p>Time Window Selector</p> </li> <li> <p>Drift Metric Selector</p> </li> <li> <p>Refresh Data (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#71-hyperparameter-search-playground","title":"71. Hyperparameter Search Playground","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_70","title":"Description","text":"<p>Run grid/random searches and compare performance heatmaps.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_70","title":"Learning Goals","text":"<ul> <li> <p>Understand hyperparameter optimization</p> </li> <li> <p>Interpret search results</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_70","title":"Input Controls","text":"<ol> <li> <p>Search Type Selector</p> </li> <li> <p>Parameter Range Sliders</p> </li> <li> <p>Run Search (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#72-model-stacking-visualizer","title":"72. Model Stacking Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_71","title":"Description","text":"<p>Show predictions from multiple base models and meta-learner output.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_71","title":"Learning Goals","text":"<ul> <li> <p>Understand stacking ensembles</p> </li> <li> <p>See diversity benefits</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_71","title":"Input Controls","text":"<ol> <li> <p>Base Model Selector</p> </li> <li> <p>Meta-Learner Selector</p> </li> <li> <p>Toggle Base Predictions (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#73-pipeline-builder","title":"73. Pipeline Builder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_72","title":"Description","text":"<p>Chain preprocessing and modeling steps interactively.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_72","title":"Learning Goals","text":"<ul> <li> <p>Understand ML pipelines</p> </li> <li> <p>Ensure reproducible workflows</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_72","title":"Input Controls","text":"<ol> <li> <p>Add Step (dropdown)</p> </li> <li> <p>Remove Step (click)</p> </li> <li> <p>Run Pipeline (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#74-model-export-and-import-simulator","title":"74. Model Export and Import Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_73","title":"Description","text":"<p>Save and reload trained models to demonstrate persistence.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_73","title":"Learning Goals","text":"<ul> <li> <p>Understand model serialization</p> </li> <li> <p>Practice deployment readiness</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_73","title":"Input Controls","text":"<ol> <li> <p>Save Model (button)</p> </li> <li> <p>Load Model (button)</p> </li> <li> <p>Reset Session (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#75-api-endpoint-tester","title":"75. API Endpoint Tester","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_74","title":"Description","text":"<p>Send requests to a mock ML API and view JSON responses.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_74","title":"Learning Goals","text":"<ul> <li> <p>Understand model serving endpoints</p> </li> <li> <p>Practice request formatting</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_74","title":"Input Controls","text":"<ol> <li> <p>Input Data Field</p> </li> <li> <p>Send Request (button)</p> </li> <li> <p>View Raw Response (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#76-batch-vs-real-time-prediction-tool","title":"76. Batch vs. Real-Time Prediction Tool","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_75","title":"Description","text":"<p>Switch between batch file processing and live API predictions.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_75","title":"Learning Goals","text":"<ul> <li> <p>Understand latency differences</p> </li> <li> <p>Recognize trade-offs in deployment modes</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_75","title":"Input Controls","text":"<ol> <li> <p>Mode Selector</p> </li> <li> <p>Upload Dataset (file input)</p> </li> <li> <p>Simulate Real-Time (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#77-model-version-comparator","title":"77. Model Version Comparator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_76","title":"Description","text":"<p>Load two model versions and compare accuracy and latency.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_76","title":"Learning Goals","text":"<ul> <li> <p>Track performance over versions</p> </li> <li> <p>Make informed upgrade decisions</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_76","title":"Input Controls","text":"<ol> <li> <p>Version Selector A</p> </li> <li> <p>Version Selector B</p> </li> <li> <p>Compare Now (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#78-ab-testing-simulator","title":"78. A/B Testing Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_77","title":"Description","text":"<p>Split traffic between two models and track conversions.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_77","title":"Learning Goals","text":"<ul> <li> <p>Understand online experimentation</p> </li> <li> <p>Interpret statistical significance</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_77","title":"Input Controls","text":"<ol> <li> <p>Traffic Split Slider</p> </li> <li> <p>Run Experiment (button)</p> </li> <li> <p>View p-Value (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#79-cost-of-prediction-calculator","title":"79. Cost of Prediction Calculator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_78","title":"Description","text":"<p>Estimate compute cost for different model sizes and usage levels.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_78","title":"Learning Goals","text":"<ul> <li> <p>Relate model complexity to cost</p> </li> <li> <p>Make cost-aware deployment decisions</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_78","title":"Input Controls","text":"<ol> <li> <p>Model Size Slider</p> </li> <li> <p>Requests per Minute Slider</p> </li> <li> <p>Region Selector</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#80-energy-efficiency-meter","title":"80. Energy Efficiency Meter","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_79","title":"Description","text":"<p>Track power consumption estimates during model inference.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_79","title":"Learning Goals","text":"<ul> <li> <p>Recognize environmental impact of ML</p> </li> <li> <p>Optimize for efficiency</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_79","title":"Input Controls","text":"<ol> <li> <p>Model Type Selector</p> </li> <li> <p>Batch Size Slider</p> </li> <li> <p>Toggle Energy Display (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#81-model-interpretability-dashboard","title":"81. Model Interpretability Dashboard","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_80","title":"Description","text":"<p>Combine SHAP, partial dependence, and counterfactuals in one view for a selected prediction.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_80","title":"Learning Goals","text":"<ul> <li> <p>Integrate multiple interpretability methods</p> </li> <li> <p>Develop storytelling skills for predictions</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_80","title":"Input Controls","text":"<ol> <li> <p>Data Point Selector</p> </li> <li> <p>Interpretation Method Toggle</p> </li> <li> <p>Export Dashboard (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#82-lime-explainer-tool","title":"82. LIME Explainer Tool","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_81","title":"Description","text":"<p>Generate local linear approximations for individual predictions.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_81","title":"Learning Goals","text":"<ul> <li> <p>Understand local interpretability</p> </li> <li> <p>Compare to global feature importance</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_81","title":"Input Controls","text":"<ol> <li> <p>Data Point Selector</p> </li> <li> <p>Number of Samples Slider</p> </li> <li> <p>Toggle Highlighted Features (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#83-what-if-analysis-playground","title":"83. What-If Analysis Playground","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_82","title":"Description","text":"<p>Change feature values and watch prediction changes in real time.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_82","title":"Learning Goals","text":"<ul> <li> <p>Explore \"what-if\" scenarios</p> </li> <li> <p>Understand sensitivity of predictions</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_82","title":"Input Controls","text":"<ol> <li> <p>Feature Sliders</p> </li> <li> <p>Reset to Original (button)</p> </li> <li> <p>Show Probability Curve (toggle)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#84-bias-mitigation-simulator","title":"84. Bias Mitigation Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_83","title":"Description","text":"<p>Apply pre-processing or in-processing bias mitigation and measure impact.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_83","title":"Learning Goals","text":"<ul> <li> <p>Evaluate fairness interventions</p> </li> <li> <p>Compare accuracy before and after</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_83","title":"Input Controls","text":"<ol> <li> <p>Mitigation Method Selector</p> </li> <li> <p>Target Group Selector</p> </li> <li> <p>Recalculate Metrics (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#85-model-robustness-tester","title":"85. Model Robustness Tester","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_84","title":"Description","text":"<p>Add noise, missing values, or feature shifts to test model stability.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_84","title":"Learning Goals","text":"<ul> <li> <p>Assess robustness under real-world conditions</p> </li> <li> <p>Identify fragile models</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_84","title":"Input Controls","text":"<ol> <li> <p>Noise Level Slider</p> </li> <li> <p>Missing Value Percentage Slider</p> </li> <li> <p>Feature Shift Toggle</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#86-ensemble-diversity-visualizer","title":"86. Ensemble Diversity Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_85","title":"Description","text":"<p>Plot decision boundaries of ensemble members to show diversity benefits.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_85","title":"Learning Goals","text":"<ul> <li> <p>Understand why diversity improves ensembles</p> </li> <li> <p>Detect overcorrelated base models</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_85","title":"Input Controls","text":"<ol> <li> <p>Number of Models Slider</p> </li> <li> <p>Model Type Selector</p> </li> <li> <p>Toggle Overlay Boundaries (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#87-transfer-learning-feature-explorer","title":"87. Transfer Learning Feature Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_86","title":"Description","text":"<p>Load pre-trained model features and visualize them for a custom dataset.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_86","title":"Learning Goals","text":"<ul> <li> <p>Understand feature reuse</p> </li> <li> <p>See adaptation benefits</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_86","title":"Input Controls","text":"<ol> <li> <p>Pre-Trained Model Selector</p> </li> <li> <p>Layer Output Selector</p> </li> <li> <p>Toggle Feature Map Display</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#88-fine-tuning-tracker","title":"88. Fine-Tuning Tracker","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_87","title":"Description","text":"<p>Compare base and fine-tuned model accuracy/loss curves.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_87","title":"Learning Goals","text":"<ul> <li> <p>Understand fine-tuning process</p> </li> <li> <p>Evaluate improvements over baseline</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_87","title":"Input Controls","text":"<ol> <li> <p>Learning Rate Slider</p> </li> <li> <p>Epoch Count Slider</p> </li> <li> <p>Toggle Base Model Curve (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#89-multi-task-learning-visualizer","title":"89. Multi-Task Learning Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_88","title":"Description","text":"<p>Train on two tasks simultaneously and track performance for each.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_88","title":"Learning Goals","text":"<ul> <li> <p>Understand shared representations</p> </li> <li> <p>Recognize trade-offs in multi-task setups</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_88","title":"Input Controls","text":"<ol> <li> <p>Task Weight Sliders</p> </li> <li> <p>Epoch Count Slider</p> </li> <li> <p>Toggle Shared Layers (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#90-attention-mechanism-explorer","title":"90. Attention Mechanism Explorer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_89","title":"Description","text":"<p>Visualize attention weights for sequence-to-sequence models.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_89","title":"Learning Goals","text":"<ul> <li> <p>Understand how models focus on parts of input</p> </li> <li> <p>Interpret attention heatmaps</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_89","title":"Input Controls","text":"<ol> <li> <p>Input Sequence Field</p> </li> <li> <p>Highlight Attention Matrix (checkbox)</p> </li> <li> <p>Reset Example (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#91-transformer-architecture-flow","title":"91. Transformer Architecture Flow","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_90","title":"Description","text":"<p>Step through encoder and decoder layers with visual activations.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_90","title":"Learning Goals","text":"<ul> <li> <p>See data flow in transformer models</p> </li> <li> <p>Recognize role of each sublayer</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_90","title":"Input Controls","text":"<ol> <li> <p>Layer Stepper (next/prev)</p> </li> <li> <p>Toggle Positional Encoding View</p> </li> <li> <p>Reset Sequence (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#92-hyperparameter-sensitivity-map","title":"92. Hyperparameter Sensitivity Map","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_91","title":"Description","text":"<p>Generate heatmaps showing accuracy changes across parameter ranges.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_91","title":"Learning Goals","text":"<ul> <li> <p>Identify sensitive parameters</p> </li> <li> <p>Focus tuning efforts effectively</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_91","title":"Input Controls","text":"<ol> <li> <p>Parameter Range Sliders</p> </li> <li> <p>Run Grid Search (button)</p> </li> <li> <p>Toggle Best Point Marker (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#93-model-compression-simulator","title":"93. Model Compression Simulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_92","title":"Description","text":"<p>Prune weights and quantize parameters, tracking accuracy drop.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_92","title":"Learning Goals","text":"<ul> <li> <p>Understand trade-offs between size and performance</p> </li> <li> <p>Recognize deployment benefits of smaller models</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_92","title":"Input Controls","text":"<ol> <li> <p>Pruning Percentage Slider</p> </li> <li> <p>Quantization Level Selector</p> </li> <li> <p>Apply Compression (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#94-edge-deployment-emulator","title":"94. Edge Deployment Emulator","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_93","title":"Description","text":"<p>Simulate running a model on constrained hardware.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_93","title":"Learning Goals","text":"<ul> <li> <p>Understand latency and memory constraints</p> </li> <li> <p>Optimize for edge environments</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_93","title":"Input Controls","text":"<ol> <li> <p>Hardware Profile Selector</p> </li> <li> <p>Batch Size Slider</p> </li> <li> <p>Toggle Latency Display (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#95-streaming-data-dashboard","title":"95. Streaming Data Dashboard","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_94","title":"Description","text":"<p>Stream incoming data and update predictions in real time.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_94","title":"Learning Goals","text":"<ul> <li> <p>Handle continuous inputs</p> </li> <li> <p>Recognize challenges in online learning</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_94","title":"Input Controls","text":"<ol> <li> <p>Stream Speed Slider</p> </li> <li> <p>Pause/Resume Stream (button)</p> </li> <li> <p>Reset Dashboard (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#96-online-learning-visualizer","title":"96. Online Learning Visualizer","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_95","title":"Description","text":"<p>Update model incrementally with new data and track evolving accuracy.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_95","title":"Learning Goals","text":"<ul> <li> <p>Understand incremental training</p> </li> <li> <p>Monitor performance drift</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_95","title":"Input Controls","text":"<ol> <li> <p>Learning Rate Slider</p> </li> <li> <p>Batch Size Slider</p> </li> <li> <p>Toggle History Chart (checkbox)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#97-capstone-project-data-selector","title":"97. Capstone Project Data Selector","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_96","title":"Description","text":"<p>Choose dataset for final project from curated sources and preview statistics.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_96","title":"Learning Goals","text":"<ul> <li> <p>Practice dataset selection skills</p> </li> <li> <p>Evaluate dataset suitability</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_96","title":"Input Controls","text":"<ol> <li> <p>Dataset Selector</p> </li> <li> <p>Preview Stats (button)</p> </li> <li> <p>Download Data (button)</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#98-model-comparison-dashboard","title":"98. Model Comparison Dashboard","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_97","title":"Description","text":"<p>Compare multiple models across accuracy, latency, and fairness metrics.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_97","title":"Learning Goals","text":"<ul> <li> <p>Perform multi-metric evaluation</p> </li> <li> <p>Select best model for deployment</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_97","title":"Input Controls","text":"<ol> <li> <p>Model Selector (multi-select)</p> </li> <li> <p>Metric Selector</p> </li> <li> <p>Toggle Best Model Highlight</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#99-end-to-end-workflow-builder","title":"99. End-to-End Workflow Builder","text":""},{"location":"sims/microsim-lists/100-data-science-microsims/#description_98","title":"Description","text":"<p>Drag-and-drop stages to build a full ML pipeline from data to deployment.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_98","title":"Learning Goals","text":"<ul> <li> <p>Integrate all learned concepts</p> </li> <li> <p>Visualize project workflow</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_98","title":"Input Controls","text":"<ol> <li> <p>Stage Palette (drag items)</p> </li> <li> <p>Connect Stages (mouse drag)</p> </li> <li> <p>Run Workflow (button)</p> </li> <li> <p>Ethical Impact Assessment Tool</p> </li> </ol>"},{"location":"sims/microsim-lists/100-data-science-microsims/#description_99","title":"Description","text":"<p>Rate model across transparency, fairness, privacy, and societal impact dimensions.</p>"},{"location":"sims/microsim-lists/100-data-science-microsims/#learning-goals_99","title":"Learning Goals","text":"<ul> <li> <p>Incorporate ethics into data science projects</p> </li> <li> <p>Balance technical and social factors</p> </li> </ul>"},{"location":"sims/microsim-lists/100-data-science-microsims/#input-controls_99","title":"Input Controls","text":"<ol> <li> <p>Impact Category Sliders</p> </li> <li> <p>Generate Report (button)</p> </li> <li> <p>Reset Assessment (button)</p> </li> </ol>"},{"location":"sims/normal-dice-distribution/","title":"MicroSim Template","text":""},{"location":"sims/normal-dice-distribution/#sample-iframe","title":"Sample iframe","text":"<p>You can include the following in your HTML to use this MicroSim</p> <pre><code>&lt;iframe src=\"DOC_ROOT/docs/sims/MICROSIM_NAME/main.html\" height=\"400px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim Edit this MicroSim</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/microsims/sims/spectrum-analyzer/main.html\" height=\"400\"  scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/normal-dice-distribution/#about-this-microsim","title":"About this MicroSim","text":""},{"location":"sims/pair-dice-sum-distribution/","title":"Two-Dice Sum Distribution MicroSim","text":""},{"location":"sims/pair-dice-sum-distribution/#sample-iframe","title":"Sample iframe","text":"<p>You can include the following in your HTML to use this MicroSim</p> <pre><code>&lt;iframe src=\"data-science-course/sims/pair-dice-sum-distribution//main.html\" height=\"500px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim Edit this MicroSim</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/microsims/sims/spectrum-analyzer/main.html\" height=\"400\"  scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/pair-dice-sum-distribution/#about-this-microsim","title":"About this MicroSim","text":""},{"location":"sims/template/","title":"MicroSim Template","text":""},{"location":"sims/template/#sample-iframe","title":"Sample iframe","text":"<p>You can include the following in your HTML to use this MicroSim</p> <pre><code>&lt;iframe src=\"/data-science-course/docs/sims/MICROSIM_NAME/main.html\" height=\"400px\" scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim Edit this MicroSim</p> <pre><code>&lt;iframe src=\"https://dmccreary.github.io/microsims/sims/spectrum-analyzer/main.html\" height=\"400\"  scrolling=\"no\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"sims/template/#about-this-microsim","title":"About this MicroSim","text":"<p>This MicroSim teaches us how to specify the drawing of a static filled circle.</p>"},{"location":"sims/template/#sample-prompt","title":"Sample Prompt","text":"<p>Prompt</p> <p>Create a single file p5.js sketch.   Draw a green circle on a 600x400 canvas with a radius of 200.</p>"},{"location":"sims/template/#sample-response","title":"Sample Response","text":"<pre><code>// canvas regions setup\n// let canvasWidth = 750;\nlet drawHeight = 400;\nlet controlHeight = 50;\nlet canvasHeight = drawHeight + controlHeight;\nlet aspectRatio = 1.91; // Open Graph standard\nlet canvasWidth = canvasHeight * aspectRatio;\nlet radius = 200;\n\nfunction setup() {\n  const canvas = createCanvas(canvasWidth, canvasHeight);\n  var mainElement = document.querySelector('main');\n  canvas.parent(mainElement);\n}\n\nfunction draw() {\n  // background of drawing region\n  fill('aliceblue');\n  rect(0, 0, canvasWidth, drawHeight);\n\n  // background of controls\n  fill('whitegray');\n  rect(0, drawHeight, canvasWidth, controlHeight);\n  circle(canvasWidth/2, canvasHeight/2, radius);\n}\n</code></pre>"},{"location":"sims/template/#lesson-plan","title":"Lesson Plan","text":""},{"location":"sims/template/#grade-level-subject-and-topic","title":"Grade Level, Subject and Topic","text":"<p>9th grade geometry. Circle and radius.</p>"},{"location":"sims/template/#activities","title":"Activities","text":""},{"location":"sims/template/#fill-color","title":"Fill Color","text":"<p>Change the color in the prompt.  You can specify any one of the 140 named colors.</p>"},{"location":"sims/template/#border-weight","title":"Border Weight","text":"<p>Change the prompt to include a black border of width 10.</p>"},{"location":"sims/template/#border-color","title":"Border Color","text":"<p>Change the prompt to make the border purple.</p>"},{"location":"sims/template/#change-the-radius","title":"Change the Radius","text":"<p>Change the prompt to make the circle smaller or larger by changing the radius from 10 to 200.</p>"},{"location":"sims/template/#change-the-location","title":"Change the Location","text":"<p>Change the prompt to move the circle to the left or right.</p>"},{"location":"sims/template/#references","title":"References","text":"<ul> <li>Processing Wiki on Positioning Your Canvas</li> </ul>"},{"location":"sims/ten-stats/","title":"Ten Status MicroSims","text":"<p>Run the Vis.js MicroSim</p>"}]}