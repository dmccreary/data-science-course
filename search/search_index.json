{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Based Data Science with Python","text":"<p>Welcome to our website for the course that uses AI to help students learn data science.</p>"},{"location":"checklist/","title":"Site Checklist","text":"<ol> <li>Customize the fields in your mkdocs.yml file</li> <li>Configure Google Analytics to use the right site ID</li> <li>Make sure that your .gitignore file includes the <code>site</code> directory</li> <li>Test the build</li> <li>Make sure the Edit button appears</li> <li>Make sure that code color heightening renders correctly</li> <li>run <code>git config advice.addIgnoredFile false</code></li> </ol>"},{"location":"code-highlight-test/","title":"Code Syntax Color Highlight Test","text":""},{"location":"code-highlight-test/#python","title":"Python","text":"<pre><code>hello_string = \"Hello World!\"\nprint(hello_string)\nx = 1\nif x == 1:\n    # indented four spaces\n    print(\"x is 1.\")\n</code></pre>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"glossary/","title":"Glossary of Terms","text":""},{"location":"glossary/#iso-definition","title":"ISO Definition","text":"<p>A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"glossary/#term","title":"Term","text":"<p>This is the definition of the term.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p>"},{"location":"how-we-built-this-site/#image-generation-and-compression","title":"Image Generation and Compression","text":"<p>I have used ChatGPT to create most of my images.  However, they are too large for most websites.  To compress them down I used  https://tinypng.com/ which is a free tool  for compressing png images without significant loss of quality.  The files created with ChatGPT are typically around 1-2 MB.  After  using the TinyPNG site the size is typically around 200-300KB.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"Site References","text":"<ol> <li>mkdocs - https://www.mkdocs.org/ - this is our tool for building the website.  It converts Markdown into HTML in the <code>site</code> directory.</li> <li>mkdocs material theme - https://squidfunk.github.io/mkdocs-material/ - this is the theme for our site.  The theme adds the user interface elements that give our site the look and feel.  It also has the features such as social cards.</li> <li>GitHub Pages - https://pages.github.com/ - this is the free tool for hosting public websites created by mkdocs</li> <li>Markdown - https://www.mkdocs.org/user-guide/writing-your-docs/#writing-with-markdown - this is the format we use for text.  It allows us to have headers, lists, tables, links and images without learning HTML.</li> <li>Deploy Mkdocs GitHub Action - https://github.com/marketplace/actions/deploy-mkdocs - this is the tool we use to automatically build our site after edits are checked in with Git.</li> <li>Git Book - https://git-scm.com/book/en/v2 - a useful book on Git.  Just read the first two chapters to learn how to check in new code.</li> <li>Conda - https://conda.io/ - this is a command line tool that keeps our Python libraries organized for each project.</li> <li>VS Code - https://code.visualstudio.com/ - this is the integrated development environment we use to mange the files on our website.</li> <li>Markdown Paste - https://marketplace.visualstudio.com/items?itemName=telesoho.vscode-markdown-paste-image - this is the VS code extension we use to make sure we keep the markdown format generated by ChatGPT.</li> </ol>"},{"location":"concepts/concept-dependencies/","title":"Concept Dependencies","text":""},{"location":"concepts/concept-dependencies/#prompt","title":"Prompt","text":"<pre><code>That was perfect.  Thank you very much.\nThe next step is to create a dependency graph\nof all the 150 concepts on the list. \nFor each concept, think about other concepts\nthat this concept depends upon for understanding.\n\nFor each of the 150 concepts return a single row in CSV format.\n\nColumn 1 is the ConceptID (the integer 1 to 150)\nColumn 2 is the ConceptLabel\nColumn 3 is the Dependencies in the form of pipe-delimited list of ConceptIDs\n\nMake sure that Foundation Concepts (prerequisites) like knowledge of Python don't have any dependencies.\nMake sure that every concept except Foundation Concepts have at least one dependency.\n</code></pre>"},{"location":"concepts/concept-enumeration/","title":"Concept Enumeration","text":""},{"location":"concepts/concept-enumeration/#prompt","title":"Prompt","text":"<p>```linenums=\"0\" I would like to develop a new course called  \"Introduction to Data Science with Python using AI\". </p> <p>I would like you to generate a list of all the core concepts that we would cover in this course and the dependency relationships between these concepts so we could order them and create an learning graph. This course would assume that students have basic Python programming experience.  This course would be a class that covers the following topics: </p> <ol> <li>What is data science? </li> <li>Summary of business needs for employees with data science skills. </li> <li>Review of Python concepts </li> <li>How generative AI can help you learn Python </li> <li>Basic Python libraries for handling data such as NumPy </li> <li>Python statistical libraries </li> <li>Python libraries for machine learning </li> <li>Python libraries for working with graph data </li> <li>Python libraries for visualization with a focus on Plotly </li> <li>Python libraries for NLP </li> <li>Python libraries for vector stores </li> <li>Python libraries for GenAI including LangChain and LlamaIndex </li> </ol> <p>Please create a numbered list of the 150 most important topics  that would be taught in this course. Begin with the prerequisite concepts and then proceed to defining key terms. Then include the core concepts used in Python data analysis. Finally, close with some potential final project concepts  that students could create. Think carefully about the ordering  of the concepts from simple to more abstract. For each concept,  return a conceptID followed by short name which would be the label for the concept in a learning graph (concept dependency). Feel free to use short names and abbreviations.</p> <p>ChatGPT</p> <p>Thought for 1m 34s</p> <ol> <li>DS Definition - Definition of Data Science</li> <li>DS Importance - Importance of Data Science</li> <li>DS vs DA - Data Science vs. Data Analysis</li> <li>DS Workflow - Data Science Workflow</li> <li>DS Roles - Roles in Data Science</li> <li>DS DataCollection - Data Collection Methods</li> <li>DS DataCleaning - Data Cleaning Processes</li> <li>DS DataExploration - Exploratory Data Analysis</li> <li>DS FeatureEngineering - Feature Engineering</li> <li>DS Modeling - Modeling and Algorithms</li> <li>DS Evaluation - Model Evaluation Techniques</li> <li>DS Deployment - Model Deployment Strategies</li> <li>Business DS Needs - Business Needs for Data Science Skills</li> <li>Business DS Impact - Impact on Decision Making</li> <li>Business DS Examples - Business Applications of Data Science</li> <li>Python DataTypes - Data Types in Python</li> <li>Python DataStructures - Data Structures (List, Dict, Set)</li> <li>Python Control - Control Structures (Loops, Conditionals)</li> <li>Python Functions - Functions and Modules</li> <li>Python OOP - Object-Oriented Programming</li> <li>Python FileHandling - File Handling</li> <li>Python Exceptions - Exception Handling</li> <li>Python Debugging - Debugging Techniques</li> <li>Python LibrariesIntro - Introduction to Python Libraries</li> <li>AI Intro - Introduction to Generative AI</li> <li>AI LearnPython - AI Tools for Learning Python</li> <li>AI CodeAssistants - Using AI Assistants for Coding</li> <li>AI LearningResources - AI-Generated Learning Resources</li> <li>AI Ethics - Ethical Considerations of AI</li> <li>NumPy Intro - Introduction to NumPy</li> <li>NumPy Arrays - NumPy Arrays and Operations</li> <li>NumPy Broadcasting - Broadcasting in NumPy</li> <li>NumPy AdvancedIndexing - Advanced Indexing</li> <li>NumPy MathFunctions - Mathematical Functions</li> <li>Pandas Intro - Introduction to Pandas</li> <li>Pandas DataFrames - DataFrames and Series</li> <li>Pandas IO - Reading and Writing Data</li> <li>Pandas Selection - Data Selection and Filtering</li> <li>Pandas Cleaning - Data Cleaning in Pandas</li> <li>Pandas MissingData - Handling Missing Data</li> <li>Pandas Merging - Merging and Joining DataFrames</li> <li>Pandas Grouping - Data Aggregation and Grouping</li> <li>Pandas Pivot - Pivot Tables</li> <li>Pandas TimeSeries - Time Series Data</li> <li>Stats Intro - Introduction to Statistics</li> <li>Stats Descriptive - Descriptive Statistics</li> <li>Stats Inferential - Inferential Statistics</li> <li>Stats Distributions - Probability Distributions</li> <li>SciPy Intro - SciPy for Statistical Analysis</li> <li>Statsmodels Intro - Statsmodels Library</li> <li>Stats Hypothesis - Hypothesis Testing</li> <li>Stats Regression - Regression Analysis</li> <li>ML Intro - Introduction to Machine Learning</li> <li>ML Supervised - Supervised Learning</li> <li>ML Unsupervised - Unsupervised Learning</li> <li>Sklearn Intro - scikit-learn Library</li> <li>ML Preprocessing - Data Preprocessing</li> <li>ML FeatureSelection - Feature Selection Techniques</li> <li>ML CrossValidation - Cross-Validation Methods</li> <li>ML Classification - Classification Algorithms</li> <li>ML Regression - Regression Algorithms</li> <li>ML Clustering - Clustering Algorithms</li> <li>ML Evaluation - Model Evaluation and Validation</li> <li>NetworkX Intro - NetworkX Library</li> <li>NetworkX Create - Creating Graphs</li> <li>NetworkX Algorithms - Graph Algorithms</li> <li>NetworkX Visualize - Graph Visualization</li> <li>Viz Importance - Importance of Data Visualization</li> <li>Matplotlib Intro - Introduction to Matplotlib</li> <li>Seaborn Intro - Introduction to Seaborn</li> <li>Plotly Intro - Introduction to Plotly</li> <li>Plotly Basic - Basic Plots with Plotly</li> <li>Plotly Interactive - Interactive Visualizations</li> <li>Plotly Dash - Plotly Dash for Web Apps</li> <li>NLP Intro - Introduction to NLP</li> <li>NLP TextPreprocessing - Text Preprocessing Techniques</li> <li>NLP Tokenization - Tokenization Methods</li> <li>NLP WordEmbeddings - Word Embeddings</li> <li>NLTK Intro - NLTK Library</li> <li>Spacy Intro - spaCy Library</li> <li>NLP Sentiment - Sentiment Analysis</li> <li>NLP TextClassify - Text Classification</li> <li>VectorStores Intro - Introduction to Vector Stores</li> <li>Faiss Intro - FAISS Library</li> <li>Annoy Intro - Annoy Library</li> <li>VectorStores Apps - Vector Store Applications</li> <li>GenAI Intro - Introduction to Generative AI</li> <li>LangChain Intro - LangChain Library</li> <li>LangChain Pipelines - Creating Pipelines</li> <li>LangChain COT - Chain-of-thought Prompting</li> <li>LlamaIndex Intro - LlamaIndex Library</li> <li>LlamaIndex Indexing - Indexing Data</li> <li>LlamaIndex Querying - Querying Data</li> <li>Project Ideas - Potential Final Projects Overview</li> <li>Project DataAnalysis - Data Analysis Project</li> <li>Project MLModel - Machine Learning Model Project</li> <li>Project NLP - NLP Application Project</li> <li>Project Visualization - Data Visualization Dashboard</li> <li>Project GraphAnalysis - Graph Analysis Project</li> <li>Project AIChatbot - AI-Powered Chatbot Project</li> <li>Project Planning - Planning a Data Science Project</li> <li>Project Dataset - Choosing Datasets</li> <li>Project Teams - Team Collaboration</li> <li>Project Presentation - Presenting Findings</li> <li>Project Documentation - Project Documentation</li> <li>Project Deployment - Deploying Projects</li> <li>ML DeepLearning - Introduction to Deep Learning</li> <li>TensorFlow Intro - TensorFlow Library</li> <li>PyTorch Intro - PyTorch Library</li> <li>DL NeuralNetworks - Neural Network Fundamentals</li> <li>DL CNNs - Convolutional Neural Networks</li> <li>DL RNNs - Recurrent Neural Networks</li> <li>DL TransferLearning - Transfer Learning</li> <li>DL NLP Transformers - Transformers Architecture</li> <li>DL NLP BERT - BERT Model</li> <li>TimeSeries Intro - Time Series Analysis</li> <li>TimeSeries Decomposition - Time Series Decomposition</li> <li>TimeSeries ARIMA - ARIMA Models</li> <li>TimeSeries Forecasting - Forecasting Techniques</li> <li>Recommender Intro - Recommender Systems</li> <li>Recommender CollabFilter - Collaborative Filtering</li> <li>Recommender ContentBased - Content-Based Filtering</li> <li>Recommender Hybrid - Hybrid Recommenders</li> <li>DataEng Intro - Introduction to Data Engineering</li> <li>DataEng ETL - ETL Processes</li> <li>DataEng DataWarehouses - Data Warehouses</li> <li>DataEng DataLakes - Data Lakes</li> <li>ML Reinforcement - Reinforcement Learning Basics</li> <li>ML GANs - Generative Adversarial Networks</li> <li>ML AutoML - Automated Machine Learning</li> <li>ML Explainability - Model Explainability</li> <li>BigData Intro - Introduction to Big Data</li> <li>PySpark Intro - Introduction to PySpark</li> <li>Cloud Intro - Cloud Computing Basics</li> <li>AWS Intro - AWS Overview</li> <li>Docker Intro - Introduction to Docker</li> <li>Ethics AI - Ethical Considerations in AI</li> <li>Privacy Data - Data Privacy and Security</li> <li>Bias Fairness - Bias and Fairness in ML</li> <li>Git Intro - Introduction to Git</li> <li>GitHub Intro - Using GitHub</li> <li>Viz BestPractices - Visualization Best Practices</li> <li>Dask Intro - Dask for Parallel Computing</li> <li>CaseStudies Intro - Case Studies Overview</li> <li>Communication Skills - Communication Skills</li> <li>CriticalThinking Skills - Critical Thinking</li> <li>Leadership Skills - Leadership in Data Science</li> <li>Final Review - Course Summary and Review</li> <li>Next Steps - Next Steps in Learning</li> <li>Course Evaluation - Course Feedback and Evaluation</li> </ol> <p>o1</p>"},{"location":"concepts/concept-taxonomy/","title":"Concept Taxonomy","text":"<p>Certainly! Based on the course content you've provided, here is a 10-category taxonomy of the types of concepts in this course:</p> <ol> <li>Foundation Concepts (Prerequisites)</li> <li>Key Terms</li> <li>Python Programming Concepts</li> <li>Python Libraries</li> <li>Data Manipulation and Analysis</li> <li>Statistical Analysis</li> <li>Machine Learning Concepts</li> <li>Data Visualization</li> <li>Natural Language Processing (NLP)</li> <li>Generative AI and Advanced Topics</li> </ol>"},{"location":"concepts/concept-taxonomy/#detailed-taxonomy","title":"Detailed Taxonomy:","text":"<ol> <li> <p>Foundation Concepts (Prerequisites)     Fundamental skills and knowledge required before diving into data science topics, including basic programming concepts and understanding of data types.</p> </li> <li> <p>Key Terms     Essential terminology and definitions used in data science, machine learning, AI, and related fields to build a strong conceptual foundation.</p> </li> <li> <p>Python Programming Concepts     Core Python programming skills necessary for data science, such as control structures, functions, object-oriented programming, file handling, and debugging.</p> </li> <li> <p>Python Libraries     Introduction to important Python libraries used in data science, including NumPy, Pandas, SciPy, Statsmodels, scikit-learn, NetworkX, and more.</p> </li> <li> <p>Data Manipulation and Analysis     Techniques for collecting, cleaning, exploring, and transforming data to prepare it for analysis, including data handling with Pandas and NumPy.</p> </li> <li> <p>Statistical Analysis     Concepts and methods in statistics necessary for analyzing data and making inferences, including descriptive and inferential statistics, probability distributions, and hypothesis testing.</p> </li> <li> <p>Machine Learning Concepts     Understanding of machine learning algorithms, model building, evaluation techniques, and deployment strategies using libraries like scikit-learn.</p> </li> <li> <p>Data Visualization     Tools and techniques for visualizing data to effectively communicate insights, focusing on libraries like Matplotlib, Seaborn, and Plotly.</p> </li> <li> <p>Natural Language Processing (NLP)     Concepts and tools for processing and analyzing textual data, including text preprocessing, tokenization, sentiment analysis, and using libraries like NLTK and spaCy.</p> </li> <li> <p>Generative AI and Advanced Topics     Advanced topics including generative AI, vector stores, deep learning frameworks, and the use of libraries like LangChain and LlamaIndex for building AI applications.</p> </li> </ol> <p>This taxonomy covers the breadth of topics in your course, organizing them into coherent categories that reflect their roles in the learning pathway. Each category groups related concepts together, making it easier to structure the course content and understand the dependencies between topics.</p> <p>o1</p>"},{"location":"sims/","title":"List of MicroSims for Data Science","text":"<p>Learning Graph</p>"},{"location":"sims/learning-graph/","title":"View Learning Graph","text":"<p>Run Learning Graph MicroSim</p>"}]}