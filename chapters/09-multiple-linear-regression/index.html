
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An online course on introduction to data science with Python.  Extensive use of AI tools and MicroSims to help you learn.">
      
      
        <meta name="author" content="Dan McCreary">
      
      
        <link rel="canonical" href="https://dmccreary.github.io/data-science-course/chapters/09-multiple-linear-regression/">
      
      
        <link rel="prev" href="../08-model-evaluation/">
      
      
        <link rel="next" href="../10-numpy-computing/">
      
      
      <link rel="icon" href="../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.43">
    
    
      
        <title>Multiple Linear Regression - AI Based Data Science with Python</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-RTBCWGJKKR"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-RTBCWGJKKR",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-RTBCWGJKKR",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Multiple Linear Regression - AI Based Data Science with Python" >
      
        <meta  property="og:description"  content="An online course on introduction to data science with Python.  Extensive use of AI tools and MicroSims to help you learn." >
      
        <meta  property="og:image"  content="https://dmccreary.github.io/data-science-course/assets/images/social/chapters/09-multiple-linear-regression/index.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://dmccreary.github.io/data-science-course/chapters/09-multiple-linear-regression/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Multiple Linear Regression - AI Based Data Science with Python" >
      
        <meta  name="twitter:description"  content="An online course on introduction to data science with Python.  Extensive use of AI tools and MicroSims to help you learn." >
      
        <meta  name="twitter:image"  content="https://dmccreary.github.io/data-science-course/assets/images/social/chapters/09-multiple-linear-regression/index.png" >
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#multiple-linear-regression" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="AI Based Data Science with Python" class="md-header__button md-logo" aria-label="AI Based Data Science with Python" data-md-component="logo">
      
  <img src="../../img/logo-192.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI Based Data Science with Python
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Multiple Linear Regression
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/dmccreary/data-science-course" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub Repo
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="AI Based Data Science with Python" class="md-nav__button md-logo" aria-label="AI Based Data Science with Python" data-md-component="logo">
      
  <img src="../../img/logo-192.png" alt="logo">

    </a>
    AI Based Data Science with Python
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/dmccreary/data-science-course" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub Repo
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course-description/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Course Description
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Chapters
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Chapters
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-intro-to-data-science/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Data Science
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02-python-environment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Environment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-python-data-structures/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Data Structures
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-data-cleaning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Cleaning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-data-visualization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Visualization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-statistical-foundations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistical Foundations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-simple-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple Linear Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-model-evaluation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Evaluation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Multiple Linear Regression
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Multiple Linear Regression
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts Covered
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-leveling-up-your-prediction-powers" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: Leveling Up Your Prediction Powers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#from-one-feature-to-many-multiple-predictors" class="md-nav__link">
    <span class="md-ellipsis">
      From One Feature to Many: Multiple Predictors
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-your-first-multiple-regression-model" class="md-nav__link">
    <span class="md-ellipsis">
      Building Your First Multiple Regression Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building Your First Multiple Regression Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-multiple-regression-anatomy" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Multiple Regression Anatomy
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interpreting-multiple-regression-coefficients" class="md-nav__link">
    <span class="md-ellipsis">
      Interpreting Multiple Regression Coefficients
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-multicollinearity-problem" class="md-nav__link">
    <span class="md-ellipsis">
      The Multicollinearity Problem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variance-inflation-factor-quantifying-multicollinearity" class="md-nav__link">
    <span class="md-ellipsis">
      Variance Inflation Factor: Quantifying Multicollinearity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variance Inflation Factor: Quantifying Multicollinearity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-multicollinearity-detector-microsim" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Multicollinearity Detector MicroSim
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feature-selection-choosing-the-right-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Selection: Choosing the Right Variables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Selection: Choosing the Right Variables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#forward-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Forward Selection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backward-elimination" class="md-nav__link">
    <span class="md-ellipsis">
      Backward Elimination
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stepwise-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Stepwise Selection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Stepwise Selection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-feature-selection-race" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Feature Selection Race
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#handling-categorical-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Handling Categorical Variables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Handling Categorical Variables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dummy-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Dummy Variables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#one-hot-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      One-Hot Encoding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="One-Hot Encoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-one-hot-encoding-visualizer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: One-Hot Encoding Visualizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interaction-terms-when-features-work-together" class="md-nav__link">
    <span class="md-ellipsis">
      Interaction Terms: When Features Work Together
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#polynomial-features-capturing-curved-relationships" class="md-nav__link">
    <span class="md-ellipsis">
      Polynomial Features: Capturing Curved Relationships
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feature-engineering-the-art-of-creating-better-features" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Engineering: The Art of Creating Better Features
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Engineering: The Art of Creating Better Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-feature-engineering-laboratory" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Feature Engineering Laboratory
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feature-importance-understanding-what-matters" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Importance: Understanding What Matters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Importance: Understanding What Matters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coefficient-magnitude-after-standardization" class="md-nav__link">
    <span class="md-ellipsis">
      Coefficient Magnitude (After Standardization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#permutation-importance" class="md-nav__link">
    <span class="md-ellipsis">
      Permutation Importance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Permutation Importance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-feature-importance-explorer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Feature Importance Explorer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together-a-complete-multiple-regression-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Putting It All Together: A Complete Multiple Regression Workflow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Putting It All Together: A Complete Multiple Regression Workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-multiple-regression-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Multiple Regression Pipeline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-mistakes-to-avoid" class="md-nav__link">
    <span class="md-ellipsis">
      Common Mistakes to Avoid
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-your-multiple-regression-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      Summary: Your Multiple Regression Toolkit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#looking-ahead" class="md-nav__link">
    <span class="md-ellipsis">
      Looking Ahead
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-numpy-computing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NumPy Computing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11-nonlinear-models-regularization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Non-linear Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12-intro-to-machine-learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Intro to Machine Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13-neural-networks-pytorch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neural Networks and PyTorch
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../chapters-v1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Old v1 Content
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../labs/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Labs
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
      
        
          
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../sims/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    MicroSims
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../learning-graph/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Learning Graph
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../prompts/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Sample GenAI Prompts
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frequently Asked Questions
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how-we-built-this-site/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How We Built This Site
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../checklist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customization Checklist
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../license/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    License
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    References
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../checklist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customization Checklist
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contact
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts Covered
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-leveling-up-your-prediction-powers" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: Leveling Up Your Prediction Powers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#from-one-feature-to-many-multiple-predictors" class="md-nav__link">
    <span class="md-ellipsis">
      From One Feature to Many: Multiple Predictors
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-your-first-multiple-regression-model" class="md-nav__link">
    <span class="md-ellipsis">
      Building Your First Multiple Regression Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building Your First Multiple Regression Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-multiple-regression-anatomy" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Multiple Regression Anatomy
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interpreting-multiple-regression-coefficients" class="md-nav__link">
    <span class="md-ellipsis">
      Interpreting Multiple Regression Coefficients
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-multicollinearity-problem" class="md-nav__link">
    <span class="md-ellipsis">
      The Multicollinearity Problem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variance-inflation-factor-quantifying-multicollinearity" class="md-nav__link">
    <span class="md-ellipsis">
      Variance Inflation Factor: Quantifying Multicollinearity
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variance Inflation Factor: Quantifying Multicollinearity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-multicollinearity-detector-microsim" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Multicollinearity Detector MicroSim
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feature-selection-choosing-the-right-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Selection: Choosing the Right Variables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Selection: Choosing the Right Variables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#forward-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Forward Selection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backward-elimination" class="md-nav__link">
    <span class="md-ellipsis">
      Backward Elimination
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stepwise-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Stepwise Selection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Stepwise Selection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-feature-selection-race" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Feature Selection Race
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#handling-categorical-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Handling Categorical Variables
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Handling Categorical Variables">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dummy-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Dummy Variables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#one-hot-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      One-Hot Encoding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="One-Hot Encoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-one-hot-encoding-visualizer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: One-Hot Encoding Visualizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interaction-terms-when-features-work-together" class="md-nav__link">
    <span class="md-ellipsis">
      Interaction Terms: When Features Work Together
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#polynomial-features-capturing-curved-relationships" class="md-nav__link">
    <span class="md-ellipsis">
      Polynomial Features: Capturing Curved Relationships
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feature-engineering-the-art-of-creating-better-features" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Engineering: The Art of Creating Better Features
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Engineering: The Art of Creating Better Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-feature-engineering-laboratory" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Feature Engineering Laboratory
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feature-importance-understanding-what-matters" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Importance: Understanding What Matters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Importance: Understanding What Matters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coefficient-magnitude-after-standardization" class="md-nav__link">
    <span class="md-ellipsis">
      Coefficient Magnitude (After Standardization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#permutation-importance" class="md-nav__link">
    <span class="md-ellipsis">
      Permutation Importance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Permutation Importance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-feature-importance-explorer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Feature Importance Explorer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together-a-complete-multiple-regression-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Putting It All Together: A Complete Multiple Regression Workflow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Putting It All Together: A Complete Multiple Regression Workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-multiple-regression-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Multiple Regression Pipeline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-mistakes-to-avoid" class="md-nav__link">
    <span class="md-ellipsis">
      Common Mistakes to Avoid
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-your-multiple-regression-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      Summary: Your Multiple Regression Toolkit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#looking-ahead" class="md-nav__link">
    <span class="md-ellipsis">
      Looking Ahead
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/dmccreary/data-science-course/blob/master/docs/chapters/09-multiple-linear-regression/index.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="multiple-linear-regression">Multiple Linear Regression</h1>
<hr />
<p>title: Multiple Linear Regression
description: Unlock the power of multiple features to build more accurate predictions
generated_by: chapter-content-generator skill
date: 2025-12-15
version: 0.03</p>
<hr />
<h2 id="summary">Summary</h2>
<p>This chapter extends linear regression to handle multiple predictor variables. Students will learn to build models with multiple features, understand and diagnose multicollinearity, and apply various feature selection methods. The chapter covers handling categorical variables through dummy variables and one-hot encoding, creating interaction terms, and understanding feature importance. By the end of this chapter, students will be able to build and interpret multiple regression models with both numerical and categorical predictors.</p>
<h2 id="concepts-covered">Concepts Covered</h2>
<p>This chapter covers the following 15 concepts from the learning graph:</p>
<ol>
<li>Multiple Linear Regression</li>
<li>Multiple Predictors</li>
<li>Multicollinearity</li>
<li>Variance Inflation Factor</li>
<li>Feature Selection</li>
<li>Forward Selection</li>
<li>Backward Elimination</li>
<li>Stepwise Selection</li>
<li>Categorical Variables</li>
<li>Dummy Variables</li>
<li>One-Hot Encoding</li>
<li>Interaction Terms</li>
<li>Polynomial Features</li>
<li>Feature Engineering</li>
<li>Feature Importance</li>
</ol>
<h2 id="prerequisites">Prerequisites</h2>
<p>This chapter builds on concepts from:</p>
<ul>
<li><a href="../07-simple-linear-regression/">Chapter 7: Simple Linear Regression</a></li>
<li><a href="../08-model-evaluation/">Chapter 8: Model Evaluation and Validation</a></li>
</ul>
<hr />
<h2 id="introduction-leveling-up-your-prediction-powers">Introduction: Leveling Up Your Prediction Powers</h2>
<p>In the last few chapters, you learned to predict outcomes using a single feature. That's like trying to predict someone's basketball skills by only looking at their height. Sure, height matters, but what about their practice hours, speed, and jumping ability? Real-world predictions almost always depend on <em>multiple</em> factors working together.</p>
<p><strong>Multiple linear regression</strong> is your superpower upgrade. Instead of drawing a line through 2D data, you're now fitting a <em>hyperplane</em> through multi-dimensional space. Don't worry if that sounds intimidating—the math is surprisingly similar to what you already know, and scikit-learn handles the heavy lifting. Your job is to understand what the model is doing and how to use it wisely.</p>
<p>By the end of this chapter, you'll be able to build models that consider dozens of features simultaneously, handle both numbers and categories, and identify which features actually matter. That's serious prediction power.</p>
<h2 id="from-one-feature-to-many-multiple-predictors">From One Feature to Many: Multiple Predictors</h2>
<p>In simple linear regression, we had one predictor variable <span class="arithmatex">\(x\)</span> and one target <span class="arithmatex">\(y\)</span>:</p>
<div class="arithmatex">\[y = \beta_0 + \beta_1 x\]</div>
<p>With <strong>multiple linear regression</strong>, we have multiple predictors—let's call them <span class="arithmatex">\(x_1, x_2, x_3\)</span>, and so on:</p>
<div class="arithmatex">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + ... + \beta_p x_p\]</div>
<p>Each <span class="arithmatex">\(\beta\)</span> coefficient tells you how much <span class="arithmatex">\(y\)</span> changes when that specific <span class="arithmatex">\(x\)</span> increases by one unit, <em>holding all other variables constant</em>. That last part is crucial—it's what makes multiple regression so powerful. You can isolate the effect of each feature.</p>
<p>Here's a concrete example. Suppose you're predicting house prices with three features:</p>
<ul>
<li><span class="arithmatex">\(x_1\)</span> = square footage</li>
<li><span class="arithmatex">\(x_2\)</span> = number of bedrooms</li>
<li><span class="arithmatex">\(x_3\)</span> = age of house (years)</li>
</ul>
<p>Your model might look like:</p>
<div class="arithmatex">\[\text{Price} = 50000 + 150 \times \text{SqFt} + 10000 \times \text{Bedrooms} - 1000 \times \text{Age}\]</div>
<p>This tells you:</p>
<ul>
<li>Base price is $50,000</li>
<li>Each square foot adds $150</li>
<li>Each bedroom adds $10,000</li>
<li>Each year of age <em>subtracts</em> $1,000</li>
</ul>
<p>The negative coefficient for age makes sense—older houses typically sell for less, all else being equal.</p>
<h2 id="building-your-first-multiple-regression-model">Building Your First Multiple Regression Model</h2>
<p>Let's build a multiple regression model in Python. The process is almost identical to simple regression—scikit-learn handles the complexity behind the scenes.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>

<span class="c1"># Load housing data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;housing.csv&#39;</span><span class="p">)</span>

<span class="c1"># Select multiple features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;square_feet&#39;</span><span class="p">,</span> <span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;bathrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;lot_size&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>

<span class="c1"># Split the data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Create and train the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># View the coefficients</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Intercept:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>The output shows you how each feature contributes to the prediction. Positive coefficients increase the predicted price; negative ones decrease it.</p>
<h4 id="diagram-multiple-regression-anatomy">Diagram: Multiple Regression Anatomy</h4>
<details>
<summary>Multiple Regression Anatomy</summary>
<p>Type: infographic</p>
<p>Bloom Taxonomy: Understand</p>
<p>Learning Objective: Help students visualize how multiple features combine to form a single prediction, understanding each coefficient's role</p>
<p>Layout: Central equation with branching explanations for each component</p>
<p>Visual Elements:
- Large central equation: y = β₀ + β₁x₁ + β₂x₂ + β₃x₃
- Each term has an arrow pointing to an explanation box
- β₀ box: "Starting point (intercept) - prediction when all features are zero"
- Each βᵢxᵢ box: shows feature name, coefficient value, and contribution
- Final prediction shown as sum of all contributions with animated addition</p>
<p>Interactive Elements:
- Hover over each term to see its specific contribution
- Slider for each feature value (x₁, x₂, x₃)
- As sliders move, show each term's contribution updating
- Final prediction updates in real-time as sum of all terms
- Color coding: positive contributions in green, negative in red</p>
<p>Example Data:
- House price prediction with square_feet, bedrooms, age
- Show specific numbers: 150 × 1500 sqft = $225,000 contribution</p>
<p>Color Scheme:
- Intercept: Blue
- Positive coefficients: Green gradient
- Negative coefficients: Red gradient
- Final prediction: Gold</p>
<p>Implementation: HTML/CSS/JavaScript with interactive sliders</p>
</details>
<h2 id="interpreting-multiple-regression-coefficients">Interpreting Multiple Regression Coefficients</h2>
<p>Each coefficient in multiple regression has a specific interpretation: it tells you the expected change in <span class="arithmatex">\(y\)</span> for a one-unit increase in that feature, <strong>while holding all other features constant</strong>. This "all else being equal" interpretation is what makes multiple regression so valuable.</p>
<p>Let's examine our model's coefficients:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>

<span class="c1"># Create coefficient visualization</span>
<span class="n">coef_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
    <span class="s1">&#39;Coefficient&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
<span class="p">})</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
    <span class="n">coef_df</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Feature Coefficients: Impact on House Price&#39;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span>
    <span class="n">color_continuous_scale</span><span class="o">=</span><span class="s1">&#39;RdYlGn&#39;</span><span class="p">,</span>
    <span class="n">color_continuous_midpoint</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p>A few important caveats about interpreting coefficients:</p>
<table>
<thead>
<tr>
<th>Consideration</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scale differences</td>
<td>A coefficient of 100 for square feet isn't comparable to 10,000 for bedrooms—units differ</td>
</tr>
<tr>
<td>Correlation between features</td>
<td>If bedrooms and square feet are correlated, their individual effects are harder to isolate</td>
</tr>
<tr>
<td>Non-linear relationships</td>
<td>Coefficients assume linear effects; reality might be curved</td>
</tr>
<tr>
<td>Categorical variables</td>
<td>Need special handling (we'll cover this soon)</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Standardizing for Fair Comparison</p>
<p>To compare coefficient magnitudes fairly, standardize your features first (subtract mean, divide by standard deviation). Then coefficients represent "effect of one standard deviation change" and are directly comparable.</p>
</div>
<h2 id="the-multicollinearity-problem">The Multicollinearity Problem</h2>
<p>Here's a tricky situation: what happens when your predictor variables are highly correlated with each other? This is called <strong>multicollinearity</strong>, and it can cause serious problems for your model.</p>
<p>Imagine predicting house prices with both "square feet" and "number of rooms." These features are strongly related—bigger houses have more rooms. When features are correlated:</p>
<ul>
<li>Coefficients become unstable (small data changes cause big coefficient swings)</li>
<li>Standard errors inflate, making significance tests unreliable</li>
<li>Individual feature effects become hard to interpret</li>
<li>The model might still predict well overall, but you can't trust individual coefficients</li>
</ul>
<p>Think of it like two people trying to push a car together at the exact same angle. You can see the car moved, but you can't tell who pushed harder—their efforts are indistinguishable.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Check for correlations between features</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">plotly.figure_factory</span> <span class="k">as</span> <span class="nn">ff</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">ff</span><span class="o">.</span><span class="n">create_annotated_heatmap</span><span class="p">(</span>
    <span class="n">z</span><span class="o">=</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
    <span class="n">y</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">index</span><span class="p">),</span>
    <span class="n">colorscale</span><span class="o">=</span><span class="s1">&#39;RdBu&#39;</span><span class="p">,</span>
    <span class="n">zmid</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Feature Correlation Matrix&#39;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p>Look for correlations above 0.7 or below -0.7—these pairs of features might cause multicollinearity issues.</p>
<h2 id="variance-inflation-factor-quantifying-multicollinearity">Variance Inflation Factor: Quantifying Multicollinearity</h2>
<p>The <strong>Variance Inflation Factor (VIF)</strong> is a precise way to measure multicollinearity. It tells you how much the variance of a coefficient is inflated due to correlations with other predictors.</p>
<ul>
<li>VIF = 1: No correlation with other features (ideal)</li>
<li>VIF = 1-5: Moderate correlation (usually acceptable)</li>
<li>VIF &gt; 5: High correlation (concerning)</li>
<li>VIF &gt; 10: Severe multicollinearity (definitely a problem)</li>
</ul>
<p>Here's how to calculate VIF for each feature:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>

<span class="c1"># Calculate VIF for each feature</span>
<span class="n">vif_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">vif_data</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>
<span class="n">vif_data</span><span class="p">[</span><span class="s1">&#39;VIF&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vif_data</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;VIF&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
<p>If you find high VIF values, you have options:</p>
<ul>
<li>Remove one of the correlated features</li>
<li>Combine correlated features into a single composite feature</li>
<li>Use regularization techniques (covered in a later chapter)</li>
<li>Accept that individual coefficients may be unreliable, but overall predictions are fine</li>
</ul>
<h4 id="diagram-multicollinearity-detector-microsim">Diagram: Multicollinearity Detector MicroSim</h4>
<details>
<summary>Multicollinearity Detector MicroSim</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Analyze, Evaluate</p>
<p>Learning Objective: Help students understand how correlated features affect coefficient stability and learn to diagnose multicollinearity using VIF</p>
<p>Canvas Layout (850x500):
- Left panel (400x500): Scatter plot matrix showing feature correlations
- Right panel (450x500): VIF display and coefficient stability visualization</p>
<p>Left Panel Elements:
- 3x3 scatter plot matrix for selected features
- Correlation coefficients displayed on off-diagonal
- Color intensity indicates correlation strength
- Clickable to focus on any pair</p>
<p>Right Panel Elements:
- Bar chart of VIF values for all features
- Color coding: Green (&lt;5), Yellow (5-10), Red (&gt;10)
- Below: Coefficient confidence intervals that widen with higher VIF
- Warning messages for problematic features</p>
<p>Interactive Controls:
- Dropdown: Select dataset (housing, cars, student performance)
- Checkbox: Add highly correlated feature (to demonstrate VIF increase)
- Button: "Simulate 100 data samples" - shows coefficient variation
- Slider: Artificially adjust correlation between two features</p>
<p>Key Demonstrations:
- Watch VIF spike when adding a correlated feature
- See coefficient confidence intervals widen with high VIF
- Observe coefficient values fluctuate wildly when resampling with multicollinearity</p>
<p>Implementation: p5.js with statistical calculations</p>
</details>
<h2 id="feature-selection-choosing-the-right-variables">Feature Selection: Choosing the Right Variables</h2>
<p>Not every available feature belongs in your model. <strong>Feature selection</strong> is the art and science of choosing which variables to include. Too few features, and you underfit. Too many, and you risk overfitting and multicollinearity.</p>
<p>There are three classic approaches to feature selection:</p>
<h3 id="forward-selection">Forward Selection</h3>
<p><strong>Forward selection</strong> starts with no features and adds them one at a time. At each step, you add the feature that most improves the model, until no remaining feature provides significant improvement.</p>
<p>The process:</p>
<ol>
<li>Start with an empty model (intercept only)</li>
<li>Try adding each remaining feature one at a time</li>
<li>Keep the one that gives the biggest improvement (if significant)</li>
<li>Repeat until no feature improves the model enough</li>
</ol>
<h3 id="backward-elimination">Backward Elimination</h3>
<p><strong>Backward elimination</strong> works in reverse. Start with all features and remove the least useful ones:</p>
<ol>
<li>Start with all features in the model</li>
<li>Find the feature with the smallest contribution (highest p-value or lowest impact)</li>
<li>Remove it if it's below your threshold</li>
<li>Repeat until all remaining features are significant</li>
</ol>
<h3 id="stepwise-selection">Stepwise Selection</h3>
<p><strong>Stepwise selection</strong> combines both approaches. At each step, you can either add a feature or remove one, depending on which action most improves the model. This flexibility helps find combinations that neither forward nor backward selection would discover alone.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Simple implementation of forward selection using cross-validation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="k">def</span> <span class="nf">forward_selection</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">remaining</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">max_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining</span><span class="p">)</span>

    <span class="k">while</span> <span class="n">remaining</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_features</span><span class="p">:</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">best_feature</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">remaining</span><span class="p">:</span>
            <span class="n">current_features</span> <span class="o">=</span> <span class="n">selected</span> <span class="o">+</span> <span class="p">[</span><span class="n">feature</span><span class="p">]</span>
            <span class="n">X_subset</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">current_features</span><span class="p">]</span>

            <span class="c1"># Use cross-validation to evaluate</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
                <span class="n">LinearRegression</span><span class="p">(),</span> <span class="n">X_subset</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span>
            <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
                <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
                <span class="n">best_feature</span> <span class="o">=</span> <span class="n">feature</span>

        <span class="k">if</span> <span class="n">best_feature</span><span class="p">:</span>
            <span class="n">selected</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_feature</span><span class="p">)</span>
            <span class="n">remaining</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">best_feature</span><span class="p">)</span>
            <span class="n">best_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_score</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">best_feature</span><span class="si">}</span><span class="s2">: CV R² = </span><span class="si">{</span><span class="n">best_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">selected</span><span class="p">,</span> <span class="n">best_scores</span>

<span class="c1"># Run forward selection</span>
<span class="n">selected_features</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">forward_selection</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<table>
<thead>
<tr>
<th>Method</th>
<th>Starts With</th>
<th>Action</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td>Forward Selection</td>
<td>No features</td>
<td>Adds best one at a time</td>
<td>Many features, few are relevant</td>
</tr>
<tr>
<td>Backward Elimination</td>
<td>All features</td>
<td>Removes worst one at a time</td>
<td>Fewer features, most are useful</td>
</tr>
<tr>
<td>Stepwise Selection</td>
<td>Any starting point</td>
<td>Adds or removes each step</td>
<td>Complex relationships</td>
</tr>
</tbody>
</table>
<h4 id="diagram-feature-selection-race">Diagram: Feature Selection Race</h4>
<details>
<summary>Feature Selection Race</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Apply, Analyze</p>
<p>Learning Objective: Visualize and compare different feature selection strategies, understanding how each method builds or prunes the feature set</p>
<p>Canvas Layout (800x550):
- Top area (800x400): Three parallel "race tracks" for each method
- Bottom area (800x150): Results comparison table</p>
<p>Race Track Elements:
- Each track shows features as checkpoints
- Forward: Start empty, light up features as added
- Backward: Start full, dim features as removed
- Stepwise: Show both add and remove actions
- Current model score displayed at each step</p>
<p>Interactive Controls:
- Button: "Start Race" - animate all three methods simultaneously
- Speed slider: Control animation speed
- Dropdown: Select dataset
- Checkbox: "Show R² at each step"
- Button: "Compare Final Models"</p>
<p>Animation:
- Features light up (added) or dim (removed) as methods progress
- Score counter updates at each step
- Pause at each step to show decision being made
- Highlight which feature is being considered</p>
<p>Results Comparison:
- Table showing: Method, Features Selected, Final R², Time
- Visual indicator of which method "won" (best score)
- Discussion of when each method excels</p>
<p>Implementation: p5.js with step-by-step animation</p>
</details>
<h2 id="handling-categorical-variables">Handling Categorical Variables</h2>
<p>So far, we've only used numerical features. But what about <strong>categorical variables</strong> like neighborhood, car brand, or education level? These don't have a natural numeric ordering, so we can't just plug them into the equation.</p>
<p>The solution is to convert categories into numbers using <strong>dummy variables</strong> or <strong>one-hot encoding</strong>.</p>
<h3 id="dummy-variables">Dummy Variables</h3>
<p>A <strong>dummy variable</strong> is a binary (0 or 1) variable that represents whether an observation belongs to a category. For a categorical variable with <span class="arithmatex">\(k\)</span> categories, you create <span class="arithmatex">\(k-1\)</span> dummy variables.</p>
<p>Why <span class="arithmatex">\(k-1\)</span> instead of <span class="arithmatex">\(k\)</span>? Because the last category is implied when all dummies are 0. This avoids redundancy and multicollinearity.</p>
<p>Example: For "Neighborhood" with three values (Downtown, Suburbs, Rural):</p>
<table>
<thead>
<tr>
<th>Observation</th>
<th>Neighborhood</th>
<th>Is_Downtown</th>
<th>Is_Suburbs</th>
</tr>
</thead>
<tbody>
<tr>
<td>House 1</td>
<td>Downtown</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>House 2</td>
<td>Suburbs</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>House 3</td>
<td>Rural</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>House 4</td>
<td>Downtown</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Notice that Rural is the "reference category"—it's represented by zeros in both columns.</p>
<h3 id="one-hot-encoding">One-Hot Encoding</h3>
<p><strong>One-hot encoding</strong> creates <span class="arithmatex">\(k\)</span> dummy variables (one for each category). While this seems simpler, it creates redundancy that must be handled. Most libraries automatically drop one category to prevent issues.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Method 1: pd.get_dummies (creates one-hot encoding)</span>
<span class="n">df_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;neighborhood&#39;</span><span class="p">],</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Method 2: Using scikit-learn&#39;s OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>

<span class="c1"># Create preprocessor</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;neighborhood&#39;</span><span class="p">,</span> <span class="s1">&#39;style&#39;</span><span class="p">]</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;square_feet&#39;</span><span class="p">,</span> <span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">]</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="s1">&#39;passthrough&#39;</span><span class="p">,</span> <span class="n">numerical_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">),</span> <span class="n">categorical_features</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Fit and transform</span>
<span class="n">X_processed</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="diagram-one-hot-encoding-visualizer">Diagram: One-Hot Encoding Visualizer</h4>
<details>
<summary>One-Hot Encoding Visualizer</summary>
<p>Type: infographic</p>
<p>Bloom Taxonomy: Understand, Apply</p>
<p>Learning Objective: Demonstrate how categorical variables are transformed into numerical format through one-hot encoding</p>
<p>Layout: Before/After transformation with animated conversion</p>
<p>Visual Elements:
- Left side: Original categorical column with color-coded categories
- Right side: Multiple binary columns (one per category)
- Animated arrows showing the transformation
- Each row clearly shows which column gets the "1"</p>
<p>Example Data:
- Categorical column: Color (Red, Blue, Green, Red, Blue)
- Transforms to: Is_Red, Is_Blue, Is_Green columns
- Shows both "keep all" and "drop first" options</p>
<p>Interactive Elements:
- Dropdown: Select different categorical variables to encode
- Toggle: "Drop first category" vs "Keep all categories"
- Hover: Highlight corresponding cells in original and encoded view
- Button: "Add new category" - shows a new column appears
- Slider: Adjust number of unique categories (2-8) to see encoding grow</p>
<p>Educational Callouts:
- Warning when all categories kept: "This creates multicollinearity!"
- Explanation of reference category concept
- Formula showing how original is reconstructed</p>
<p>Color Scheme:
- Each category has unique color
- Same colors used in binary columns for matching</p>
<p>Implementation: HTML/CSS/JavaScript with smooth animations</p>
</details>
<h2 id="interaction-terms-when-features-work-together">Interaction Terms: When Features Work Together</h2>
<p>Sometimes the effect of one feature depends on the value of another. For example, the value of a swimming pool might depend on whether the house is in a warm or cold climate. A pool adds more value in Arizona than in Alaska!</p>
<p><strong>Interaction terms</strong> capture these combined effects by multiplying features together:</p>
<div class="arithmatex">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 (x_1 \times x_2)\]</div>
<p>The interaction term <span class="arithmatex">\(x_1 \times x_2\)</span> allows the effect of <span class="arithmatex">\(x_1\)</span> to change depending on the value of <span class="arithmatex">\(x_2\)</span> (and vice versa).</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="c1"># Create interaction terms (degree=2, no squared terms)</span>
<span class="n">interaction</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X_with_interactions</span> <span class="o">=</span> <span class="n">interaction</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># See the new feature names</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">interaction</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Features with interactions:&quot;</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>When to consider interactions:</p>
<ul>
<li>Domain knowledge suggests features work together</li>
<li>Residual plots show patterns when you split by another variable</li>
<li>Theory indicates multiplicative effects</li>
<li>You have enough data to estimate additional parameters</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Interaction Explosion</p>
<p>With many features, the number of possible interactions explodes. Five features have 10 pairwise interactions. Ten features have 45. Only include interactions you have good reason to suspect exist, or use regularization to prevent overfitting.</p>
</div>
<h2 id="polynomial-features-capturing-curved-relationships">Polynomial Features: Capturing Curved Relationships</h2>
<p>Remember from simple regression that relationships aren't always linear? <strong>Polynomial features</strong> extend multiple regression to handle curved relationships by including squared, cubed, or higher-order terms.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Create polynomial features of degree 2</span>
<span class="n">poly_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">poly_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate</span>
<span class="n">train_score</span> <span class="o">=</span> <span class="n">poly_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">poly_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train R²: </span><span class="si">{</span><span class="n">train_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test R²: </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>With polynomial features of degree 2 on 5 original features, you get:</p>
<ul>
<li>5 original features</li>
<li>5 squared terms (x₁², x₂², ...)</li>
<li>10 interaction terms (x₁x₂, x₁x₃, ...)</li>
<li>Total: 20 features!</li>
</ul>
<p>This is powerful but dangerous. Watch your test score carefully—it's easy to overfit with high-degree polynomials.</p>
<h2 id="feature-engineering-the-art-of-creating-better-features">Feature Engineering: The Art of Creating Better Features</h2>
<p><strong>Feature engineering</strong> is the creative process of transforming raw data into features that better represent the underlying problem. This is often where data scientists add the most value—domain knowledge transformed into predictive power.</p>
<p>Common feature engineering techniques:</p>
<table>
<thead>
<tr>
<th>Technique</th>
<th>Example</th>
<th>Why It Helps</th>
</tr>
</thead>
<tbody>
<tr>
<td>Log transform</td>
<td>log(income)</td>
<td>Handles skewed distributions</td>
</tr>
<tr>
<td>Binning</td>
<td>Age groups (20s, 30s, 40s)</td>
<td>Captures non-linear thresholds</td>
</tr>
<tr>
<td>Date extraction</td>
<td>Day of week from timestamp</td>
<td>Captures cyclical patterns</td>
</tr>
<tr>
<td>Ratios</td>
<td>Price per square foot</td>
<td>Normalizes for size</td>
</tr>
<tr>
<td>Aggregations</td>
<td>Average neighborhood price</td>
<td>Incorporates context</td>
</tr>
<tr>
<td>Domain calculations</td>
<td>BMI from height and weight</td>
<td>Captures known relationships</td>
</tr>
</tbody>
</table>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Feature engineering examples</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;price_per_sqft&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;square_feet&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;age_squared&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;log_lot_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;lot_size&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># +1 to handle zeros</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;rooms_per_bathroom&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_new&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>Good feature engineering requires:</p>
<ul>
<li>Understanding your domain</li>
<li>Exploring the data thoroughly</li>
<li>Creativity and experimentation</li>
<li>Validation to confirm new features actually help</li>
</ul>
<h4 id="diagram-feature-engineering-laboratory">Diagram: Feature Engineering Laboratory</h4>
<details>
<summary>Feature Engineering Laboratory</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Create, Apply</p>
<p>Learning Objective: Practice creating new features and immediately see their impact on model performance</p>
<p>Canvas Layout (900x550):
- Left panel (350x550): Feature creation interface
- Center panel (350x550): Data preview with new features
- Right panel (200x550): Model performance metrics</p>
<p>Left Panel - Feature Creation:
- Dropdown: Select first variable
- Dropdown: Select operation (+, -, *, /, log, square, bin)
- Dropdown: Select second variable (if applicable)
- Text input: New feature name
- Button: "Create Feature"
- List of created features with delete option</p>
<p>Center Panel - Data Preview:
- Table showing original and engineered features
- First 10 rows of data
- Histogram of new feature distribution
- Correlation of new feature with target</p>
<p>Right Panel - Performance:
- R² score (updates when features change)
- Train vs Test comparison
- Feature importance ranking
- Delta from baseline (how much new features helped)</p>
<p>Interactive Workflow:
1. View baseline model performance
2. Create a new feature
3. See immediate impact on R²
4. Try different transformations
5. Compare which features help most</p>
<p>Preset Examples:
- Button: "Try log transform on skewed feature"
- Button: "Create ratio feature"
- Button: "Add polynomial term"</p>
<p>Implementation: p5.js with real-time model retraining</p>
</details>
<h2 id="feature-importance-understanding-what-matters">Feature Importance: Understanding What Matters</h2>
<p>After building a model with many features, you'll want to know which ones are actually important. <strong>Feature importance</strong> measures how much each feature contributes to predictions.</p>
<p>Several approaches to measure importance:</p>
<h3 id="coefficient-magnitude-after-standardization">Coefficient Magnitude (After Standardization)</h3>
<p>When features are standardized, coefficient magnitude indicates relative importance:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># Standardize features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Fit model on standardized data</span>
<span class="n">model_scaled</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model_scaled</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compare coefficient magnitudes</span>
<span class="n">importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
    <span class="s1">&#39;Coefficient&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model_scaled</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">importance_df</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="permutation-importance">Permutation Importance</h3>
<p><strong>Permutation importance</strong> measures how much the model's performance drops when you randomly shuffle one feature's values. A big drop means the feature was important:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>

<span class="c1"># Calculate permutation importance</span>
<span class="n">perm_importance</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Create importance dataframe</span>
<span class="n">importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
    <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">perm_importance</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">,</span>
    <span class="s1">&#39;Std&#39;</span><span class="p">:</span> <span class="n">perm_importance</span><span class="o">.</span><span class="n">importances_std</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Visualize with Plotly</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
    <span class="n">importance_df</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Importance&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span>
    <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">,</span>
    <span class="n">error_x</span><span class="o">=</span><span class="s1">&#39;Std&#39;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Permutation Feature Importance&#39;</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">yaxis</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;categoryorder&#39;</span><span class="p">:</span> <span class="s1">&#39;total ascending&#39;</span><span class="p">})</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p>Permutation importance has advantages:</p>
<ul>
<li>Works for any model, not just linear regression</li>
<li>Captures importance in context of other features</li>
<li>Accounts for interactions</li>
</ul>
<h4 id="diagram-feature-importance-explorer">Diagram: Feature Importance Explorer</h4>
<details>
<summary>Feature Importance Explorer</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Analyze, Evaluate</p>
<p>Learning Objective: Compare different methods of measuring feature importance and understand their trade-offs</p>
<p>Canvas Layout (800x500):
- Left panel (400x500): Importance comparison chart
- Right panel (400x500): Individual feature deep-dive</p>
<p>Left Panel Elements:
- Three parallel horizontal bar charts stacked vertically:
  1. Coefficient magnitude (standardized)
  2. Permutation importance
  3. Drop-column importance (R² drop when feature removed)
- Features aligned across all three charts for easy comparison
- Color coding shows agreement/disagreement between methods</p>
<p>Right Panel - Feature Deep-Dive:
- Select a feature to explore in detail
- Scatter plot: feature vs target
- Partial dependence plot
- Distribution of feature values
- Interaction effects with other top features</p>
<p>Interactive Controls:
- Dropdown: Select which importance method to highlight
- Click on feature bar to see deep-dive in right panel
- Toggle: Show error bars (std across iterations)
- Button: "Run permutation test" (animated shuffling)</p>
<p>Visual Insights:
- Highlight when methods disagree about importance ranking
- Show confidence intervals for permutation importance
- Indicate which features might be redundant (similar importance patterns)</p>
<p>Implementation: p5.js with multiple visualization modes</p>
</details>
<h2 id="putting-it-all-together-a-complete-multiple-regression-workflow">Putting It All Together: A Complete Multiple Regression Workflow</h2>
<p>Here's a complete workflow for building a multiple regression model with all the techniques we've learned:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>

<span class="c1"># 1. Load and explore data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;housing.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Identify feature types</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;square_feet&#39;</span><span class="p">,</span> <span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;bathrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;lot_size&#39;</span><span class="p">]</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;neighborhood&#39;</span><span class="p">,</span> <span class="s1">&#39;style&#39;</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;price&#39;</span>

<span class="c1"># 3. Create feature engineering</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;price_per_sqft&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;square_feet&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;age_squared&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span>

<span class="c1"># Update feature list</span>
<span class="n">numerical_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;age_squared&#39;</span><span class="p">)</span>

<span class="c1"># 4. Split data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">numerical_features</span> <span class="o">+</span> <span class="n">categorical_features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 5. Create preprocessing pipeline</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">numerical_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">sparse_output</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">categorical_features</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># 6. Create full pipeline</span>
<span class="n">model_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;regressor&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># 7. Train and evaluate with cross-validation</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CV R² scores: </span><span class="si">{</span><span class="n">cv_scores</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean CV R²: </span><span class="si">{</span><span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="n">cv_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">*</span><span class="mi">2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="c1"># 8. Fit final model and evaluate on test set</span>
<span class="n">model_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">model_pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test R²: </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 9. Check for multicollinearity in numerical features</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>

<span class="n">X_num</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">numerical_features</span><span class="p">]</span>
<span class="n">vif_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">numerical_features</span><span class="p">,</span>
    <span class="s1">&#39;VIF&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X_num</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">numerical_features</span><span class="p">))]</span>
<span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">VIF values:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vif_data</span><span class="p">)</span>

<span class="c1"># 10. Visualize predictions vs actuals</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="s1">&#39;Actual Price&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="s1">&#39;Predicted Price&#39;</span><span class="p">},</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Multiple Regression: Actual vs Predicted&#39;</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_shape</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x1</span><span class="o">=</span><span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
              <span class="n">y0</span><span class="o">=</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y1</span><span class="o">=</span><span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
              <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">dash</span><span class="o">=</span><span class="s1">&#39;dash&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="diagram-multiple-regression-pipeline">Diagram: Multiple Regression Pipeline</h4>
<details>
<summary>Multiple Regression Pipeline</summary>
<p>Type: workflow</p>
<p>Bloom Taxonomy: Apply, Analyze</p>
<p>Learning Objective: Understand the complete workflow for building production-ready multiple regression models</p>
<p>Visual Style: Horizontal flowchart with data transformation stages</p>
<p>Stages:
1. "Raw Data"
   Hover: "Mixed types: numbers, categories, missing values"
   Icon: Database
   Color: Gray</p>
<ol>
<li>
<p>"Feature Engineering"
   Hover: "Create new features: ratios, transformations, domain knowledge"
   Icon: Wrench
   Color: Blue
   Sub-items: log transforms, ratios, polynomials</p>
</li>
<li>
<p>"Train/Test Split"
   Hover: "80/20 split before any preprocessing"
   Icon: Scissors
   Color: Purple</p>
</li>
<li>
<p>"Preprocessing"
   Hover: "Scale numerics, encode categoricals"
   Icon: Filter
   Color: Orange
   Sub-items: StandardScaler, OneHotEncoder</p>
</li>
<li>
<p>"Check Multicollinearity"
   Hover: "Calculate VIF, handle correlated features"
   Icon: Warning
   Color: Yellow</p>
</li>
<li>
<p>"Feature Selection"
   Hover: "Forward, backward, or stepwise selection"
   Icon: Checkboxes
   Color: Teal</p>
</li>
<li>
<p>"Model Training"
   Hover: "Fit LinearRegression on training data"
   Icon: Brain
   Color: Green</p>
</li>
<li>
<p>"Cross-Validation"
   Hover: "Get stable performance estimate"
   Icon: Loop
   Color: Blue</p>
</li>
<li>
<p>"Final Evaluation"
   Hover: "Test set performance, residual analysis"
   Icon: Chart
   Color: Red</p>
</li>
<li>
<p>"Feature Importance"
    Hover: "Understand what drives predictions"
    Icon: Bar Chart
    Color: Gold</p>
</li>
</ol>
<p>Data Flow Arrows:
- Show data shape changing at each stage
- Indicate sample counts at train/test split
- Show feature counts growing (engineering) and shrinking (selection)</p>
<p>Interactive Elements:
- Click each stage for expanded view
- Hover shows common pitfalls at each stage
- Toggle to show "what can go wrong" warnings</p>
<p>Implementation: HTML/CSS/JavaScript with click interactions</p>
</details>
<h2 id="common-mistakes-to-avoid">Common Mistakes to Avoid</h2>
<p>As you build multiple regression models, watch out for these pitfalls:</p>
<p><strong>Including Too Many Features</strong>: More features don't always mean better models. Each feature adds complexity and potential for overfitting. Start simple and add features only when they demonstrably help.</p>
<p><strong>Ignoring Multicollinearity</strong>: High VIF values don't break your model, but they make coefficient interpretation unreliable. If you need to explain what each feature does, address multicollinearity first.</p>
<p><strong>Forgetting to Encode Categoricals</strong>: Passing string columns directly to scikit-learn causes errors. Always one-hot encode or use a proper preprocessor.</p>
<p><strong>Data Leakage in Preprocessing</strong>: Fit your scaler and encoder only on training data, then transform both train and test. Using information from test data during preprocessing inflates your performance estimates.</p>
<p><strong>Overfitting with Interactions and Polynomials</strong>: Each interaction or polynomial term is an additional feature. With the power to add quadratic terms and interactions, it's easy to create dozens of features that overfit your training data.</p>
<div class="admonition tip">
<p class="admonition-title">The Simplicity Principle</p>
<p>If a simpler model performs almost as well as a complex one, choose the simpler model. It will be easier to explain, more robust to new data, and less likely to fail in production.</p>
</div>
<h2 id="summary-your-multiple-regression-toolkit">Summary: Your Multiple Regression Toolkit</h2>
<p>You now have a comprehensive toolkit for multiple regression:</p>
<ul>
<li><strong>Multiple predictors</strong> let you model complex, multi-factor relationships</li>
<li><strong>Multicollinearity</strong> and <strong>VIF</strong> help you diagnose problematic feature correlations</li>
<li><strong>Feature selection</strong> methods (forward, backward, stepwise) find the best feature subsets</li>
<li><strong>Dummy variables</strong> and <strong>one-hot encoding</strong> handle categorical features</li>
<li><strong>Interaction terms</strong> capture features that work together</li>
<li><strong>Polynomial features</strong> model curved relationships</li>
<li><strong>Feature engineering</strong> creates new predictive variables from domain knowledge</li>
<li><strong>Feature importance</strong> reveals what's driving your predictions</li>
</ul>
<p>With these tools, you can build models that capture the true complexity of real-world problems while remaining interpretable and reliable.</p>
<h2 id="looking-ahead">Looking Ahead</h2>
<p>In the next chapter, we'll explore NumPy in depth—the numerical computing engine that powers all of these calculations. Understanding NumPy will help you work more efficiently with large datasets and understand what's happening under the hood of scikit-learn.</p>
<hr />
<h2 id="key-takeaways">Key Takeaways</h2>
<ul>
<li>Multiple linear regression extends simple regression to handle any number of features</li>
<li>Each coefficient represents the effect of that feature while holding others constant</li>
<li>Multicollinearity occurs when features are correlated; use VIF to detect it</li>
<li>Feature selection methods help identify the most useful features</li>
<li>Categorical variables must be encoded as dummy variables before modeling</li>
<li>Interaction terms capture features that work together in non-additive ways</li>
<li>Feature engineering often provides more improvement than algorithm choice</li>
<li>Always validate with cross-validation and check residuals for patterns</li>
</ul>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../08-model-evaluation/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Model Evaluation">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Model Evaluation
              </div>
            </div>
          </a>
        
        
          
          <a href="../10-numpy-computing/" class="md-footer__link md-footer__link--next" aria-label="Next: NumPy Computing">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                NumPy Computing
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 Dan McCreary. Licensed under <a href="license/">CC BY-NC-SA 4.0</a> for non-commercial use.
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.expand", "navigation.path", "navigation.prune", "navigation.indexes", "toc.follow", "navigation.top", "navigation.footer", "content.action.edit"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>