
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An online course on introduction to data science with Python.  Extensive use of AI tools and MicroSims to help you learn.">
      
      
        <meta name="author" content="Dan McCreary">
      
      
        <link rel="canonical" href="https://dmccreary.github.io/data-science-course/chapters/08-model-evaluation/">
      
      
        <link rel="prev" href="../07-simple-linear-regression/">
      
      
        <link rel="next" href="../09-multiple-linear-regression/">
      
      
      <link rel="icon" href="../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.43">
    
    
      
        <title>Model Evaluation - AI Based Data Science with Python</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-RTBCWGJKKR"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-RTBCWGJKKR",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-RTBCWGJKKR",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Model Evaluation - AI Based Data Science with Python" >
      
        <meta  property="og:description"  content="An online course on introduction to data science with Python.  Extensive use of AI tools and MicroSims to help you learn." >
      
        <meta  property="og:image"  content="https://dmccreary.github.io/data-science-course/assets/images/social/chapters/08-model-evaluation/index.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://dmccreary.github.io/data-science-course/chapters/08-model-evaluation/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Model Evaluation - AI Based Data Science with Python" >
      
        <meta  name="twitter:description"  content="An online course on introduction to data science with Python.  Extensive use of AI tools and MicroSims to help you learn." >
      
        <meta  name="twitter:image"  content="https://dmccreary.github.io/data-science-course/assets/images/social/chapters/08-model-evaluation/index.png" >
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model-evaluation-and-validation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="AI Based Data Science with Python" class="md-header__button md-logo" aria-label="AI Based Data Science with Python" data-md-component="logo">
      
  <img src="../../img/logo-192.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI Based Data Science with Python
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Model Evaluation
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/dmccreary/data-science-course" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub Repo
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="AI Based Data Science with Python" class="md-nav__button md-logo" aria-label="AI Based Data Science with Python" data-md-component="logo">
      
  <img src="../../img/logo-192.png" alt="logo">

    </a>
    AI Based Data Science with Python
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/dmccreary/data-science-course" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub Repo
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course-description/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Course Description
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Chapters
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Chapters
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-intro-to-data-science/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Data Science
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02-python-environment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Environment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-python-data-structures/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Data Structures
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-data-cleaning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Cleaning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-data-visualization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Visualization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-statistical-foundations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistical Foundations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-simple-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple Linear Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Model Evaluation
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Model Evaluation
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts Covered
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-the-reality-check-superpower" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: The Reality Check Superpower
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-problem-with-trusting-your-own-grades" class="md-nav__link">
    <span class="md-ellipsis">
      The Problem with Trusting Your Own Grades
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-data-and-testing-data-dividing-your-data-kingdom" class="md-nav__link">
    <span class="md-ellipsis">
      Training Data and Testing Data: Dividing Your Data Kingdom
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-train-test-split-your-first-defense-against-self-deception" class="md-nav__link">
    <span class="md-ellipsis">
      The Train-Test Split: Your First Defense Against Self-Deception
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Train-Test Split: Your First Defense Against Self-Deception">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-train-test-split-visualization" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Train-Test Split Visualization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#validation-data-the-third-kingdom" class="md-nav__link">
    <span class="md-ellipsis">
      Validation Data: The Third Kingdom
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#measuring-model-performance-the-metrics-that-matter" class="md-nav__link">
    <span class="md-ellipsis">
      Measuring Model Performance: The Metrics That Matter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Measuring Model Performance: The Metrics That Matter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-squared-the-explanation-score" class="md-nav__link">
    <span class="md-ellipsis">
      R-Squared: The Explanation Score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted-r-squared-the-honest-version" class="md-nav__link">
    <span class="md-ellipsis">
      Adjusted R-Squared: The Honest Version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-squared-error-the-average-squared-miss" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Squared Error: The Average Squared Miss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#root-mean-squared-error-mse-you-can-understand" class="md-nav__link">
    <span class="md-ellipsis">
      Root Mean Squared Error: MSE You Can Understand
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-absolute-error-the-simple-alternative" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Error: The Simple Alternative
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mean Absolute Error: The Simple Alternative">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-metrics-comparison-microsim" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Metrics Comparison MicroSim
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#calculating-metrics-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      Calculating Metrics in Python
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#residual-analysis-csi-data-science" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Analysis: CSI Data Science
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Residual Analysis: CSI Data Science">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-residual-pattern-detective" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Residual Pattern Detective
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-perils-of-overfitting-when-your-model-studies-too-hard" class="md-nav__link">
    <span class="md-ellipsis">
      The Perils of Overfitting: When Your Model Studies Too Hard
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-dangers-of-underfitting-when-your-model-doesnt-try-hard-enough" class="md-nav__link">
    <span class="md-ellipsis">
      The Dangers of Underfitting: When Your Model Doesn't Try Hard Enough
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-and-variance-the-fundamental-tradeoff" class="md-nav__link">
    <span class="md-ellipsis">
      Bias and Variance: The Fundamental Tradeoff
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Bias and Variance: The Fundamental Tradeoff">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-bias-variance-dartboard" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Bias-Variance Dartboard
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-complexity-the-goldilocks-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Model Complexity: The Goldilocks Problem
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Complexity: The Goldilocks Problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-complexity-curve-explorer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Complexity Curve Explorer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cross-validation-the-ultimate-fairness-test" class="md-nav__link">
    <span class="md-ellipsis">
      Cross-Validation: The Ultimate Fairness Test
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cross-Validation: The Ultimate Fairness Test">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-fold-cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      K-Fold Cross-Validation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="K-Fold Cross-Validation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-k-fold-cross-validation-animator" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: K-Fold Cross-Validation Animator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#leave-one-out-cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      Leave-One-Out Cross-Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-holdout-method" class="md-nav__link">
    <span class="md-ellipsis">
      The Holdout Method
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameters-the-settings-you-choose" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameters: The Settings You Choose
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-selection-and-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Model Selection and Comparison
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Selection and Comparison">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-model-selection-dashboard" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Model Selection Dashboard
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together-the-model-evaluation-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Putting It All Together: The Model Evaluation Workflow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Putting It All Together: The Model Evaluation Workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-model-evaluation-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Model Evaluation Workflow
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-pitfalls-and-how-to-avoid-them" class="md-nav__link">
    <span class="md-ellipsis">
      Common Pitfalls and How to Avoid Them
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-your-model-evaluation-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      Summary: Your Model Evaluation Toolkit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#looking-ahead" class="md-nav__link">
    <span class="md-ellipsis">
      Looking Ahead
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-multiple-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multiple Linear Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-numpy-computing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NumPy Computing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11-nonlinear-models-regularization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Non-linear Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12-intro-to-machine-learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Intro to Machine Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13-neural-networks-pytorch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neural Networks and PyTorch
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../chapters-v1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Old v1 Content
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../labs/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Labs
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
      
        
          
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../sims/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    MicroSims
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../learning-graph/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Learning Graph
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../prompts/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Sample GenAI Prompts
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frequently Asked Questions
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how-we-built-this-site/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How We Built This Site
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../checklist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customization Checklist
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../license/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    License
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    References
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../checklist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customization Checklist
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contact
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts Covered
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-the-reality-check-superpower" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: The Reality Check Superpower
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-problem-with-trusting-your-own-grades" class="md-nav__link">
    <span class="md-ellipsis">
      The Problem with Trusting Your Own Grades
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-data-and-testing-data-dividing-your-data-kingdom" class="md-nav__link">
    <span class="md-ellipsis">
      Training Data and Testing Data: Dividing Your Data Kingdom
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-train-test-split-your-first-defense-against-self-deception" class="md-nav__link">
    <span class="md-ellipsis">
      The Train-Test Split: Your First Defense Against Self-Deception
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Train-Test Split: Your First Defense Against Self-Deception">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-train-test-split-visualization" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Train-Test Split Visualization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#validation-data-the-third-kingdom" class="md-nav__link">
    <span class="md-ellipsis">
      Validation Data: The Third Kingdom
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#measuring-model-performance-the-metrics-that-matter" class="md-nav__link">
    <span class="md-ellipsis">
      Measuring Model Performance: The Metrics That Matter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Measuring Model Performance: The Metrics That Matter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-squared-the-explanation-score" class="md-nav__link">
    <span class="md-ellipsis">
      R-Squared: The Explanation Score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted-r-squared-the-honest-version" class="md-nav__link">
    <span class="md-ellipsis">
      Adjusted R-Squared: The Honest Version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-squared-error-the-average-squared-miss" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Squared Error: The Average Squared Miss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#root-mean-squared-error-mse-you-can-understand" class="md-nav__link">
    <span class="md-ellipsis">
      Root Mean Squared Error: MSE You Can Understand
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-absolute-error-the-simple-alternative" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Error: The Simple Alternative
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mean Absolute Error: The Simple Alternative">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-metrics-comparison-microsim" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Metrics Comparison MicroSim
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#calculating-metrics-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      Calculating Metrics in Python
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#residual-analysis-csi-data-science" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Analysis: CSI Data Science
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Residual Analysis: CSI Data Science">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-residual-pattern-detective" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Residual Pattern Detective
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-perils-of-overfitting-when-your-model-studies-too-hard" class="md-nav__link">
    <span class="md-ellipsis">
      The Perils of Overfitting: When Your Model Studies Too Hard
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-dangers-of-underfitting-when-your-model-doesnt-try-hard-enough" class="md-nav__link">
    <span class="md-ellipsis">
      The Dangers of Underfitting: When Your Model Doesn't Try Hard Enough
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-and-variance-the-fundamental-tradeoff" class="md-nav__link">
    <span class="md-ellipsis">
      Bias and Variance: The Fundamental Tradeoff
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Bias and Variance: The Fundamental Tradeoff">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-bias-variance-dartboard" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Bias-Variance Dartboard
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-complexity-the-goldilocks-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Model Complexity: The Goldilocks Problem
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Complexity: The Goldilocks Problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-complexity-curve-explorer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Complexity Curve Explorer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cross-validation-the-ultimate-fairness-test" class="md-nav__link">
    <span class="md-ellipsis">
      Cross-Validation: The Ultimate Fairness Test
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cross-Validation: The Ultimate Fairness Test">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-fold-cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      K-Fold Cross-Validation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="K-Fold Cross-Validation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-k-fold-cross-validation-animator" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: K-Fold Cross-Validation Animator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#leave-one-out-cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      Leave-One-Out Cross-Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-holdout-method" class="md-nav__link">
    <span class="md-ellipsis">
      The Holdout Method
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameters-the-settings-you-choose" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameters: The Settings You Choose
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-selection-and-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Model Selection and Comparison
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Selection and Comparison">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-model-selection-dashboard" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Model Selection Dashboard
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together-the-model-evaluation-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Putting It All Together: The Model Evaluation Workflow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Putting It All Together: The Model Evaluation Workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-model-evaluation-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Model Evaluation Workflow
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-pitfalls-and-how-to-avoid-them" class="md-nav__link">
    <span class="md-ellipsis">
      Common Pitfalls and How to Avoid Them
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-your-model-evaluation-toolkit" class="md-nav__link">
    <span class="md-ellipsis">
      Summary: Your Model Evaluation Toolkit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#looking-ahead" class="md-nav__link">
    <span class="md-ellipsis">
      Looking Ahead
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/dmccreary/data-science-course/blob/master/docs/chapters/08-model-evaluation/index.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="model-evaluation-and-validation">Model Evaluation and Validation</h1>
<hr />
<p>title: Model Evaluation and Validation
description: Learn to measure your model's true powers and avoid self-deception
generated_by: chapter-content-generator skill
date: 2025-12-15
version: 0.03</p>
<hr />
<h2 id="summary">Summary</h2>
<p>This chapter teaches students how to properly evaluate and validate machine learning models. Students will learn about training and testing data splits, key performance metrics (R-squared, MSE, RMSE, MAE), and residual analysis. The chapter covers the critical concepts of overfitting and underfitting, the bias-variance tradeoff, and various cross-validation techniques. By the end of this chapter, students will be able to assess model quality, compare different models, and select the best model for their data.</p>
<h2 id="concepts-covered">Concepts Covered</h2>
<p>This chapter covers the following 25 concepts from the learning graph:</p>
<ol>
<li>Model Performance</li>
<li>Training Data</li>
<li>Testing Data</li>
<li>Train Test Split</li>
<li>Validation Data</li>
<li>R-Squared</li>
<li>Adjusted R-Squared</li>
<li>Mean Squared Error</li>
<li>Root Mean Squared Error</li>
<li>Mean Absolute Error</li>
<li>Residual Analysis</li>
<li>Residual Plot</li>
<li>Overfitting</li>
<li>Underfitting</li>
<li>Bias</li>
<li>Variance</li>
<li>Bias-Variance Tradeoff</li>
<li>Model Complexity</li>
<li>Cross-Validation</li>
<li>K-Fold Cross-Validation</li>
<li>Leave One Out CV</li>
<li>Holdout Method</li>
<li>Model Selection</li>
<li>Hyperparameters</li>
<li>Model Comparison</li>
</ol>
<h2 id="prerequisites">Prerequisites</h2>
<p>This chapter builds on concepts from:</p>
<ul>
<li><a href="../06-statistical-foundations/">Chapter 6: Statistical Foundations</a></li>
<li><a href="../07-simple-linear-regression/">Chapter 7: Simple Linear Regression</a></li>
</ul>
<hr />
<h2 id="introduction-the-reality-check-superpower">Introduction: The Reality Check Superpower</h2>
<p>Congratulations! You've built your first predictive model. It can draw a line through data and make predictions about the future. That's genuinely impressive. But here's a question that separates the data science amateurs from the professionals: <strong>How do you know if your model is actually any good?</strong></p>
<p>Think about it this way. Imagine you have a friend who claims they can predict tomorrow's weather perfectly—because they just memorized all the weather from the past year. Ask them about last Tuesday's weather? Perfect answer. Ask them about <em>next</em> Tuesday? Complete disaster. They didn't learn weather patterns; they just memorized history.</p>
<p>This chapter gives you the superpower to see through this kind of self-deception. You'll learn to honestly evaluate whether your model has discovered genuine patterns or just memorized your data. This skill is crucial because in the real world, a model that looks amazing in training but fails in production is worse than useless—it gives you false confidence that leads to bad decisions.</p>
<h2 id="the-problem-with-trusting-your-own-grades">The Problem with Trusting Your Own Grades</h2>
<p>Let's start with a fundamental truth about <strong>model performance</strong>: you can't trust a model to grade its own homework. If you train a model on data and then test it on that same data, you're essentially asking, "Hey model, how well did you memorize what I showed you?" The answer will always be "Pretty darn well!" But memorization isn't learning.</p>
<p>Here's why this matters:</p>
<ul>
<li>A model that memorizes will score 100% on data it has seen</li>
<li>That same model might score 40% on new data</li>
<li>You need to know the <em>real</em> performance before deploying your model</li>
<li>Real-world predictions always involve data the model hasn't seen</li>
</ul>
<p>This is why we need to be clever about how we evaluate our models. We need to simulate the real world—where predictions are made on never-before-seen data—while still using the limited data we have.</p>
<h2 id="training-data-and-testing-data-dividing-your-data-kingdom">Training Data and Testing Data: Dividing Your Data Kingdom</h2>
<p>The solution to the self-grading problem is beautifully simple: split your data into two kingdoms. One kingdom is for <strong>training</strong>—teaching the model. The other is for <strong>testing</strong>—evaluating the model honestly.</p>
<p><strong>Training data</strong> is the portion of your dataset that your model gets to learn from. This is the data that the model uses to find patterns, calculate coefficients, and tune its parameters. Think of training data as the textbook the model studies from.</p>
<p><strong>Testing data</strong> is the portion you hide from the model during training. It's the "final exam" that the model has never seen before. When you evaluate your model on testing data, you get an honest estimate of how it will perform on new, real-world data.</p>
<p>Here's the key insight: your testing data must remain completely invisible to the model until the very end. If even a hint of testing data influences your model's training, you've contaminated your experiment. It's like a student peeking at the exam questions before the test—their grade no longer reflects their true knowledge.</p>
<table>
<thead>
<tr>
<th>Data Type</th>
<th>Purpose</th>
<th>When Used</th>
<th>Model Sees During Training?</th>
</tr>
</thead>
<tbody>
<tr>
<td>Training Data</td>
<td>Teach the model patterns</td>
<td>During model fitting</td>
<td>Yes</td>
</tr>
<tr>
<td>Testing Data</td>
<td>Evaluate final performance</td>
<td>After training complete</td>
<td>No</td>
</tr>
<tr>
<td>Validation Data</td>
<td>Tune settings and choose models</td>
<td>During development</td>
<td>Sometimes (indirectly)</td>
</tr>
</tbody>
</table>
<h2 id="the-train-test-split-your-first-defense-against-self-deception">The Train-Test Split: Your First Defense Against Self-Deception</h2>
<p>The <strong>train-test split</strong> is the procedure of dividing your data into training and testing portions. Typically, you'll use 70-80% of your data for training and hold back 20-30% for testing. This ratio balances two competing needs: you want enough training data for the model to learn well, but you also want enough testing data for a reliable performance estimate.</p>
<p>Here's how to perform a train-test split with scikit-learn:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Load your data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;housing_prices.csv&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;square_feet&#39;</span><span class="p">,</span> <span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>

<span class="c1"># Split: 80% training, 20% testing</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>  <span class="c1"># Makes the split reproducible</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Testing samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>The <code>random_state</code> parameter is important—it ensures that every time you run this code, you get the same split. This makes your experiments reproducible. Without it, you'd get different results each time, making it impossible to compare different models fairly.</p>
<h4 id="diagram-train-test-split-visualization">Diagram: Train-Test Split Visualization</h4>
<details>
<summary>Train-Test Split Visualization</summary>
<p>Type: infographic</p>
<p>Bloom Taxonomy: Understand</p>
<p>Learning Objective: Help students visualize how data is divided and why the testing portion must remain separate</p>
<p>Layout: Horizontal bar representation of full dataset with animated split</p>
<p>Visual Elements:
- Full dataset shown as a horizontal bar with 100 small squares (each representing a data point)
- Squares are randomly colored to show data variety
- Animation shows 80 squares sliding left (training) and 20 sliding right (testing)
- "Wall" appears between training and testing portions
- Icons show model can "see" training data (eye icon) but testing data is "hidden" (blindfold icon)</p>
<p>Interactive Elements:
- Slider to adjust split ratio from 50/50 to 90/10
- As slider moves, squares animate between groups
- Display updates showing "Training: X samples, Testing: Y samples"
- Warning appears if split becomes too extreme (&lt; 60% or &gt; 90% training)</p>
<p>Color Scheme:
- Training data: Green shades
- Testing data: Blue shades
- Warning states: Orange/Red</p>
<p>Implementation: p5.js with smooth animations</p>
</details>
<h2 id="validation-data-the-third-kingdom">Validation Data: The Third Kingdom</h2>
<p>Sometimes two kingdoms aren't enough. <strong>Validation data</strong> is a third portion of data, carved out from your training set, that you use to make decisions <em>during</em> model development. This is different from testing data, which you only touch at the very end.</p>
<p>Why do we need validation data? Because as you develop your model, you make many choices:</p>
<ul>
<li>Should you include this feature or that feature?</li>
<li>Should you use a simple linear model or a complex polynomial?</li>
<li>What settings (hyperparameters) work best?</li>
</ul>
<p>Every time you make a choice based on performance, you're implicitly "using" that data to train your decisions. If you make these choices using your test data, you're cheating—you're letting test data influence your model development.</p>
<p>The validation set solves this. You train on training data, evaluate choices on validation data, and only at the very end—when all decisions are final—do you touch the test data for your honest final grade.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Three-way split: 60% train, 20% validation, 20% test</span>
<span class="n">X_temp</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_temp</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>  <span class="c1"># 0.25 of 0.8 = 0.2</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s2">, Validation: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span><span class="si">}</span><span class="s2">, Test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h2 id="measuring-model-performance-the-metrics-that-matter">Measuring Model Performance: The Metrics That Matter</h2>
<p>Now that you know how to split your data honestly, let's talk about <em>what</em> to measure. There are several key metrics for evaluating regression models, and each tells you something different about your model's performance.</p>
<h3 id="r-squared-the-explanation-score">R-Squared: The Explanation Score</h3>
<p><strong>R-squared</strong> (<span class="arithmatex">\(R^2\)</span>), also called the coefficient of determination, tells you what fraction of the variation in your target variable your model explains. It ranges from 0 to 1, where:</p>
<ul>
<li><span class="arithmatex">\(R^2 = 0\)</span> means your model explains nothing (just predicts the average)</li>
<li><span class="arithmatex">\(R^2 = 1\)</span> means your model explains everything (perfect predictions)</li>
<li><span class="arithmatex">\(R^2 = 0.7\)</span> means your model explains 70% of the variation</li>
</ul>
<p>The formula is:</p>
<div class="arithmatex">\[R^2 = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}\]</div>
<p>In plain English: R-squared compares your model's errors to the errors you'd get by just guessing the average every time. If your model's errors are much smaller, R-squared is close to 1. If your model is barely better than guessing the average, R-squared is close to 0.</p>
<div class="admonition tip">
<p class="admonition-title">Interpreting R-Squared</p>
<p>An R² of 0.8 sounds great, but context matters! For predicting lottery numbers, even 0.1 would be suspicious. For predicting height from age in growing children, 0.8 might be disappointing. Always consider what R² is typical for your domain.</p>
</div>
<h3 id="adjusted-r-squared-the-honest-version">Adjusted R-Squared: The Honest Version</h3>
<p>There's a sneaky problem with regular R-squared: it <em>always</em> increases when you add more features to your model, even if those features are useless. Your model might not actually get better—it just gets more complicated.</p>
<p><strong>Adjusted R-squared</strong> fixes this by penalizing model complexity:</p>
<div class="arithmatex">\[R^2_{adj} = 1 - \frac{(1 - R^2)(n - 1)}{n - p - 1}\]</div>
<p>Where <span class="arithmatex">\(n\)</span> is the number of samples and <span class="arithmatex">\(p\)</span> is the number of features. Adjusted R-squared only increases if a new feature improves the model enough to justify its added complexity. This makes it a better metric for comparing models with different numbers of features.</p>
<h3 id="mean-squared-error-the-average-squared-miss">Mean Squared Error: The Average Squared Miss</h3>
<p><strong>Mean Squared Error (MSE)</strong> is exactly what it sounds like: the average of your squared prediction errors.</p>
<div class="arithmatex">\[MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2\]</div>
<p>Why square the errors? Two reasons:</p>
<ol>
<li>It prevents positive and negative errors from canceling out</li>
<li>It punishes big mistakes more than small ones (a prediction off by 10 is 100 times worse than one off by 1)</li>
</ol>
<p>The downside of MSE is that it's in squared units, which can be hard to interpret. If you're predicting prices in dollars, MSE is in "dollars squared," which is weird.</p>
<h3 id="root-mean-squared-error-mse-you-can-understand">Root Mean Squared Error: MSE You Can Understand</h3>
<p><strong>Root Mean Squared Error (RMSE)</strong> solves the squared units problem by taking the square root:</p>
<div class="arithmatex">\[RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}\]</div>
<p>RMSE is in the same units as your target variable. If you're predicting house prices and your RMSE is $25,000, you can say "on average, my predictions are off by about $25,000." That's much more interpretable!</p>
<h3 id="mean-absolute-error-the-simple-alternative">Mean Absolute Error: The Simple Alternative</h3>
<p><strong>Mean Absolute Error (MAE)</strong> takes a different approach—instead of squaring errors, it just uses absolute values:</p>
<div class="arithmatex">\[MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|\]</div>
<p>MAE is also in the original units and is simpler to understand than RMSE. The key difference: MAE treats all errors equally, while RMSE punishes big errors more severely. Which should you use? It depends on whether large errors are especially bad for your application.</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Units</th>
<th>Big Errors</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td>R²</td>
<td>Unitless (0-1)</td>
<td>Averaged</td>
<td>Fraction of variance explained</td>
</tr>
<tr>
<td>MSE</td>
<td>Squared units</td>
<td>Heavily penalized</td>
<td>Average squared error</td>
</tr>
<tr>
<td>RMSE</td>
<td>Original units</td>
<td>Moderately penalized</td>
<td>Typical error magnitude</td>
</tr>
<tr>
<td>MAE</td>
<td>Original units</td>
<td>Equal weight</td>
<td>Average absolute error</td>
</tr>
</tbody>
</table>
<h4 id="diagram-metrics-comparison-microsim">Diagram: Metrics Comparison MicroSim</h4>
<details>
<summary>Metrics Comparison MicroSim</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Apply, Analyze</p>
<p>Learning Objective: Help students understand how different error metrics respond to the same prediction errors, especially the difference between MAE and RMSE when outliers are present</p>
<p>Canvas Layout (800x500):
- Left side (500x500): Scatter plot with regression line and interactive points
- Right side (300x500): Real-time metrics display</p>
<p>Visual Elements:
- 10 data points that can be dragged
- Regression line that updates in real-time
- Vertical lines showing residuals (prediction errors)
- Residuals colored by size (green = small, yellow = medium, red = large)</p>
<p>Interactive Controls:
- Draggable data points to create different error patterns
- Button: "Add Outlier" - adds a point far from the line
- Button: "Reset to Default" - returns to initial configuration
- Checkbox: "Show squared residuals" - visualizes MSE calculation
- Checkbox: "Show absolute residuals" - visualizes MAE calculation</p>
<p>Metrics Display (updates in real-time):
- R²: X.XXX
- MSE: X.XX
- RMSE: X.XX
- MAE: X.XX
- Bar chart comparing metrics (normalized for visualization)</p>
<p>Key Learning Moments:
- Drag one point far away and watch RMSE spike more than MAE
- Create symmetrical errors and see they still contribute to metrics
- Notice how R² can decrease when predictions get worse</p>
<p>Default Parameters:
- 10 points roughly following y = 2x + 1 with small noise
- Initial R² around 0.85</p>
<p>Implementation: p5.js with real-time regression recalculation</p>
</details>
<h2 id="calculating-metrics-in-python">Calculating Metrics in Python</h2>
<p>Here's how to calculate all these metrics using scikit-learn:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Train the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Make predictions on test data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate metrics</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>  <span class="c1"># or mean_squared_error(y_test, y_pred, squared=False)</span>
<span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R-Squared: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RMSE: </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">mae</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>Let's visualize these predictions with Plotly to see how well our model performs:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

<span class="c1"># Create a comparison dataframe</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Actual&#39;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">,</span>
    <span class="s1">&#39;Predicted&#39;</span><span class="p">:</span> <span class="n">y_pred</span>
<span class="p">})</span>

<span class="c1"># Scatter plot of actual vs predicted</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">results</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Actual&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Actual vs Predicted Values&#39;</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Actual&#39;</span><span class="p">:</span> <span class="s1">&#39;Actual Values&#39;</span><span class="p">,</span> <span class="s1">&#39;Predicted&#39;</span><span class="p">:</span> <span class="s1">&#39;Predicted Values&#39;</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Add perfect prediction line</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
        <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;lines&#39;</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Perfect Prediction&#39;</span><span class="p">,</span>
        <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">dash</span><span class="o">=</span><span class="s1">&#39;dash&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h2 id="residual-analysis-csi-data-science">Residual Analysis: CSI Data Science</h2>
<p><strong>Residual analysis</strong> is like being a detective investigating your model's mistakes. A <strong>residual</strong> is simply the difference between the actual value and your predicted value:</p>
<div class="arithmatex">\[\text{Residual} = y_{\text{actual}} - y_{\text{predicted}}\]</div>
<p>Looking at individual residuals tells you where your model is struggling. But the real power comes from looking at <em>patterns</em> in your residuals. If your residuals are randomly scattered (no pattern), your model is working well. If there's a pattern, something is wrong.</p>
<p>A <strong>residual plot</strong> shows residuals on the y-axis and either predicted values or a feature on the x-axis. Here's what to look for:</p>
<ul>
<li><strong>Random scatter around zero</strong>: Good! Model assumptions are met.</li>
<li><strong>Curved pattern</strong>: Bad! Relationship might be non-linear.</li>
<li><strong>Funnel shape (spreads out)</strong>: Bad! Variance isn't constant (heteroscedasticity).</li>
<li><strong>Clusters or groups</strong>: Bad! Missing categorical information.</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Calculate residuals</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span>

<span class="c1"># Create residual plot with Plotly</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">residuals</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Residual Plot: Hunting for Patterns&#39;</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="s1">&#39;Predicted Values&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="s1">&#39;Residuals&#39;</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Add horizontal line at y=0</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_hline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">line_dash</span><span class="o">=</span><span class="s2">&quot;dash&quot;</span><span class="p">,</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="diagram-residual-pattern-detective">Diagram: Residual Pattern Detective</h4>
<details>
<summary>Residual Pattern Detective</summary>
<p>Type: infographic</p>
<p>Bloom Taxonomy: Analyze, Evaluate</p>
<p>Learning Objective: Train students to recognize common residual patterns and diagnose what's wrong with their model</p>
<p>Layout: 2x2 grid of residual plot examples with diagnostic labels</p>
<p>Panels:
1. Top-Left: "Healthy Residuals"
   - Random scatter around horizontal line at 0
   - Caption: "Random pattern = model is working well"
   - Green checkmark icon
   - Hover: "No systematic bias, assumptions met"</p>
<ol>
<li>Top-Right: "Curved Pattern"</li>
<li>U-shaped or wave pattern in residuals</li>
<li>Caption: "Curved pattern = try polynomial features"</li>
<li>Yellow warning icon</li>
<li>
<p>Hover: "Linear model missing non-linear relationship"</p>
</li>
<li>
<p>Bottom-Left: "Funnel Shape"</p>
</li>
<li>Residuals spread out as predictions increase</li>
<li>Caption: "Funnel shape = variance problems"</li>
<li>Orange warning icon</li>
<li>
<p>Hover: "Consider log transformation of target"</p>
</li>
<li>
<p>Bottom-Right: "Clustered Groups"</p>
</li>
<li>Distinct groups of residuals at different levels</li>
<li>Caption: "Clusters = missing categorical variable"</li>
<li>Red warning icon</li>
<li>Hover: "Include the grouping variable as a feature"</li>
</ol>
<p>Interactive Elements:
- Click each panel for expanded explanation
- Hover shows diagnostic advice
- "Quiz mode" button randomly shows a pattern and asks for diagnosis</p>
<p>Color Scheme:
- Residual points in blue
- Reference line in red (dashed)
- Background panels in light gray</p>
<p>Implementation: HTML/CSS/JavaScript with interactive panels</p>
</details>
<h2 id="the-perils-of-overfitting-when-your-model-studies-too-hard">The Perils of Overfitting: When Your Model Studies Too Hard</h2>
<p>Here's a paradox: a model can perform <em>too well</em> on training data. When this happens, we call it <strong>overfitting</strong>. An overfit model has essentially memorized the training data, including all its noise and random fluctuations. It achieves amazing training scores but fails miserably on new data.</p>
<p>Think of a student who memorizes every practice test word-for-word instead of learning the underlying concepts. They'll ace practice tests but bomb the actual exam if the questions are phrased even slightly differently.</p>
<p>Signs of overfitting:</p>
<ul>
<li>Training error is very low</li>
<li>Test error is much higher than training error</li>
<li>Model is complex (many features, high polynomial degree)</li>
<li>Training data is limited</li>
</ul>
<p>An overfit model has low <strong>bias</strong> (its predictions aren't systematically wrong) but high <strong>variance</strong> (its predictions are very sensitive to which specific training data it saw).</p>
<h2 id="the-dangers-of-underfitting-when-your-model-doesnt-try-hard-enough">The Dangers of Underfitting: When Your Model Doesn't Try Hard Enough</h2>
<p>The opposite problem is <strong>underfitting</strong>. An underfit model is too simple to capture the patterns in the data. It performs poorly on both training and test data because it never learned the real relationship.</p>
<p>Think of a student who only skims the textbook and tries to pass by guessing. They'll do poorly on everything.</p>
<p>Signs of underfitting:</p>
<ul>
<li>Training error is high</li>
<li>Test error is also high (and similar to training error)</li>
<li>Model is very simple (few features, too restrictive)</li>
<li>There's clearly more pattern in the data to capture</li>
</ul>
<p>An underfit model has high <strong>bias</strong> (it systematically misses the true pattern) but low <strong>variance</strong> (its predictions are consistent, just consistently wrong).</p>
<table>
<thead>
<tr>
<th>Condition</th>
<th>Training Error</th>
<th>Test Error</th>
<th>Model Complexity</th>
<th>Cure</th>
</tr>
</thead>
<tbody>
<tr>
<td>Underfitting</td>
<td>High</td>
<td>High</td>
<td>Too low</td>
<td>Add features, increase complexity</td>
</tr>
<tr>
<td>Good Fit</td>
<td>Low</td>
<td>Low (similar)</td>
<td>Just right</td>
<td>Keep it!</td>
</tr>
<tr>
<td>Overfitting</td>
<td>Very Low</td>
<td>High</td>
<td>Too high</td>
<td>Reduce complexity, get more data</td>
</tr>
</tbody>
</table>
<h2 id="bias-and-variance-the-fundamental-tradeoff">Bias and Variance: The Fundamental Tradeoff</h2>
<p><strong>Bias</strong> and <strong>variance</strong> are two types of model errors that pull in opposite directions.</p>
<p><strong>Bias</strong> is the error from oversimplifying. A high-bias model makes strong assumptions about the data that might not be true. It will consistently miss the target in the same direction, like a dart thrower who always aims too far left.</p>
<p><strong>Variance</strong> is the error from being too sensitive to training data. A high-variance model changes dramatically depending on which specific samples it was trained on. It's like a dart thrower whose aim is all over the place—sometimes left, sometimes right, sometimes high, sometimes low.</p>
<p>The <strong>bias-variance tradeoff</strong> is the fundamental tension in machine learning:</p>
<ul>
<li>Simple models: High bias, low variance (consistent but often wrong)</li>
<li>Complex models: Low bias, high variance (can be right but unstable)</li>
</ul>
<p>Your goal is to find the sweet spot—a model complex enough to capture the real pattern but simple enough to not chase noise.</p>
<h4 id="diagram-bias-variance-dartboard">Diagram: Bias-Variance Dartboard</h4>
<details>
<summary>Bias-Variance Dartboard</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Understand, Apply</p>
<p>Learning Objective: Visualize bias and variance using the intuitive dartboard analogy, and understand how model complexity affects this tradeoff</p>
<p>Canvas Layout (800x450):
- Left side: Four dartboard panels (2x2 grid, each 180x180)
- Right side: Interactive model complexity slider and explanation panel</p>
<p>Dartboard Panels:
1. Top-left: "Low Bias, Low Variance" - Darts clustered at center (bullseye)
   - Label: "The Goal: Accurate and Consistent"
2. Top-right: "Low Bias, High Variance" - Darts scattered but centered on bullseye
   - Label: "Accurate on Average, But Inconsistent"
3. Bottom-left: "High Bias, Low Variance" - Darts clustered but off-center
   - Label: "Consistent but Systematically Wrong"
4. Bottom-right: "High Bias, High Variance" - Darts scattered and off-center
   - Label: "The Worst: Wrong and Inconsistent"</p>
<p>Interactive Elements:
- Slider: "Model Complexity" (1 to 10 scale)
- As slider moves left (simpler): highlight high-bias panels
- As slider moves right (complex): highlight high-variance panels
- Button: "Throw 10 Darts" - animates darts landing based on current complexity setting
- The fifth dartboard shows real-time results based on slider position</p>
<p>Real-time Display:
- Bias indicator bar
- Variance indicator bar
- Total Error = Bias² + Variance (visualized as stacked bar)</p>
<p>Animation:
- Darts "thrown" one at a time with slight delay
- Each dart leaves a mark on the board
- After all darts, metrics calculate and display</p>
<p>Implementation: p5.js with dart physics animation</p>
</details>
<h2 id="model-complexity-the-goldilocks-problem">Model Complexity: The Goldilocks Problem</h2>
<p><strong>Model complexity</strong> refers to how flexible or expressive your model is. A simple linear model with one feature has low complexity. A polynomial model with degree 10 has high complexity. A neural network with millions of parameters has very high complexity.</p>
<p>The Goldilocks principle applies: you want a model that's <em>just right</em>. Too simple, and you underfit. Too complex, and you overfit.</p>
<p>Here's how complexity relates to polynomial regression:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="c1"># Compare different polynomial degrees</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>

<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
        <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="p">),</span>
        <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">train_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">test_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Degree </span><span class="si">{</span><span class="n">degree</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Train R²=</span><span class="si">{</span><span class="n">train_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test R²=</span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>Typically, you'll see training R² keep increasing with complexity, but test R² will peak and then decrease as overfitting kicks in.</p>
<h4 id="diagram-complexity-curve-explorer">Diagram: Complexity Curve Explorer</h4>
<details>
<summary>Complexity Curve Explorer</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Apply, Evaluate</p>
<p>Learning Objective: Visualize how training and test error change as model complexity increases, and identify the optimal complexity level</p>
<p>Canvas Layout (800x500):
- Top (800x350): Main visualization showing data points and fitted curve
- Bottom (800x150): Error vs. Complexity chart</p>
<p>Top Panel Elements:
- 30 data points following a cubic relationship with noise
- Polynomial curve that updates with complexity slider
- Curve color indicates fit quality (green = good, red = overfit/underfit)</p>
<p>Bottom Panel Elements:
- X-axis: Model Complexity (polynomial degree 1-15)
- Y-axis: Error (MSE)
- Two lines: Training Error (blue) and Test Error (orange)
- Vertical marker showing current complexity selection
- Shaded regions: "Underfitting Zone" (left), "Sweet Spot" (middle), "Overfitting Zone" (right)</p>
<p>Interactive Controls:
- Slider: "Polynomial Degree" (1 to 15)
- Checkbox: "Show training error curve"
- Checkbox: "Show test error curve"
- Button: "Auto-find optimal" - animates to minimum test error
- Button: "Reset data" - generates new random dataset</p>
<p>Real-time Metrics Display:
- Current degree: X
- Training MSE: X.XX
- Test MSE: X.XX
- Gap (Test - Train): X.XX (with color coding)</p>
<p>Key Insights Highlighted:
- When gap is large (&gt;threshold): "Overfitting Warning!" in red
- When both errors are high: "Underfitting Warning!" in yellow
- When gap is small and errors low: "Good fit!" in green</p>
<p>Implementation: p5.js with polynomial regression calculation</p>
</details>
<h2 id="cross-validation-the-ultimate-fairness-test">Cross-Validation: The Ultimate Fairness Test</h2>
<p>The simple train-test split has a weakness: your results depend heavily on which specific data points ended up in training vs. testing. With a different random split, you might get very different results. <strong>Cross-validation</strong> solves this by testing on <em>all</em> of your data, just not all at once.</p>
<h3 id="k-fold-cross-validation">K-Fold Cross-Validation</h3>
<p><strong>K-Fold Cross-Validation</strong> divides your data into K equal-sized chunks called "folds." Then it trains K different models, each time using a different fold as the test set and the remaining K-1 folds for training. Finally, it averages the K test scores to get a more reliable performance estimate.</p>
<p>The most common choice is K=5 or K=10. Here's how 5-fold cross-validation works:</p>
<ol>
<li>Split data into 5 folds</li>
<li>Train on folds 1,2,3,4; test on fold 5 → Score 1</li>
<li>Train on folds 1,2,3,5; test on fold 4 → Score 2</li>
<li>Train on folds 1,2,4,5; test on fold 3 → Score 3</li>
<li>Train on folds 1,3,4,5; test on fold 2 → Score 4</li>
<li>Train on folds 2,3,4,5; test on fold 1 → Score 5</li>
<li>Final score = Average of all 5 scores</li>
</ol>
<p>This gives you a much more reliable estimate because every data point gets to be in the test set exactly once.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># 5-fold cross-validation</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CV Scores: </span><span class="si">{</span><span class="n">cv_scores</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean CV Score: </span><span class="si">{</span><span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Standard Deviation: </span><span class="si">{</span><span class="n">cv_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>The standard deviation tells you how stable your model's performance is. A low standard deviation means your model performs consistently across different subsets of data.</p>
<h4 id="diagram-k-fold-cross-validation-animator">Diagram: K-Fold Cross-Validation Animator</h4>
<details>
<summary>K-Fold Cross-Validation Animator</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Understand, Apply</p>
<p>Learning Objective: Visualize how K-fold cross-validation rotates through the data and why it provides a more reliable performance estimate</p>
<p>Canvas Layout (700x500):
- Main area (700x350): Visual representation of data folds
- Bottom area (700x150): Results table and summary statistics</p>
<p>Visual Elements:
- Data represented as 50 colored squares in a horizontal strip
- Squares grouped into K folds with subtle borders between groups
- Training folds colored green
- Test fold colored blue
- Animation shows the "window" of test data sliding across folds</p>
<p>Interactive Controls:
- Dropdown: "Number of folds (K)" - options: 3, 5, 10
- Button: "Run Cross-Validation" - starts animation
- Button: "Pause/Resume"
- Speed slider: controls animation speed
- Button: "Reset"</p>
<p>Animation Sequence:
1. Show all data as neutral color
2. Divide into K folds with visual separation
3. For each iteration:
   - Highlight test fold in blue
   - Highlight training folds in green
   - Show mini-chart of model being "trained"
   - Display score for this fold
   - Pause briefly, then move to next fold
4. After all folds complete, show final averaged score</p>
<p>Results Display:
- Table showing each fold's score
- Running average line chart
- Final statistics: Mean, Std Dev, Min, Max
- Comparison to simple train-test split result</p>
<p>Educational Callouts:
- "Every data point tested exactly once!"
- "Average gives more reliable estimate"
- When std is high: "High variance in scores - model might be unstable"</p>
<p>Implementation: p5.js with step-by-step animation</p>
</details>
<h3 id="leave-one-out-cross-validation">Leave-One-Out Cross-Validation</h3>
<p><strong>Leave-One-Out Cross-Validation (LOOCV)</strong> is the extreme version where K equals the number of data points. For each iteration, you train on <em>all</em> data except one point, then test on that single point. This is the most thorough form of cross-validation but can be computationally expensive for large datasets.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span><span class="p">,</span> <span class="n">cross_val_score</span>

<span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of splits: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Score: </span><span class="si">{</span><span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>LOOCV is mostly used when you have very limited data and need to squeeze every drop of information from it.</p>
<h3 id="the-holdout-method">The Holdout Method</h3>
<p>The <strong>holdout method</strong> is the simplest validation approach—it's just the train-test split we learned earlier. While it's simple and fast, it's also the least reliable because your results depend on the random split. Cross-validation improves upon the holdout method by removing this randomness.</p>
<h2 id="hyperparameters-the-settings-you-choose">Hyperparameters: The Settings You Choose</h2>
<p><strong>Hyperparameters</strong> are the settings you choose <em>before</em> training your model. They're different from regular parameters (like regression coefficients) which are <em>learned</em> during training.</p>
<p>Examples of hyperparameters:</p>
<ul>
<li>The degree in polynomial regression</li>
<li>The train-test split ratio</li>
<li>The number of folds K in cross-validation</li>
<li>(In future chapters) Learning rate, number of layers, regularization strength</li>
</ul>
<p>Hyperparameters are typically chosen by trying different values and seeing which performs best on validation data. This process is called <strong>hyperparameter tuning</strong>.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Create a pipeline</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Define hyperparameters to try</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;poly__degree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>

<span class="c1"># Search for best hyperparameters</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best degree: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;poly__degree&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best CV Score: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h2 id="model-selection-and-comparison">Model Selection and Comparison</h2>
<p><strong>Model selection</strong> is the process of choosing the best model from a set of candidates. This could mean choosing between:</p>
<ul>
<li>Different algorithms (linear vs. polynomial)</li>
<li>Different feature sets (which columns to include)</li>
<li>Different hyperparameter settings</li>
</ul>
<p>The key principle: always compare models using their <em>test</em> performance (or cross-validation score), never their training performance. A model that looks great on training data might be terrible in practice.</p>
<p><strong>Model comparison</strong> involves evaluating multiple models on the same data using the same metrics. Here's a systematic approach:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="c1"># Compare multiple polynomial degrees</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>

<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">())</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="n">degree</span><span class="p">,</span>
        <span class="s1">&#39;mean_score&#39;</span><span class="p">:</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="s1">&#39;std_score&#39;</span><span class="p">:</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="p">})</span>

<span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="c1"># Visualize with Plotly</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;degree&#39;</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;mean_score&#39;</span><span class="p">],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;lines+markers&#39;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Mean CV Score&#39;</span><span class="p">,</span>
    <span class="n">error_y</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">array</span><span class="o">=</span><span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;std_score&#39;</span><span class="p">],</span> <span class="n">visible</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Model Comparison: Polynomial Degree vs. CV Score&#39;</span><span class="p">,</span>
    <span class="n">xaxis_title</span><span class="o">=</span><span class="s1">&#39;Polynomial Degree&#39;</span><span class="p">,</span>
    <span class="n">yaxis_title</span><span class="o">=</span><span class="s1">&#39;Cross-Validation R²&#39;</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">400</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Find the best model</span>
<span class="n">best_idx</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;mean_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best model: degree </span><span class="si">{</span><span class="n">results_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">best_idx</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;degree&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score: </span><span class="si">{</span><span class="n">results_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">best_idx</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;mean_score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="diagram-model-selection-dashboard">Diagram: Model Selection Dashboard</h4>
<details>
<summary>Model Selection Dashboard</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy: Evaluate, Analyze</p>
<p>Learning Objective: Practice the complete model selection workflow, from training multiple models to selecting the best one based on validation performance</p>
<p>Canvas Layout (900x600):
- Left panel (450x600): Model configuration and training
- Right panel (450x600): Results comparison and visualization</p>
<p>Left Panel Elements:
- Dataset selector: "Generate Data" button with options (linear, quadratic, sine wave, noisy)
- Model type selector: Linear, Polynomial (with degree slider 1-10)
- Train-Test split slider (60-90%)
- Cross-validation folds dropdown (3, 5, 10)
- "Train Model" button
- "Add to Comparison" button</p>
<p>Right Panel Elements:
- Table of trained models with columns: Model Name, Train R², Test R², CV Mean, CV Std
- Bar chart comparing CV scores across models
- Selected model's predictions vs actual scatter plot
- "Declare Winner" button highlights best model
- "Clear All" button resets comparison</p>
<p>Interactive Workflow:
1. Generate or load data
2. Configure model settings
3. Click "Train Model" to see individual results
4. Click "Add to Comparison" to add to leaderboard
5. Repeat with different configurations
6. Compare all models in the results table
7. Click "Declare Winner" to highlight the best performer</p>
<p>Visual Feedback:
- Training progress animation when model trains
- Color coding: green for best model, yellow for good, red for poor
- Warning icons when overfitting detected (large train-test gap)
- Trophy icon next to winning model</p>
<p>Educational Hints:
- Tooltip: "Look for high CV score with low standard deviation"
- Warning when user tries to compare models on different data
- Celebration animation when optimal model found</p>
<p>Implementation: p5.js with integrated ML calculations</p>
</details>
<h2 id="putting-it-all-together-the-model-evaluation-workflow">Putting It All Together: The Model Evaluation Workflow</h2>
<p>Here's the complete workflow for evaluating models like a professional:</p>
<ol>
<li>
<p><strong>Split your data</strong> into training and test sets (or training, validation, and test)</p>
</li>
<li>
<p><strong>Train your model</strong> on the training data only</p>
</li>
<li>
<p><strong>Evaluate using cross-validation</strong> during model development</p>
</li>
<li>
<p><strong>Try different models/hyperparameters</strong> and compare using validation or CV scores</p>
</li>
<li>
<p><strong>Select the best model</strong> based on validation performance</p>
</li>
<li>
<p><strong>Final evaluation on test data</strong> only after all decisions are made</p>
</li>
<li>
<p><strong>Analyze residuals</strong> to check if model assumptions hold</p>
</li>
<li>
<p><strong>Report honest metrics</strong> including uncertainty (standard deviation)</p>
</li>
</ol>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Complete evaluation workflow example</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Step 1: Split data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Step 2-5: Find best model using cross-validation on training data</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">()),</span> <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())])</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;poly__degree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best hyperparameters: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best CV score: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Step 6: Final evaluation on test data</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final test score: </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Step 7: Residual analysis</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean residual: </span><span class="si">{</span><span class="n">residuals</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Should be close to 0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Residual std: </span><span class="si">{</span><span class="n">residuals</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="diagram-model-evaluation-workflow">Diagram: Model Evaluation Workflow</h4>
<details>
<summary>Model Evaluation Workflow</summary>
<p>Type: workflow</p>
<p>Bloom Taxonomy: Apply, Analyze</p>
<p>Learning Objective: Understand the complete model evaluation pipeline and the order of operations to avoid data leakage</p>
<p>Visual Style: Vertical flowchart with swimlanes for different data subsets</p>
<p>Swimlanes:
- Full Dataset
- Training Data
- Validation/CV
- Test Data (final)</p>
<p>Steps:
1. Start: "Load Complete Dataset"
   Hover: "All data before any splits"
   Lane: Full Dataset</p>
<ol>
<li>
<p>Process: "Split into Train and Test"
   Hover: "Typically 80/20 split, test data is locked away"
   Lane: Full Dataset → Training Data + Test Data
   Color: Blue</p>
</li>
<li>
<p>Process: "Train Initial Model"
   Hover: "Fit model on training data only"
   Lane: Training Data
   Color: Green</p>
</li>
<li>
<p>Process: "Cross-Validate"
   Hover: "Get reliable performance estimate using K-fold CV"
   Lane: Training Data (with internal splits shown)
   Color: Green</p>
</li>
<li>
<p>Decision: "Try Different Models?"
   Hover: "Compare polynomial degrees, feature sets, algorithms"
   Lane: Validation/CV
   Color: Yellow</p>
</li>
<li>
<p>Process: "Hyperparameter Tuning"
   Hover: "Use GridSearchCV or similar to find best settings"
   Lane: Training Data
   Color: Green</p>
</li>
<li>
<p>Process: "Select Best Model"
   Hover: "Choose based on validation/CV performance, not training!"
   Lane: Validation/CV
   Color: Yellow</p>
</li>
<li>
<p>Process: "Final Evaluation"
   Hover: "ONLY NOW touch test data - this is your honest grade"
   Lane: Test Data
   Color: Red</p>
</li>
<li>
<p>Process: "Residual Analysis"
   Hover: "Check for patterns, validate assumptions"
   Lane: Test Data
   Color: Red</p>
</li>
<li>
<p>End: "Report Results"
    Hover: "Report test metrics with confidence intervals"
    Lane: All lanes
    Color: Purple</p>
</li>
</ol>
<p>Arrows and Flow:
- Main flow goes top to bottom
- Iteration loop from "Try Different Models?" back to "Train Initial Model"
- Clear visual barrier before "Final Evaluation" indicating "Point of No Return"</p>
<p>Key Visual Elements:
- Lock icon on Test Data swimlane until step 8
- Warning symbol if any arrow tries to cross into Test Data early
- Checkmarks appearing as each step completes</p>
<p>Implementation: HTML/CSS/JavaScript with hover interactions</p>
</details>
<h2 id="common-pitfalls-and-how-to-avoid-them">Common Pitfalls and How to Avoid Them</h2>
<p>As you develop your model evaluation superpowers, watch out for these traps:</p>
<p><strong>Data Leakage</strong>: Information from test data influences training. This inflates your metrics and leads to disappointment in production. Always split data <em>before</em> any preprocessing that looks at target values.</p>
<p><strong>Overfitting to Validation Data</strong>: If you try too many models and always pick the best validation score, you can overfit to your validation set. Hold out a truly final test set and only use it once.</p>
<p><strong>Ignoring Variance</strong>: A single train-test split gives you one number. That number has uncertainty! Use cross-validation to estimate how stable your performance is.</p>
<p><strong>Wrong Metric for the Problem</strong>: R² isn't always the right choice. For some problems, you might care more about avoiding big mistakes (use RMSE) or want robust performance (use MAE). Match your metric to your real-world goals.</p>
<p><strong>Not Checking Residuals</strong>: A model can have decent R² but still have systematic problems visible in residual plots. Always look at your residuals!</p>
<div class="admonition warning">
<p class="admonition-title">The Final Test Rule</p>
<p>Once you evaluate on your test set, you're done. If you go back and tune your model based on test results, and then evaluate again, your test set has become a validation set. You've lost your honest evaluation. Some practitioners save a final "holdout" set that never gets touched until the very final model goes to production.</p>
</div>
<h2 id="summary-your-model-evaluation-toolkit">Summary: Your Model Evaluation Toolkit</h2>
<p>You now have a powerful toolkit for honest model evaluation:</p>
<ul>
<li><strong>Train-test split</strong> separates learning from evaluation</li>
<li><strong>Validation data</strong> helps tune models without cheating</li>
<li><strong>R², MSE, RMSE, MAE</strong> each tell different stories about performance</li>
<li><strong>Residual analysis</strong> reveals hidden problems</li>
<li><strong>Overfitting and underfitting</strong> are the twin dangers to avoid</li>
<li><strong>Bias-variance tradeoff</strong> explains why model complexity matters</li>
<li><strong>Cross-validation</strong> gives stable, reliable estimates</li>
<li><strong>Model comparison</strong> helps you choose the best approach</li>
</ul>
<p>Remember: the goal isn't just to build a model that looks good on paper. It's to build a model that will perform well on data it has never seen before—because that's the only kind of data that matters in the real world.</p>
<p>With these evaluation superpowers, you can confidently assess any model's true capabilities and avoid the trap of self-deception. You're no longer just building models; you're building models you can <em>trust</em>.</p>
<h2 id="looking-ahead">Looking Ahead</h2>
<p>In the next chapter, we'll extend our regression toolkit to handle multiple features simultaneously. Multiple linear regression will let you model more complex relationships—but with great power comes great responsibility. Your new evaluation skills will be essential for navigating the increased complexity without falling into the overfitting trap.</p>
<hr />
<h2 id="key-takeaways">Key Takeaways</h2>
<ul>
<li>Never evaluate a model on the same data it was trained on—that's just testing memorization</li>
<li>The train-test split creates honest evaluation; cross-validation makes it reliable</li>
<li>R² tells you proportion of variance explained; RMSE tells you typical error size in original units</li>
<li>Residual plots reveal patterns your metrics might miss</li>
<li>Overfitting (high variance) and underfitting (high bias) are equally dangerous</li>
<li>Cross-validation gives you both a performance estimate and uncertainty measure</li>
<li>Model selection should be based on validation/CV performance, with final evaluation on held-out test data</li>
<li>The simpler model that performs nearly as well is often the better choice</li>
</ul>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../07-simple-linear-regression/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Simple Linear Regression">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Simple Linear Regression
              </div>
            </div>
          </a>
        
        
          
          <a href="../09-multiple-linear-regression/" class="md-footer__link md-footer__link--next" aria-label="Next: Multiple Linear Regression">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Multiple Linear Regression
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 Dan McCreary. Licensed under <a href="license/">CC BY-NC-SA 4.0</a> for non-commercial use.
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.expand", "navigation.path", "navigation.prune", "navigation.indexes", "toc.follow", "navigation.top", "navigation.footer", "content.action.edit"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>